{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e50eb93",
   "metadata": {},
   "source": [
    "# EurDyscover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908c4eb",
   "metadata": {},
   "source": [
    "This script structures the data available from different sources, namely video recordings, inscopix and accelerometer for a single session of one animal. Later, the goal is to generalize the code for all files of all animals.\n",
    "\n",
    "Importantly, it identifies errors, signal misalignments, dropped frames, ...\n",
    "\n",
    "Most files used to build this script were downloaded to the Desktop from the google drive 'EurDyscover>Organized>Analyzed data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59bbfcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welcome the user that is going to run the analysis :)\n",
    "name = input('Please enter your name: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50da663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Diogo! Join me in preparing your data for analysis :). We should start by importing all the necessary files, followed by checking and correcting missing data\n"
     ]
    }
   ],
   "source": [
    "if name:\n",
    "    print(\"Hello {}! Join me in preparing your data for analysis :). We should start by importing all the necessary files, followed by checking and correcting missing data\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ede7a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818e832",
   "metadata": {},
   "source": [
    "# 1. Import all the files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c6753",
   "metadata": {},
   "source": [
    "## 1.1 Import neuron.mat\n",
    "This is a matlab file containing the information of every neuron across time.\n",
    "\n",
    "\n",
    "The [CNMF-E](https://github.com/zhoupc/CNMF_E) package for extracting calcium traces from microendoscope data outputs Matlab .mat files.  These files represent the data as a custom Matlab class called Sources2D, so they cannot be directly loaded into Python for further analysis.  This repository provides functions for converting the CNMF-E output into Numpy .npy files.\n",
    "\n",
    "The Matlab function `Sources2D_to_simple_mat` converts the .mat file output by CNMFe to a more basic .mat file that can be opened in Python using `scipy.io.loadmat`.  In order to load the .mat files generated by CNMF-E into Matlab you must also have the file *Sources2D.m* which contains the Matlab class definition in the Matlab file path.\n",
    "\n",
    " The Python function `simple_mat_to_npy` converts the  .mat file generated by `Sources2D_to_simple_mat`  to a folder of .npy files with a separate file for each of the variables 'A', 'S', 'C', 'C_raw'.   The A matrix is reshaped such that neuron footprints can be visualised with `plt.imshow(A[0])` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510afad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Thu Aug 18 15:41:30 2022',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'None': MatlabOpaque([(b'file_name', b'MCOS', b'string', array([[3707764736],\n",
       "                      [         2],\n",
       "                      [         1],\n",
       "                      [         1],\n",
       "                      [         1],\n",
       "                      [         1]], dtype=uint32))                   ],\n",
       "              dtype=[('s0', 'O'), ('s1', 'O'), ('s2', 'O'), ('arr', 'O')]),\n",
       " 'A': <94605x232 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 48504 stored elements in Compressed Sparse Column format>,\n",
       " 'C': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         6.68933050e-08, 6.02981023e-08, 5.43531396e-08],\n",
       "        [9.38301307e-02, 8.47053864e-02, 7.64680005e-02, ...,\n",
       "         5.22859009e-05, 4.72012285e-05, 4.26110277e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.72706407e-10, 3.39488589e-10, 3.09231341e-10],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         1.30100834e-03, 1.23240212e-03, 1.16741371e-03],\n",
       "        [3.35046121e-01, 2.73042885e-01, 2.22513894e-01, ...,\n",
       "         3.07704732e-08, 2.50761261e-08, 2.04355681e-08],\n",
       "        [2.21460790e+00, 2.04826360e+00, 1.89441381e+00, ...,\n",
       "         1.33157254e-41, 1.23155506e-41, 1.13905013e-41]]),\n",
       " 'S': <232x24428 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 16186 stored elements in Compressed Sparse Column format>,\n",
       " 'C_raw': array([[-0.40612891,  0.18300714, -0.23267231, ..., -0.10002826,\n",
       "         -0.30621961, -0.40336283],\n",
       "        [-0.04776913,  0.06428621,  0.15249081, ..., -0.09491153,\n",
       "         -0.28223448,  0.14740536],\n",
       "        [-0.05746017, -0.32487097, -0.23398402, ..., -0.73468601,\n",
       "         -0.0473376 , -0.03257586],\n",
       "        ...,\n",
       "        [-1.08224398, -1.25240864, -2.73551175, ...,  1.11791634,\n",
       "          0.93355372,  0.18870505],\n",
       "        [ 0.97755395, -1.28046263, -0.17943313, ..., -1.17186207,\n",
       "         -2.37735314, -2.22612654],\n",
       "        [ 0.47326361, -0.03838293,  1.08786366, ..., -0.1235285 ,\n",
       "         -0.55321162, -0.34514889]]),\n",
       " 'image_size': array([[265, 357]], dtype=uint16),\n",
       " '__function_workspace__': array([[  0,   1,  73,  77,   0,   0,   0,   0,  14,   0,   0,   0,  40,\n",
       "           3,   0,   0,   6,   0,   0,   0,   8,   0,   0,   0,   2,   0,\n",
       "           0,   0,   0,   0,   0,   0,   5,   0,   0,   0,   8,   0,   0,\n",
       "           0,   1,   0,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,\n",
       "           0,   0,   0,   0,   5,   0,   4,   0,   5,   0,   0,   0,   1,\n",
       "           0,   0,   0,   5,   0,   0,   0,  77,  67,  79,  83,   0,   0,\n",
       "           0,   0,  14,   0,   0,   0, 224,   2,   0,   0,   6,   0,   0,\n",
       "           0,   8,   0,   0,   0,  17,   0,   0,   0,   0,   0,   0,   0,\n",
       "           1,   0,   0,   0,   0,   0,   0,   0,   1,   0,   4,   0,  77,\n",
       "          67,  79,  83,   1,   0,   0,   0,  13,   0,   0,   0,  70, 105,\n",
       "         108, 101,  87, 114,  97, 112, 112, 101, 114,  95,  95,   0,   0,\n",
       "           0,  14,   0,   0,   0, 160,   2,   0,   0,   6,   0,   0,   0,\n",
       "           8,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   5,\n",
       "           0,   0,   0,   8,   0,   0,   0,   4,   0,   0,   0,   1,   0,\n",
       "           0,   0,   1,   0,   0,   0,   0,   0,   0,   0,  14,   0,   0,\n",
       "           0, 232,   0,   0,   0,   6,   0,   0,   0,   8,   0,   0,   0,\n",
       "           9,   0,   0,   0,   0,   0,   0,   0,   5,   0,   0,   0,   8,\n",
       "           0,   0,   0, 184,   0,   0,   0,   1,   0,   0,   0,   1,   0,\n",
       "           0,   0,   0,   0,   0,   0,   2,   0,   0,   0, 184,   0,   0,\n",
       "           0,   2,   0,   0,   0,   2,   0,   0,   0,  56,   0,   0,   0,\n",
       "          88,   0,   0,   0, 112,   0,   0,   0, 160,   0,   0,   0, 168,\n",
       "           0,   0,   0, 184,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,  97, 110, 121,   0, 115, 116, 114, 105, 110, 103,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   1,   0,   0,\n",
       "           0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "           0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,  14,   0,   0,   0,   0,   0,   0,   0,  14,   0,\n",
       "           0,   0, 200,   0,   0,   0,   6,   0,   0,   0,   8,   0,   0,\n",
       "           0,  15,   0,   0,   0,   0,   0,   0,   0,   5,   0,   0,   0,\n",
       "           8,   0,   0,   0,   1,   0,   0,   0,  19,   0,   0,   0,   1,\n",
       "           0,   0,   0,   0,   0,   0,   0,  13,   0,   0,   0, 152,   0,\n",
       "           0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,\n",
       "           0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "           1,   0,   0,   0,   0,   0,   0,   0,  53,   0,   0,   0,   0,\n",
       "           0,   0,   0,  67,   0,  58,   0,  92,   0,  85,   0, 115,   0,\n",
       "         101,   0, 114,   0, 115,   0,  92,   0, 117,   0, 115,   0, 101,\n",
       "           0, 114,   0,  92,   0,  68,   0, 101,   0, 115,   0, 107,   0,\n",
       "         116,   0, 111,   0, 112,   0,  92,   0,  52,   0,  50,   0,  51,\n",
       "           0,  49,   0,  50,   0,  95,   0,  50,   0,  70,   0,  95,   0,\n",
       "          66,   0,  50,   0,  92,   0,  52,   0,  50,   0,  51,   0,  49,\n",
       "           0,  50,   0,  95,   0,  50,   0,  70,   0,  95,   0, 110,   0,\n",
       "         101,   0, 117,   0, 114,   0, 111,   0, 110,   0,  46,   0, 109,\n",
       "           0,  97,   0, 116,   0,   0,   0,   0,   0,   0,   0,  14,   0,\n",
       "           0,   0, 168,   0,   0,   0,   6,   0,   0,   0,   8,   0,   0,\n",
       "           0,   1,   0,   0,   0,   0,   0,   0,   0,   5,   0,   0,   0,\n",
       "           8,   0,   0,   0,   2,   0,   0,   0,   1,   0,   0,   0,   1,\n",
       "           0,   0,   0,   0,   0,   0,   0,  14,   0,   0,   0,  56,   0,\n",
       "           0,   0,   6,   0,   0,   0,   8,   0,   0,   0,   2,   0,   0,\n",
       "           0,   0,   0,   0,   0,   5,   0,   0,   0,   8,   0,   0,   0,\n",
       "           1,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "           0,   0,   0,   5,   0,   4,   0,   1,   0,   0,   0,   1,   0,\n",
       "           0,   0,   0,   0,   0,   0,  14,   0,   0,   0,  56,   0,   0,\n",
       "           0,   6,   0,   0,   0,   8,   0,   0,   0,   2,   0,   0,   0,\n",
       "           0,   0,   0,   0,   5,   0,   0,   0,   8,   0,   0,   0,   1,\n",
       "           0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "           0,   0,   5,   0,   4,   0,   1,   0,   0,   0,   1,   0,   0,\n",
       "           0,   0,   0,   0,   0,  14,   0,   0,   0, 136,   0,   0,   0,\n",
       "           6,   0,   0,   0,   8,   0,   0,   0,   9,   0,   0,   0,   0,\n",
       "           0,   0,   0,   5,   0,   0,   0,   8,   0,   0,   0,   1,   0,\n",
       "           0,   0,  88,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "           0,   2,   0,   0,   0,  88,   0,   0,   0,   0,   1,  73,  77,\n",
       "           0,   0,   0,   0,  14,   0,   0,   0,  72,   0,   0,   0,   6,\n",
       "           0,   0,   0,   8,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "           0,   0,   5,   0,   0,   0,   8,   0,   0,   0,   1,   0,   0,\n",
       "           0,   1,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "           5,   0,   4,   0,   5,   0,   0,   0,   1,   0,   0,   0,   5,\n",
       "           0,   0,   0,  77,  67,  79,  83,   0,   0,   0,   0,  14,   0,\n",
       "           0,   0,   0,   0,   0,   0]], dtype=uint8)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using matlab function Sources2D_to_simple_mat, I obtain the data.mat file\n",
    "path_data = \"C:\\\\Users\\\\user\\\\Desktop\\\\42312_2F_B2\\\\CNMF-E_mat2npy-master\\\\data.mat\"\n",
    "\n",
    "from os.path import dirname, join as pjoin\n",
    "import scipy.io as sio\n",
    "\n",
    "# this test varible contains the information of the data.mat file \n",
    "neuron_mat_info = sio.loadmat(path_data)\n",
    "neuron_mat_info #python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "500c9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert A from sparse matrix to numpy array. Reshape A to be size [n_neurons, image_y_dim, image_x_dim]\n",
    "A = neuron_mat_info['A'].toarray().reshape([*np.flip(neuron_mat_info['image_size'][0]),-1]).transpose()\n",
    "# Convert S from sparse matrix to numpy array.\n",
    "S = neuron_mat_info['S'].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c1ba6",
   "metadata": {},
   "source": [
    "I can now access all four variables: 'A', 'S', 'C', 'C_raw'\n",
    "(A and S directly, and C/C_raw using neuron_mat_info['C']/neuron_mat_info['C_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3fa3d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape: (232, 265, 357)\n",
      "S shape: (232, 24428)\n",
      "C shape: (232, 24428)\n",
      "C_raw shape: (232, 24428)\n",
      "\n",
      "This data looks ok :)\n",
      "\n",
      "The df_calcium dataframe was created correctly :)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuron_1</th>\n",
       "      <th>neuron_2</th>\n",
       "      <th>neuron_3</th>\n",
       "      <th>neuron_4</th>\n",
       "      <th>neuron_5</th>\n",
       "      <th>neuron_6</th>\n",
       "      <th>neuron_7</th>\n",
       "      <th>neuron_8</th>\n",
       "      <th>neuron_9</th>\n",
       "      <th>neuron_10</th>\n",
       "      <th>...</th>\n",
       "      <th>neuron_223</th>\n",
       "      <th>neuron_224</th>\n",
       "      <th>neuron_225</th>\n",
       "      <th>neuron_226</th>\n",
       "      <th>neuron_227</th>\n",
       "      <th>neuron_228</th>\n",
       "      <th>neuron_229</th>\n",
       "      <th>neuron_230</th>\n",
       "      <th>neuron_231</th>\n",
       "      <th>neuron_232</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.093830</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.533628e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.171160e-01</td>\n",
       "      <td>1.124519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.201754e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.350461e-01</td>\n",
       "      <td>2.214608e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.084705</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.059918e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.365491e-01</td>\n",
       "      <td>1.050021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.785042e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.730429e-01</td>\n",
       "      <td>2.048264e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.076468</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.609746e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.630599e-01</td>\n",
       "      <td>0.980459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.422565e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.225139e-01</td>\n",
       "      <td>1.894414e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.069032</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.181943e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.960265e-01</td>\n",
       "      <td>0.915506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.107265e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.813357e-01</td>\n",
       "      <td>1.752120e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.062319</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.775396e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.348819e-01</td>\n",
       "      <td>0.854855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.833002e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.477780e-01</td>\n",
       "      <td>1.620514e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24423</th>\n",
       "      <td>8.232669e-08</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>4.492108e-10</td>\n",
       "      <td>3.655113e-24</td>\n",
       "      <td>1.046956e-07</td>\n",
       "      <td>0.154305</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>2.391196e-07</td>\n",
       "      <td>0.249795</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>...</td>\n",
       "      <td>2.591648e-29</td>\n",
       "      <td>8.661168e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.543449e-27</td>\n",
       "      <td>3.219191e-67</td>\n",
       "      <td>7.025631e-83</td>\n",
       "      <td>9.603638e-08</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>4.633206e-08</td>\n",
       "      <td>1.556635e-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24424</th>\n",
       "      <td>7.420987e-08</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>4.091745e-10</td>\n",
       "      <td>3.265681e-24</td>\n",
       "      <td>9.949344e-08</td>\n",
       "      <td>0.147256</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>2.181134e-07</td>\n",
       "      <td>0.233247</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>...</td>\n",
       "      <td>2.319320e-29</td>\n",
       "      <td>7.928584e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.706173e-27</td>\n",
       "      <td>2.965726e-67</td>\n",
       "      <td>6.111236e-83</td>\n",
       "      <td>7.725348e-08</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>3.775791e-08</td>\n",
       "      <td>1.439713e-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24425</th>\n",
       "      <td>6.689330e-08</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>3.727064e-10</td>\n",
       "      <td>2.917742e-24</td>\n",
       "      <td>9.454978e-08</td>\n",
       "      <td>0.140529</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1.989526e-07</td>\n",
       "      <td>0.217795</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>...</td>\n",
       "      <td>2.075607e-29</td>\n",
       "      <td>7.257963e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.942354e-27</td>\n",
       "      <td>2.732217e-67</td>\n",
       "      <td>5.315851e-83</td>\n",
       "      <td>6.214417e-08</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>3.077047e-08</td>\n",
       "      <td>1.331573e-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24426</th>\n",
       "      <td>6.029810e-08</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>3.394886e-10</td>\n",
       "      <td>2.606873e-24</td>\n",
       "      <td>8.985176e-08</td>\n",
       "      <td>0.134110</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>1.814750e-07</td>\n",
       "      <td>0.203366</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.857504e-29</td>\n",
       "      <td>6.644066e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.245547e-27</td>\n",
       "      <td>2.517094e-67</td>\n",
       "      <td>4.623987e-83</td>\n",
       "      <td>4.998994e-08</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>2.507613e-08</td>\n",
       "      <td>1.231555e-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24427</th>\n",
       "      <td>5.435314e-08</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>3.092313e-10</td>\n",
       "      <td>2.329126e-24</td>\n",
       "      <td>8.538718e-08</td>\n",
       "      <td>0.127984</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1.655327e-07</td>\n",
       "      <td>0.189894</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>...</td>\n",
       "      <td>1.662319e-29</td>\n",
       "      <td>6.082094e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.609873e-27</td>\n",
       "      <td>2.318908e-67</td>\n",
       "      <td>4.022169e-83</td>\n",
       "      <td>4.021286e-08</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>2.043557e-08</td>\n",
       "      <td>1.139050e-41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24428 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           neuron_1  neuron_2      neuron_3      neuron_4      neuron_5  \\\n",
       "0      0.000000e+00  0.093830  0.000000e+00  0.000000e+00  9.533628e-01   \n",
       "1      0.000000e+00  0.084705  0.000000e+00  0.000000e+00  9.059918e-01   \n",
       "2      0.000000e+00  0.076468  0.000000e+00  0.000000e+00  8.609746e-01   \n",
       "3      0.000000e+00  0.069032  0.000000e+00  0.000000e+00  8.181943e-01   \n",
       "4      0.000000e+00  0.062319  0.000000e+00  0.000000e+00  7.775396e-01   \n",
       "...             ...       ...           ...           ...           ...   \n",
       "24423  8.232669e-08  0.000064  4.492108e-10  3.655113e-24  1.046956e-07   \n",
       "24424  7.420987e-08  0.000058  4.091745e-10  3.265681e-24  9.949344e-08   \n",
       "24425  6.689330e-08  0.000052  3.727064e-10  2.917742e-24  9.454978e-08   \n",
       "24426  6.029810e-08  0.000047  3.394886e-10  2.606873e-24  8.985176e-08   \n",
       "24427  5.435314e-08  0.000043  3.092313e-10  2.329126e-24  8.538718e-08   \n",
       "\n",
       "       neuron_6  neuron_7      neuron_8  neuron_9  neuron_10  ...  \\\n",
       "0      0.000000  0.000000  9.171160e-01  1.124519   0.000000  ...   \n",
       "1      0.000000  0.000000  8.365491e-01  1.050021   0.000000  ...   \n",
       "2      0.000000  0.000000  7.630599e-01  0.980459   0.000000  ...   \n",
       "3      0.000000  0.000000  6.960265e-01  0.915506   0.000000  ...   \n",
       "4      0.000000  0.000000  6.348819e-01  0.854855   0.000000  ...   \n",
       "...         ...       ...           ...       ...        ...  ...   \n",
       "24423  0.154305  0.000170  2.391196e-07  0.249795   0.003817  ...   \n",
       "24424  0.147256  0.000153  2.181134e-07  0.233247   0.003480  ...   \n",
       "24425  0.140529  0.000137  1.989526e-07  0.217795   0.003173  ...   \n",
       "24426  0.134110  0.000124  1.814750e-07  0.203366   0.002892  ...   \n",
       "24427  0.127984  0.000111  1.655327e-07  0.189894   0.002637  ...   \n",
       "\n",
       "         neuron_223    neuron_224  neuron_225    neuron_226    neuron_227  \\\n",
       "0      0.000000e+00  0.000000e+00         0.0  0.000000e+00  0.000000e+00   \n",
       "1      0.000000e+00  0.000000e+00         0.0  0.000000e+00  0.000000e+00   \n",
       "2      0.000000e+00  0.000000e+00         0.0  0.000000e+00  0.000000e+00   \n",
       "3      0.000000e+00  0.000000e+00         0.0  0.000000e+00  0.000000e+00   \n",
       "4      0.000000e+00  0.000000e+00         0.0  0.000000e+00  0.000000e+00   \n",
       "...             ...           ...         ...           ...           ...   \n",
       "24423  2.591648e-29  8.661168e-12         0.0  9.543449e-27  3.219191e-67   \n",
       "24424  2.319320e-29  7.928584e-12         0.0  8.706173e-27  2.965726e-67   \n",
       "24425  2.075607e-29  7.257963e-12         0.0  7.942354e-27  2.732217e-67   \n",
       "24426  1.857504e-29  6.644066e-12         0.0  7.245547e-27  2.517094e-67   \n",
       "24427  1.662319e-29  6.082094e-12         0.0  6.609873e-27  2.318908e-67   \n",
       "\n",
       "         neuron_228    neuron_229  neuron_230    neuron_231    neuron_232  \n",
       "0      3.201754e-01  0.000000e+00    0.000000  3.350461e-01  2.214608e+00  \n",
       "1      2.785042e-01  0.000000e+00    0.000000  2.730429e-01  2.048264e+00  \n",
       "2      2.422565e-01  0.000000e+00    0.000000  2.225139e-01  1.894414e+00  \n",
       "3      2.107265e-01  0.000000e+00    0.000000  1.813357e-01  1.752120e+00  \n",
       "4      1.833002e-01  0.000000e+00    0.000000  1.477780e-01  1.620514e+00  \n",
       "...             ...           ...         ...           ...           ...  \n",
       "24423  7.025631e-83  9.603638e-08    0.001450  4.633206e-08  1.556635e-41  \n",
       "24424  6.111236e-83  7.725348e-08    0.001373  3.775791e-08  1.439713e-41  \n",
       "24425  5.315851e-83  6.214417e-08    0.001301  3.077047e-08  1.331573e-41  \n",
       "24426  4.623987e-83  4.998994e-08    0.001232  2.507613e-08  1.231555e-41  \n",
       "24427  4.022169e-83  4.021286e-08    0.001167  2.043557e-08  1.139050e-41  \n",
       "\n",
       "[24428 rows x 232 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# check if the shapes of the neural data variables are correct\n",
    "print('A shape: {}\\nS shape: {}\\nC shape: {}\\nC_raw shape: {}'.format(A.shape, S.shape, neuron_mat_info['C'].shape, neuron_mat_info['C_raw'].shape))\n",
    "# S, C and C_raw should have the same shape AND shape[0] should be the same for every variable\n",
    "missing_data = True\n",
    "if S.shape == neuron_mat_info['C'].shape == neuron_mat_info['C_raw'].shape and A.shape[0]==S.shape[0]:\n",
    "    missing_data = False\n",
    "    print('\\nThis data looks ok :)')\n",
    "    calcium_length = neuron_mat_info['C_raw'].shape[1]\n",
    "else:\n",
    "    print('There is something wrong with the variable dimensions!') \n",
    "\n",
    "#organize calcium signals in a dataframe\n",
    "df_calcium = pd.DataFrame(neuron_mat_info['C'])\n",
    "df_calcium = df_calcium.T # transpose the calcium data\n",
    "\n",
    "# generate a label for each neuron of the dataframe (e.g.: neuron_1)\n",
    "neuron_labels = []\n",
    "for neuron in range(1, neuron_mat_info['C'].shape[0]+1):\n",
    "    neuron_label = 'neuron_'+str(neuron)\n",
    "    neuron_labels.append(neuron_label)\n",
    "\n",
    "df_calcium.columns = neuron_labels\n",
    "\n",
    "# check if the calcium dataframe was created correctly\n",
    "neuron_data_ready = True\n",
    "for col, i in zip(df_calcium.columns,range(len(df_calcium))):\n",
    "    # sets the test value to False if the dimensions of the dataframe do not coincide with the original data or if a null value is find\n",
    "    if np.sum(df_calcium[col]==neuron_mat_info['C'][i])!=df_calcium.shape[0] or df_calcium.isnull().values.any()==True:\n",
    "        neuron_data_ready = False\n",
    "\n",
    "# print a message to inform the user about the data structures being created   \n",
    "if neuron_data_ready:\n",
    "    print('\\nThe df_calcium dataframe was created correctly :)')    \n",
    "else:\n",
    "    print('\\nThe df_calcium dataframe is not correct :(')\n",
    "    \n",
    "df_calcium # shows the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9490aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The df_calcium_raw dataframe was created correctly :)\n",
      "You can know proceed to step 1.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuron_1</th>\n",
       "      <th>neuron_2</th>\n",
       "      <th>neuron_3</th>\n",
       "      <th>neuron_4</th>\n",
       "      <th>neuron_5</th>\n",
       "      <th>neuron_6</th>\n",
       "      <th>neuron_7</th>\n",
       "      <th>neuron_8</th>\n",
       "      <th>neuron_9</th>\n",
       "      <th>neuron_10</th>\n",
       "      <th>...</th>\n",
       "      <th>neuron_223</th>\n",
       "      <th>neuron_224</th>\n",
       "      <th>neuron_225</th>\n",
       "      <th>neuron_226</th>\n",
       "      <th>neuron_227</th>\n",
       "      <th>neuron_228</th>\n",
       "      <th>neuron_229</th>\n",
       "      <th>neuron_230</th>\n",
       "      <th>neuron_231</th>\n",
       "      <th>neuron_232</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.406129</td>\n",
       "      <td>-0.047769</td>\n",
       "      <td>-0.057460</td>\n",
       "      <td>0.363908</td>\n",
       "      <td>0.062012</td>\n",
       "      <td>-0.822751</td>\n",
       "      <td>0.835407</td>\n",
       "      <td>0.286996</td>\n",
       "      <td>0.556763</td>\n",
       "      <td>-0.122127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398983</td>\n",
       "      <td>-1.269853</td>\n",
       "      <td>-0.617973</td>\n",
       "      <td>-1.433944</td>\n",
       "      <td>0.969161</td>\n",
       "      <td>0.748030</td>\n",
       "      <td>-1.372244</td>\n",
       "      <td>-1.082244</td>\n",
       "      <td>0.977554</td>\n",
       "      <td>0.473264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>-0.324871</td>\n",
       "      <td>-0.469909</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.611437</td>\n",
       "      <td>0.561505</td>\n",
       "      <td>0.250338</td>\n",
       "      <td>0.373676</td>\n",
       "      <td>-0.385733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176969</td>\n",
       "      <td>-1.670347</td>\n",
       "      <td>-0.936837</td>\n",
       "      <td>-0.849302</td>\n",
       "      <td>-1.961589</td>\n",
       "      <td>-0.215606</td>\n",
       "      <td>-6.017899</td>\n",
       "      <td>-1.252409</td>\n",
       "      <td>-1.280463</td>\n",
       "      <td>-0.038383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.232672</td>\n",
       "      <td>0.152491</td>\n",
       "      <td>-0.233984</td>\n",
       "      <td>-0.824166</td>\n",
       "      <td>-0.007191</td>\n",
       "      <td>-1.045340</td>\n",
       "      <td>-0.416938</td>\n",
       "      <td>0.318589</td>\n",
       "      <td>0.219718</td>\n",
       "      <td>-0.661488</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.485928</td>\n",
       "      <td>-2.247127</td>\n",
       "      <td>-0.631697</td>\n",
       "      <td>-1.413440</td>\n",
       "      <td>-1.419651</td>\n",
       "      <td>0.895889</td>\n",
       "      <td>-3.276397</td>\n",
       "      <td>-2.735512</td>\n",
       "      <td>-0.179433</td>\n",
       "      <td>1.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.204936</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>-0.587737</td>\n",
       "      <td>-0.105272</td>\n",
       "      <td>-0.327831</td>\n",
       "      <td>-1.282909</td>\n",
       "      <td>0.467048</td>\n",
       "      <td>0.497779</td>\n",
       "      <td>0.639857</td>\n",
       "      <td>-0.114571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090217</td>\n",
       "      <td>-1.718835</td>\n",
       "      <td>0.740386</td>\n",
       "      <td>-1.475167</td>\n",
       "      <td>-1.177482</td>\n",
       "      <td>1.454110</td>\n",
       "      <td>-0.716491</td>\n",
       "      <td>-1.741940</td>\n",
       "      <td>0.630301</td>\n",
       "      <td>2.266293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216542</td>\n",
       "      <td>0.446695</td>\n",
       "      <td>-0.752110</td>\n",
       "      <td>0.037540</td>\n",
       "      <td>0.767937</td>\n",
       "      <td>-1.651113</td>\n",
       "      <td>0.112862</td>\n",
       "      <td>0.181789</td>\n",
       "      <td>0.654617</td>\n",
       "      <td>0.074972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276067</td>\n",
       "      <td>-1.530954</td>\n",
       "      <td>-0.060764</td>\n",
       "      <td>-0.280535</td>\n",
       "      <td>-2.012925</td>\n",
       "      <td>-1.225314</td>\n",
       "      <td>-2.756372</td>\n",
       "      <td>-3.164117</td>\n",
       "      <td>-0.346409</td>\n",
       "      <td>-0.164486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24423</th>\n",
       "      <td>-0.606995</td>\n",
       "      <td>-0.552580</td>\n",
       "      <td>-0.934403</td>\n",
       "      <td>-0.618884</td>\n",
       "      <td>-2.043891</td>\n",
       "      <td>-1.437259</td>\n",
       "      <td>-0.574520</td>\n",
       "      <td>1.253711</td>\n",
       "      <td>-0.245027</td>\n",
       "      <td>-1.232674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686536</td>\n",
       "      <td>0.510395</td>\n",
       "      <td>-3.247753</td>\n",
       "      <td>0.143374</td>\n",
       "      <td>-0.256309</td>\n",
       "      <td>-0.573839</td>\n",
       "      <td>-2.012565</td>\n",
       "      <td>3.037851</td>\n",
       "      <td>-0.055204</td>\n",
       "      <td>0.954875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24424</th>\n",
       "      <td>-0.668474</td>\n",
       "      <td>-0.280622</td>\n",
       "      <td>-0.391308</td>\n",
       "      <td>-0.685432</td>\n",
       "      <td>-1.489544</td>\n",
       "      <td>-0.054729</td>\n",
       "      <td>-0.770300</td>\n",
       "      <td>0.841639</td>\n",
       "      <td>-1.313490</td>\n",
       "      <td>-0.770342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154207</td>\n",
       "      <td>0.860610</td>\n",
       "      <td>-2.451428</td>\n",
       "      <td>-0.537583</td>\n",
       "      <td>-1.589599</td>\n",
       "      <td>-2.384969</td>\n",
       "      <td>-2.347676</td>\n",
       "      <td>1.410373</td>\n",
       "      <td>-2.515940</td>\n",
       "      <td>2.618795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24425</th>\n",
       "      <td>-0.100028</td>\n",
       "      <td>-0.094912</td>\n",
       "      <td>-0.734686</td>\n",
       "      <td>-0.449700</td>\n",
       "      <td>-0.352617</td>\n",
       "      <td>-0.470470</td>\n",
       "      <td>-0.366492</td>\n",
       "      <td>0.997039</td>\n",
       "      <td>-2.603229</td>\n",
       "      <td>-1.598287</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184539</td>\n",
       "      <td>0.594848</td>\n",
       "      <td>-2.265827</td>\n",
       "      <td>-1.628178</td>\n",
       "      <td>-0.274957</td>\n",
       "      <td>-0.419261</td>\n",
       "      <td>-1.267465</td>\n",
       "      <td>1.117916</td>\n",
       "      <td>-1.171862</td>\n",
       "      <td>-0.123528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24426</th>\n",
       "      <td>-0.306220</td>\n",
       "      <td>-0.282234</td>\n",
       "      <td>-0.047338</td>\n",
       "      <td>-0.599466</td>\n",
       "      <td>-0.416913</td>\n",
       "      <td>-0.135880</td>\n",
       "      <td>0.022544</td>\n",
       "      <td>1.120818</td>\n",
       "      <td>-2.561249</td>\n",
       "      <td>-1.232654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626100</td>\n",
       "      <td>-0.183535</td>\n",
       "      <td>-1.211899</td>\n",
       "      <td>-1.536372</td>\n",
       "      <td>-0.808840</td>\n",
       "      <td>0.505041</td>\n",
       "      <td>-0.668510</td>\n",
       "      <td>0.933554</td>\n",
       "      <td>-2.377353</td>\n",
       "      <td>-0.553212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24427</th>\n",
       "      <td>-0.403363</td>\n",
       "      <td>0.147405</td>\n",
       "      <td>-0.032576</td>\n",
       "      <td>-0.558049</td>\n",
       "      <td>-0.628802</td>\n",
       "      <td>1.717038</td>\n",
       "      <td>0.312313</td>\n",
       "      <td>0.536609</td>\n",
       "      <td>-2.283960</td>\n",
       "      <td>-1.146639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.639934</td>\n",
       "      <td>1.247509</td>\n",
       "      <td>-1.491128</td>\n",
       "      <td>-0.429262</td>\n",
       "      <td>1.073810</td>\n",
       "      <td>0.659075</td>\n",
       "      <td>-0.190238</td>\n",
       "      <td>0.188705</td>\n",
       "      <td>-2.226127</td>\n",
       "      <td>-0.345149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24428 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       neuron_1  neuron_2  neuron_3  neuron_4  neuron_5  neuron_6  neuron_7  \\\n",
       "0     -0.406129 -0.047769 -0.057460  0.363908  0.062012 -0.822751  0.835407   \n",
       "1      0.183007  0.064286 -0.324871 -0.469909  0.858696  0.611437  0.561505   \n",
       "2     -0.232672  0.152491 -0.233984 -0.824166 -0.007191 -1.045340 -0.416938   \n",
       "3     -0.204936  0.007840 -0.587737 -0.105272 -0.327831 -1.282909  0.467048   \n",
       "4      0.216542  0.446695 -0.752110  0.037540  0.767937 -1.651113  0.112862   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24423 -0.606995 -0.552580 -0.934403 -0.618884 -2.043891 -1.437259 -0.574520   \n",
       "24424 -0.668474 -0.280622 -0.391308 -0.685432 -1.489544 -0.054729 -0.770300   \n",
       "24425 -0.100028 -0.094912 -0.734686 -0.449700 -0.352617 -0.470470 -0.366492   \n",
       "24426 -0.306220 -0.282234 -0.047338 -0.599466 -0.416913 -0.135880  0.022544   \n",
       "24427 -0.403363  0.147405 -0.032576 -0.558049 -0.628802  1.717038  0.312313   \n",
       "\n",
       "       neuron_8  neuron_9  neuron_10  ...  neuron_223  neuron_224  neuron_225  \\\n",
       "0      0.286996  0.556763  -0.122127  ...    0.398983   -1.269853   -0.617973   \n",
       "1      0.250338  0.373676  -0.385733  ...   -0.176969   -1.670347   -0.936837   \n",
       "2      0.318589  0.219718  -0.661488  ...   -0.485928   -2.247127   -0.631697   \n",
       "3      0.497779  0.639857  -0.114571  ...    0.090217   -1.718835    0.740386   \n",
       "4      0.181789  0.654617   0.074972  ...   -0.276067   -1.530954   -0.060764   \n",
       "...         ...       ...        ...  ...         ...         ...         ...   \n",
       "24423  1.253711 -0.245027  -1.232674  ...    0.686536    0.510395   -3.247753   \n",
       "24424  0.841639 -1.313490  -0.770342  ...   -0.154207    0.860610   -2.451428   \n",
       "24425  0.997039 -2.603229  -1.598287  ...   -0.184539    0.594848   -2.265827   \n",
       "24426  1.120818 -2.561249  -1.232654  ...   -0.626100   -0.183535   -1.211899   \n",
       "24427  0.536609 -2.283960  -1.146639  ...   -0.639934    1.247509   -1.491128   \n",
       "\n",
       "       neuron_226  neuron_227  neuron_228  neuron_229  neuron_230  neuron_231  \\\n",
       "0       -1.433944    0.969161    0.748030   -1.372244   -1.082244    0.977554   \n",
       "1       -0.849302   -1.961589   -0.215606   -6.017899   -1.252409   -1.280463   \n",
       "2       -1.413440   -1.419651    0.895889   -3.276397   -2.735512   -0.179433   \n",
       "3       -1.475167   -1.177482    1.454110   -0.716491   -1.741940    0.630301   \n",
       "4       -0.280535   -2.012925   -1.225314   -2.756372   -3.164117   -0.346409   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "24423    0.143374   -0.256309   -0.573839   -2.012565    3.037851   -0.055204   \n",
       "24424   -0.537583   -1.589599   -2.384969   -2.347676    1.410373   -2.515940   \n",
       "24425   -1.628178   -0.274957   -0.419261   -1.267465    1.117916   -1.171862   \n",
       "24426   -1.536372   -0.808840    0.505041   -0.668510    0.933554   -2.377353   \n",
       "24427   -0.429262    1.073810    0.659075   -0.190238    0.188705   -2.226127   \n",
       "\n",
       "       neuron_232  \n",
       "0        0.473264  \n",
       "1       -0.038383  \n",
       "2        1.087864  \n",
       "3        2.266293  \n",
       "4       -0.164486  \n",
       "...           ...  \n",
       "24423    0.954875  \n",
       "24424    2.618795  \n",
       "24425   -0.123528  \n",
       "24426   -0.553212  \n",
       "24427   -0.345149  \n",
       "\n",
       "[24428 rows x 232 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the same as the previous cell but for raw data\n",
    "import pandas as pd\n",
    "\n",
    "#organize raw calcium signals in a dataframe\n",
    "df_calcium_raw = pd.DataFrame(neuron_mat_info['C_raw'])\n",
    "df_calcium_raw = df_calcium_raw.T\n",
    "\n",
    "neuron_labels = []\n",
    "for neuron in range(1, neuron_mat_info['C_raw'].shape[0]+1):\n",
    "    neuron_label = 'neuron_'+str(neuron)\n",
    "    neuron_labels.append(neuron_label)\n",
    "\n",
    "df_calcium_raw.columns = neuron_labels\n",
    "\n",
    "raw_neuron_data_ready = True\n",
    "for col, i in zip(df_calcium_raw.columns,range(len(df_calcium_raw))):\n",
    "    if np.sum(df_calcium_raw[col]==neuron_mat_info['C_raw'][i])!=df_calcium_raw.shape[0] or df_calcium_raw.isnull().values.any()==True:\n",
    "        raw_neuron_data_ready=False\n",
    "    \n",
    "if raw_neuron_data_ready:\n",
    "    print('\\nThe df_calcium_raw dataframe was created correctly :)')\n",
    "    print('You can know proceed to step 1.2')\n",
    "    \n",
    "else:\n",
    "    print('\\nThe df_calcium dataframe is not correct :(')\n",
    "    \n",
    "df_calcium_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6603a0",
   "metadata": {},
   "source": [
    "## 1.2 Import acceldata.csv \n",
    "This is the file that contains the timestamps of all the hardware used in a session.\n",
    "\n",
    "**Useful information**:\n",
    "\n",
    "'Command' of interest - 3\n",
    "\n",
    "'RegisterAddress':\n",
    "- 34 - Accelerometer (sampling_rate = 200 Hz)\n",
    "- 37 - Camera (sampling_rate = 30 Hz)\n",
    "- 35 - Inscopix (sampling_rate = 20 Hz)\n",
    "\n",
    "In this sections, I organize the data from the acceldata.cvs file, and test all the timestamps to make sure you can follow through with the analysis.\n",
    "\n",
    "I seperately check the data from: Accelerometer, Camera and Microscope (Inscopix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1feedcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4aad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_acceldata = \"C:\\\\Users\\\\user\\\\Desktop\\\\42312_2F_B2\\\\AccelData2021-04-29T16_15_11.3801984+01_00.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44879aac",
   "metadata": {},
   "source": [
    "##### Accel data AND timestamps..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a474ef",
   "metadata": {},
   "source": [
    " With this dataframe I will start by ansewring the following question:\n",
    " Are the timestamps of this dataframe in agreement with the dimensions of the data from the following dataframes?\n",
    "\n",
    " If NO, ..let the user know (print ERROR messages, and set flags in the locations where the error was found) - the flags part is not implemented yet\n",
    "\n",
    " Finally, once everything is checked, I can start the analysis itself namely seeing which initiations detected from the    accelerometer involve the lesioned paw and checking the calcium traces in those cases versus a movement that does not involve the right paw (e.g. moving the head while standing still, initiation with the left paw, for example)\n",
    "\n",
    " The data that is going to be used for further analysis is from the first to the last '35', corresponding to the time during which all three channels are ON. The first '35' corresponds to the first TTL from the Inscopix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77865380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Command</th>\n",
       "      <th>RegisterAddress</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>DataElement0</th>\n",
       "      <th>Accel_y</th>\n",
       "      <th>Accel_z</th>\n",
       "      <th>Gyr_x</th>\n",
       "      <th>Gyr_y</th>\n",
       "      <th>Gyr_z</th>\n",
       "      <th>Magn_x</th>\n",
       "      <th>Magn_y</th>\n",
       "      <th>Magn_z</th>\n",
       "      <th>Counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>275355.4745</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275355.4745</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>275355.4755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>275355.4765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>275355.4775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338951</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3542</td>\n",
       "      <td>-5050.0</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>-6524.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-318.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338952</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3598</td>\n",
       "      <td>-5099.0</td>\n",
       "      <td>2960.0</td>\n",
       "      <td>-6369.0</td>\n",
       "      <td>-272.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-319.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338953</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3642</td>\n",
       "      <td>-5076.0</td>\n",
       "      <td>3003.0</td>\n",
       "      <td>-6238.0</td>\n",
       "      <td>-498.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-319.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338954</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3698</td>\n",
       "      <td>-4942.0</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>-6142.0</td>\n",
       "      <td>-577.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-318.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338955</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3742</td>\n",
       "      <td>-4720.0</td>\n",
       "      <td>3087.0</td>\n",
       "      <td>-6194.0</td>\n",
       "      <td>-566.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-318.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338956 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Command  RegisterAddress    Timestamp  DataElement0  Accel_y  Accel_z  \\\n",
       "0           2.0             10.0  275355.4745         225.0      NaN      NaN   \n",
       "1           1.0              0.0  275355.4745        1056.0      NaN      NaN   \n",
       "2           1.0             32.0  275355.4755           0.0      NaN      NaN   \n",
       "3           1.0              1.0  275355.4765           1.0      NaN      NaN   \n",
       "4           1.0             33.0  275355.4775           0.0      NaN      NaN   \n",
       "...         ...              ...          ...           ...      ...      ...   \n",
       "338951      3.0             34.0  276636.3542       -5050.0   2999.0  -6524.0   \n",
       "338952      3.0             34.0  276636.3598       -5099.0   2960.0  -6369.0   \n",
       "338953      3.0             34.0  276636.3642       -5076.0   3003.0  -6238.0   \n",
       "338954      3.0             34.0  276636.3698       -4942.0   3035.0  -6142.0   \n",
       "338955      3.0             34.0  276636.3742       -4720.0   3087.0  -6194.0   \n",
       "\n",
       "        Gyr_x  Gyr_y   Gyr_z  Magn_x  Magn_y  Magn_z  Counter  \n",
       "0         NaN    NaN     NaN     NaN     NaN     NaN      NaN  \n",
       "1         NaN    NaN     NaN     NaN     NaN     NaN      NaN  \n",
       "2         NaN    NaN     NaN     NaN     NaN     NaN      NaN  \n",
       "3         NaN    NaN     NaN     NaN     NaN     NaN      NaN  \n",
       "4         NaN    NaN     NaN     NaN     NaN     NaN      NaN  \n",
       "...       ...    ...     ...     ...     ...     ...      ...  \n",
       "338951  -65.0  696.0   396.0   114.0   275.0  -318.0     28.0  \n",
       "338952 -272.0  436.0   649.0   115.0   275.0  -319.0     29.0  \n",
       "338953 -498.0  355.0   868.0   115.0   275.0  -319.0     30.0  \n",
       "338954 -577.0  492.0  1140.0   115.0   275.0  -318.0     31.0  \n",
       "338955 -566.0  659.0  1394.0   115.0   275.0  -318.0     32.0  \n",
       "\n",
       "[338956 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv, numpy\n",
    "\n",
    "def convert(val): \n",
    "    try:\n",
    "        return float(val)\n",
    "    except:\n",
    "        return val\n",
    "\n",
    "with open(path_acceldata, 'r') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    values = []\n",
    "    max_cols = 0\n",
    "    for index, row in enumerate(spamreader):\n",
    "        if index==0: continue\n",
    "        row = list(map(convert, row))\n",
    "        if len(row)>max_cols: max_cols=len(row)\n",
    "        values.append(row)\n",
    "\n",
    "    matrix = []\n",
    "    for row in values:\n",
    "        row = row + [None for x in range(max_cols-len(row))]\n",
    "        matrix.append(row)\n",
    "\n",
    "    matrix = numpy.array(matrix)\n",
    "    \n",
    "matrix_columns = ['Command', 'RegisterAddress', 'Timestamp', \n",
    "                  'DataElement0', 'Accel_y','Accel_z', \n",
    "                  'Gyr_x','Gyr_y', 'Gyr_z', \n",
    "                  'Magn_x', 'Magn_y', 'Magn_z', \n",
    "                  'Counter', \n",
    "                  'col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28']\n",
    "\n",
    "df_acceldata = pd.DataFrame(matrix, columns = matrix_columns)\n",
    "df_acceldata = df_acceldata.apply(pd.to_numeric)\n",
    "to_drop = ['col_14', 'col_15', 'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21', 'col_22', 'col_23', 'col_24', 'col_25', 'col_26', 'col_27', 'col_28']\n",
    "df_acceldata = df_acceldata.drop(columns = to_drop)\n",
    "df_acceldata #this dataframe contains all the timestamps (camera, inscopix and accelerometer), as well as the accel data itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45999c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any null/none values in the x, y, or z acceldata?: False\n",
      "No null values were found in the accelerometer data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Command</th>\n",
       "      <th>RegisterAddress</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>DataElement0</th>\n",
       "      <th>Accel_y</th>\n",
       "      <th>Accel_z</th>\n",
       "      <th>Gyr_x</th>\n",
       "      <th>Gyr_y</th>\n",
       "      <th>Gyr_z</th>\n",
       "      <th>Magn_x</th>\n",
       "      <th>Magn_y</th>\n",
       "      <th>Magn_z</th>\n",
       "      <th>Counter</th>\n",
       "      <th>Total_accel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>275399.3275</td>\n",
       "      <td>-4891.0</td>\n",
       "      <td>-1286.0</td>\n",
       "      <td>-7312.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-938.0</td>\n",
       "      <td>-2673.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>-278.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>733.448416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>275399.3319</td>\n",
       "      <td>-5877.0</td>\n",
       "      <td>-1316.0</td>\n",
       "      <td>-6562.0</td>\n",
       "      <td>-1274.0</td>\n",
       "      <td>-2232.0</td>\n",
       "      <td>-2851.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>-278.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>865.564038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>275399.3375</td>\n",
       "      <td>-5918.0</td>\n",
       "      <td>-967.0</td>\n",
       "      <td>-6590.0</td>\n",
       "      <td>-2452.0</td>\n",
       "      <td>-3060.0</td>\n",
       "      <td>-3197.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>-274.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1024.107257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>275399.3419</td>\n",
       "      <td>-5806.0</td>\n",
       "      <td>-976.0</td>\n",
       "      <td>-6522.0</td>\n",
       "      <td>-2654.0</td>\n",
       "      <td>-3187.0</td>\n",
       "      <td>-3237.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>-274.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1011.194796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>275399.3475</td>\n",
       "      <td>-5985.0</td>\n",
       "      <td>-1261.0</td>\n",
       "      <td>-6424.0</td>\n",
       "      <td>-2368.0</td>\n",
       "      <td>-2861.0</td>\n",
       "      <td>-3035.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>-275.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>887.892693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247592</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3542</td>\n",
       "      <td>-5050.0</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>-6524.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-318.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>618.093446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247593</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3598</td>\n",
       "      <td>-5099.0</td>\n",
       "      <td>2960.0</td>\n",
       "      <td>-6369.0</td>\n",
       "      <td>-272.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-319.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>466.401927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247594</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3642</td>\n",
       "      <td>-5076.0</td>\n",
       "      <td>3003.0</td>\n",
       "      <td>-6238.0</td>\n",
       "      <td>-498.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-319.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>377.978456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247595</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3698</td>\n",
       "      <td>-4942.0</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>-6142.0</td>\n",
       "      <td>-577.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-318.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>285.678038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247596</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276636.3742</td>\n",
       "      <td>-4720.0</td>\n",
       "      <td>3087.0</td>\n",
       "      <td>-6194.0</td>\n",
       "      <td>-566.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>-318.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>225.200971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247597 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Command  RegisterAddress    Timestamp  DataElement0  Accel_y  Accel_z  \\\n",
       "0           3.0             34.0  275399.3275       -4891.0  -1286.0  -7312.0   \n",
       "1           3.0             34.0  275399.3319       -5877.0  -1316.0  -6562.0   \n",
       "2           3.0             34.0  275399.3375       -5918.0   -967.0  -6590.0   \n",
       "3           3.0             34.0  275399.3419       -5806.0   -976.0  -6522.0   \n",
       "4           3.0             34.0  275399.3475       -5985.0  -1261.0  -6424.0   \n",
       "...         ...              ...          ...           ...      ...      ...   \n",
       "247592      3.0             34.0  276636.3542       -5050.0   2999.0  -6524.0   \n",
       "247593      3.0             34.0  276636.3598       -5099.0   2960.0  -6369.0   \n",
       "247594      3.0             34.0  276636.3642       -5076.0   3003.0  -6238.0   \n",
       "247595      3.0             34.0  276636.3698       -4942.0   3035.0  -6142.0   \n",
       "247596      3.0             34.0  276636.3742       -4720.0   3087.0  -6194.0   \n",
       "\n",
       "         Gyr_x   Gyr_y   Gyr_z  Magn_x  Magn_y  Magn_z  Counter  Total_accel  \n",
       "0        -64.0  -938.0 -2673.0    59.0   301.0  -278.0     91.0   733.448416  \n",
       "1      -1274.0 -2232.0 -2851.0    59.0   301.0  -278.0     92.0   865.564038  \n",
       "2      -2452.0 -3060.0 -3197.0    60.0   301.0  -274.0     93.0  1024.107257  \n",
       "3      -2654.0 -3187.0 -3237.0    60.0   301.0  -274.0     94.0  1011.194796  \n",
       "4      -2368.0 -2861.0 -3035.0    61.0   302.0  -275.0     95.0   887.892693  \n",
       "...        ...     ...     ...     ...     ...     ...      ...          ...  \n",
       "247592   -65.0   696.0   396.0   114.0   275.0  -318.0     28.0   618.093446  \n",
       "247593  -272.0   436.0   649.0   115.0   275.0  -319.0     29.0   466.401927  \n",
       "247594  -498.0   355.0   868.0   115.0   275.0  -319.0     30.0   377.978456  \n",
       "247595  -577.0   492.0  1140.0   115.0   275.0  -318.0     31.0   285.678038  \n",
       "247596  -566.0   659.0  1394.0   115.0   275.0  -318.0     32.0   225.200971  \n",
       "\n",
       "[247597 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with the accel data exclusively (command=3 and register address = 34)\n",
    "df_acceldata_accel = df_acceldata.loc[df_acceldata['Command'] == 3].loc[df_acceldata['RegisterAddress'] == 34]\n",
    "\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "fs = 200 #sampling frequency\n",
    "f_cut = 1/(fs/2)\n",
    "\n",
    "filter_order = 5\n",
    "b, a = signal.butter(filter_order, f_cut, 'high')\n",
    "w, h = signal.freqs(b, a)\n",
    "\n",
    "#DataElement0 corresponds to Accel_x\n",
    "x = df_acceldata_accel['DataElement0']\n",
    "y = df_acceldata_accel['Accel_y']\n",
    "z = df_acceldata_accel['Accel_z']\n",
    "\n",
    "medfilt_order = 7\n",
    "x = signal.medfilt(x, medfilt_order)\n",
    "y = signal.medfilt(y, medfilt_order)\n",
    "z = signal.medfilt(z, medfilt_order)\n",
    "\n",
    "x_BA = signal.filtfilt(b, a, x)\n",
    "y_BA = signal.filtfilt(b, a, y)\n",
    "z_BA = signal.filtfilt(b, a, z)\n",
    "\n",
    "array_sum_x = np.sum(x)\n",
    "array_has_nan_x = np.isnan(array_sum_x)\n",
    "\n",
    "array_sum_y = np.sum(y)\n",
    "array_has_nan_y = np.isnan(array_sum_y)\n",
    "\n",
    "array_sum_z = np.sum(z)\n",
    "array_has_nan_z = np.isnan(array_sum_z)\n",
    "\n",
    "print('Are there any null/none values in the x, y, or z acceldata?: {}'.format(array_has_nan_x+array_has_nan_y+array_has_nan_z))\n",
    "if array_has_nan_x+array_has_nan_y+array_has_nan_z == False:\n",
    "    print('No null values were found in the accelerometer data.')\n",
    "\n",
    "x_GA = x - x_BA \n",
    "y_GA = y - y_BA\n",
    "z_GA = z - z_BA\n",
    "\n",
    "# metric: high-pass filter followed by the euclidian norm\n",
    "# the original signal consisted in the three components of ...\n",
    "# body+gravitational acceleration. After applying a filter, I computed the\n",
    "# total body acceleration, from which movement initiations will be detected\n",
    "# euclidian norm/vector magnitude\n",
    "total_bodyaccel = np.sqrt(x_BA**2+y_BA**2+z_BA**2)\n",
    "plt.plot(total_bodyaccel)\n",
    "\n",
    "df_acceldata_accel['Total_accel'] = total_bodyaccel\n",
    "df_acceldata_accel = df_acceldata_accel[['Command', 'RegisterAddress', 'Timestamp', \n",
    "                                         'DataElement0', 'Accel_y', 'Accel_z', \n",
    "                                         'Gyr_x', 'Gyr_y', 'Gyr_z', \n",
    "                                         'Magn_x', 'Magn_y', 'Magn_z', \n",
    "                                         'Counter', \n",
    "                                         'Total_accel']]\n",
    "\n",
    "\n",
    "df_acceldata_accel.reset_index(inplace = True, drop = True)\n",
    "df_acceldata_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e19dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the counter goes from 0 to 127, so by ploting the diff() it should be 1, 126 times followed by a -127, 1 time (repeated)\n",
    "# any deviation from this pattern, means data loss, so lets find instances\n",
    "# where counter.diff is different from 1 or -127!\n",
    "\n",
    "# add 'ghost' rows,do a linear interpolation of the accel data in those rows so that no problem arises in the psth plots??\n",
    "# add a flag to mark regions of the plot where data is missing?? (maybe not necessary since we are using the timestamps\n",
    "# as the x axis!!!)\n",
    "\n",
    "lost_data = df_acceldata_accel['Counter'].diff()\n",
    "\n",
    "for i in range(len(lost_data)):\n",
    "    if lost_data[i] == 1:\n",
    "        lost_data[i] = 0\n",
    "    elif lost_data[i] == -127:\n",
    "        lost_data[i] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01924214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228c3a4bc40>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(lost_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea556584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228adddcee0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(df_acceldata_accel['DataElement0']) # Accel_x\n",
    "plt.plot(df_acceldata_accel['Accel_y'])\n",
    "plt.plot(df_acceldata_accel['Accel_z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6cbdd840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228add493f0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(df_acceldata_accel['Total_accel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0d2fc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some accel data was lost. This should not be problematic since the timestamps (x) will be used to plot the accel data (y). This means that, when plotting, the lost data will be linearly interpolated.\n",
      "\n",
      "Now, let's check the timestamps from the camera!\n"
     ]
    }
   ],
   "source": [
    "# final test to proceed for the camera and inscopix data (not really a test, more of a warning)\n",
    "accel_TTL_correct = False\n",
    "if sum(lost_data[1:]) > 0:\n",
    "    accel_TTL_correct = True\n",
    "    print('Some accel data was lost. This should not be problematic since the timestamps (x) will be used to plot the accel data (y). This means that, when plotting, the lost data will be linearly interpolated.')\n",
    "    print('\\nNow, let\\'s check the timestamps from the camera!')\n",
    "elif  sum(lost_data[1:]) == 0:\n",
    "    accel_TTL_correct = True\n",
    "    print('No lost data :). Now, let\\'s check the timestamps from the camera!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2381f6",
   "metadata": {},
   "source": [
    "I need to perform the interpolation in this step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056553d",
   "metadata": {},
   "source": [
    "#####  Camera timestamps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74a3dbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The camera timestamps are correct. No frames were dropped :)\n",
      "Now, let's check the timestamps from the Inscopix!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Command</th>\n",
       "      <th>RegisterAddress</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>DataElement0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>275399.3020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>275399.3354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>275399.3687</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>275399.4020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>275399.4354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37109</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>276636.2192</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37110</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>276636.2525</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37111</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>276636.2859</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37112</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>276636.3192</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37113</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>276636.3525</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37114 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Command  RegisterAddress    Timestamp  DataElement0\n",
       "0          3.0             37.0  275399.3020           1.0\n",
       "1          3.0             37.0  275399.3354           1.0\n",
       "2          3.0             37.0  275399.3687           1.0\n",
       "3          3.0             37.0  275399.4020           1.0\n",
       "4          3.0             37.0  275399.4354           1.0\n",
       "...        ...              ...          ...           ...\n",
       "37109      3.0             37.0  276636.2192           1.0\n",
       "37110      3.0             37.0  276636.2525           1.0\n",
       "37111      3.0             37.0  276636.2859           1.0\n",
       "37112      3.0             37.0  276636.3192           1.0\n",
       "37113      3.0             37.0  276636.3525           1.0\n",
       "\n",
       "[37114 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the following steps I will need to check if the lenght of this df\n",
    "# is coherent with the onces from DLC predictions, frame diff and velocities\n",
    "\n",
    "# keep in mind that it is possible for the last TTL to have no correspondant frame (the TTL may have been send but the frame \n",
    "# was not recorded, for example) - furthermore, it is only problematic when the 'missing frame' is between the first and last\n",
    "# inscopix TTL's, since that is the region that counts for the session (inscopix, camera and accel - ON)\n",
    "\n",
    "df_acceldata_camera = df_acceldata.loc[df_acceldata['Command'] == 3].loc[df_acceldata['RegisterAddress'] == 37]\n",
    "\n",
    "import math\n",
    "\n",
    "camera_aq_rate = 30 #Hz\n",
    "camera_period = round(1/camera_aq_rate, 3)\n",
    "\n",
    "df_acceldata_camera = df_acceldata_camera[['Command','RegisterAddress','Timestamp','DataElement0']]\n",
    "df_acceldata_camera = df_acceldata_camera.reset_index(drop=True)\n",
    "\n",
    "camera_TTL_correct_temp = True\n",
    "for camera_TTL in range(1,len(df_acceldata_camera)):\n",
    "    if round(df_acceldata_camera['Timestamp'].diff()[camera_TTL], 2) != round(camera_period, 2):\n",
    "        print('A frame was lost here :(')\n",
    "        camera_TTL_correct_temp = False\n",
    "if camera_TTL_correct_temp:\n",
    "    print('The camera timestamps are correct. No frames were dropped :)')\n",
    "    print('Now, let\\'s check the timestamps from the Inscopix!')\n",
    "    \n",
    "df_acceldata_camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4c1dc",
   "metadata": {},
   "source": [
    "##### Inscopix timestamps...\n",
    "\n",
    "This needs to match the neuron.mat data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c254d225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data matches the data from the neuron.mat file :)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Command</th>\n",
       "      <th>RegisterAddress</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>DataElement0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>275406.7676</td>\n",
       "      <td>16416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>275406.7926</td>\n",
       "      <td>32801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>275406.8176</td>\n",
       "      <td>16419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>275406.8426</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>275406.8676</td>\n",
       "      <td>16418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>276628.3436</td>\n",
       "      <td>33883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>276628.3686</td>\n",
       "      <td>17501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>276628.3936</td>\n",
       "      <td>1116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48854</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>276628.4187</td>\n",
       "      <td>17501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48855</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>276628.4436</td>\n",
       "      <td>33884.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48856 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Command  RegisterAddress    Timestamp  DataElement0\n",
       "0          3.0             35.0  275406.7676       16416.0\n",
       "1          3.0             35.0  275406.7926       32801.0\n",
       "2          3.0             35.0  275406.8176       16419.0\n",
       "3          3.0             35.0  275406.8426          32.0\n",
       "4          3.0             35.0  275406.8676       16418.0\n",
       "...        ...              ...          ...           ...\n",
       "48851      3.0             35.0  276628.3436       33883.0\n",
       "48852      3.0             35.0  276628.3686       17501.0\n",
       "48853      3.0             35.0  276628.3936        1116.0\n",
       "48854      3.0             35.0  276628.4187       17501.0\n",
       "48855      3.0             35.0  276628.4436       33884.0\n",
       "\n",
       "[48856 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "df_acceldata_inscopix = df_acceldata.loc[df_acceldata['Command'] == 3].loc[df_acceldata['RegisterAddress'] == 35]\n",
    "\n",
    "inscopix_aq_rate = 20 #Hz\n",
    "inscopix_period = round(1/inscopix_aq_rate, 3)\n",
    "\n",
    "df_acceldata_inscopix = df_acceldata_inscopix.reset_index(drop=True)\n",
    "df_acceldata_inscopix = df_acceldata_inscopix[['Command','RegisterAddress','Timestamp','DataElement0']]\n",
    "\n",
    "inscopix_aq_rate = 20 #Hz\n",
    "inscopix_period = round(1/inscopix_aq_rate, 3)\n",
    "\n",
    "df_acceldata_inscopix = df_acceldata_inscopix.reset_index(drop=True)\n",
    "\n",
    "inscopix_TTL_correct = True\n",
    "for inscopix_TTL in range(1,len(df_acceldata_inscopix)):\n",
    "    if round(df_acceldata_inscopix['Timestamp'].diff()[inscopix_TTL], 3) != inscopix_period/2:\n",
    "        print('Some TTL is missing :(')\n",
    "        inscopix_TTL_correct = False\n",
    "    \n",
    "# I also need to check if the dimensions of the neuron data fit this \n",
    "# ...timestamps\n",
    "if len(df_acceldata_inscopix[::2]) != calcium_length:\n",
    "    inscopix_TTL_correct = False\n",
    "    print('This data is not matching the neuron.mat data :(')\n",
    "else:\n",
    "    print('This data matches the data from the neuron.mat file :)')\n",
    "\n",
    "df_acceldata_inscopix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1599db",
   "metadata": {},
   "source": [
    "##### Add timestamps to the 'neuron.mat' data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b23ee9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inscopix_ts = df_acceldata['Timestamp'].loc[df_acceldata['Command']==3].loc[df_acceldata['RegisterAddress']==35][::2]\n",
    "df_inscopix_ts.reset_index(inplace = True, drop = True)\n",
    "df_calcium['Timestamp'] = df_inscopix_ts\n",
    "df_calcium_raw['Timestamp'] = df_inscopix_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8487123f",
   "metadata": {},
   "source": [
    "## 1.3 Import FrameDiff_Centroid.csv \n",
    "This file is important to check for lost frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ebf8e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frames were dropped :)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37107</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37108</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37109</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37110</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37111</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37112 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Frame diff\n",
       "0               1\n",
       "1               1\n",
       "2               1\n",
       "3               1\n",
       "4               1\n",
       "...           ...\n",
       "37107           1\n",
       "37108           1\n",
       "37109           1\n",
       "37110           1\n",
       "37111           1\n",
       "\n",
       "[37112 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_framediff = \"C:\\\\Users\\\\user\\\\Desktop\\\\42312_2F_B2\\\\FrameDiff_Centroid2021-04-29T16_15_11.csv\"\n",
    "df_framediff = pd.read_csv(path_framediff, header=None)\n",
    "df_framediff.rename(columns={0:'Frame diff'})\n",
    "\n",
    "camera_TTL_correct = camera_TTL_correct_temp\n",
    "\n",
    "import re\n",
    "for index in range(len(df_framediff)):\n",
    "    date = re.search(r' \\d \\d{4}-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])', df_framediff.iloc[index][0])\n",
    "    df_framediff.at[index, 'Frame diff'] = date.group()[1]\n",
    "\n",
    "df_framediff = df_framediff.drop(0, axis = 1)\n",
    "df_framediff['Frame diff'] = pd.to_numeric(df_framediff['Frame diff'])\n",
    "\n",
    "# checking if the dimensions of this dataframe is coherent with TTLs from the camera\n",
    "\n",
    "# keep in mind that it is possible for the last TTL to have no correspondant frame (the TTL may have been send but the frame \n",
    "# was not recorded, for example) - furthermore, it is only problematic when the 'missing frame' is between the first and last\n",
    "# inscopix TTLs, since that is the region that counts for the session (inscopix, camera and accel - ON)\n",
    "if len(df_acceldata.loc[df_acceldata['Command']==3].loc[df_acceldata['RegisterAddress'] == 37]) - (len(df_framediff)+1) > 1:\n",
    "    camera_TTL_correct = False\n",
    "\n",
    "# checks of there is a frame diff > 1, which would stand for 'lost frames' (somewhere on 'Command 3')\n",
    "if int(np.sum(df_framediff.loc[df_framediff['Frame diff'] > 1])) == 0 and camera_TTL_correct:\n",
    "    print('No frames were dropped :)')\n",
    "else:\n",
    "    print('The number of TTLs from the camera (acceldata), does not match the length of Frame_diff! It looks like some frames were dropped :(')\n",
    "\n",
    "df_framediff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa49ff3",
   "metadata": {},
   "source": [
    "## 1.4 Import the video (processed) of the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71151733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37113.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_VideoProcessed = \"C:\\\\Users\\\\user\\\\Desktop\\\\42312_2F_B2\\\\VideoProcessed2021-04-29T16_15_55.avi\"\n",
    "# start by checking the total number of frames in this video, which should match the length of the DLC predictions\n",
    "import cv2\n",
    "import numpy as np\n",
    "vidcap = cv2.VideoCapture(path_VideoProcessed)\n",
    "total_frames = vidcap.get(7) #returns the number of frames of the video\n",
    "total_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eaa68c",
   "metadata": {},
   "source": [
    "## 1.5 Import DLC predictions .csv\n",
    "This is the file containing the x,y coordinates of the bodyparts of interest predicted by the DLC network. Each label is accompained by the likelihood of it being correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b91d2b43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28084\\1182618765.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_DLC = pd.read_csv(path_predictions_DLC)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe with DLC predictions is ready. The dimensions of this df match the total number of frames in the video :)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nose (x)</th>\n",
       "      <th>nose (y)</th>\n",
       "      <th>nose (likelihood)</th>\n",
       "      <th>tailbase (x)</th>\n",
       "      <th>tailbase (y)</th>\n",
       "      <th>tailbase (likelihood)</th>\n",
       "      <th>tailtip (x)</th>\n",
       "      <th>tailtip (y)</th>\n",
       "      <th>tailtip (likelihood)</th>\n",
       "      <th>left_frontlimb_digitaltip (x)</th>\n",
       "      <th>...</th>\n",
       "      <th>right_frontlimb_heel (x)</th>\n",
       "      <th>right_frontlimb_heel (y)</th>\n",
       "      <th>right_frontlimb_heel (likelihood)</th>\n",
       "      <th>left_hindlimb_heel (x)</th>\n",
       "      <th>left_hindlimb_heel (y)</th>\n",
       "      <th>left_hindlimb_heel (likelihood)</th>\n",
       "      <th>right_hindlimb_heel (x)</th>\n",
       "      <th>right_hindlimb_heel (y)</th>\n",
       "      <th>right_hindlimb_heel (likelihood)</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703.989075</td>\n",
       "      <td>109.582817</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>565.206299</td>\n",
       "      <td>64.867920</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>445.494476</td>\n",
       "      <td>85.937485</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>672.765625</td>\n",
       "      <td>...</td>\n",
       "      <td>646.727905</td>\n",
       "      <td>64.381477</td>\n",
       "      <td>0.967808</td>\n",
       "      <td>569.689392</td>\n",
       "      <td>82.955177</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>595.056152</td>\n",
       "      <td>47.734856</td>\n",
       "      <td>0.998693</td>\n",
       "      <td>275399.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>705.924377</td>\n",
       "      <td>116.035568</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>569.691772</td>\n",
       "      <td>65.645523</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>449.193756</td>\n",
       "      <td>79.449432</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>670.523438</td>\n",
       "      <td>...</td>\n",
       "      <td>666.607910</td>\n",
       "      <td>80.834373</td>\n",
       "      <td>0.968636</td>\n",
       "      <td>572.499634</td>\n",
       "      <td>81.936455</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>596.521179</td>\n",
       "      <td>48.103065</td>\n",
       "      <td>0.999149</td>\n",
       "      <td>275399.3354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>711.785583</td>\n",
       "      <td>118.557358</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>575.658203</td>\n",
       "      <td>64.463608</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>453.932098</td>\n",
       "      <td>72.325569</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>670.901306</td>\n",
       "      <td>...</td>\n",
       "      <td>684.069153</td>\n",
       "      <td>93.431816</td>\n",
       "      <td>0.998110</td>\n",
       "      <td>575.792603</td>\n",
       "      <td>79.244659</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>599.098511</td>\n",
       "      <td>49.064873</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>275399.3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>714.602661</td>\n",
       "      <td>120.410118</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>580.195007</td>\n",
       "      <td>63.737652</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>459.874084</td>\n",
       "      <td>67.750328</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>670.257080</td>\n",
       "      <td>...</td>\n",
       "      <td>690.320740</td>\n",
       "      <td>95.466553</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>579.551697</td>\n",
       "      <td>81.048454</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>601.921143</td>\n",
       "      <td>48.129837</td>\n",
       "      <td>0.999159</td>\n",
       "      <td>275399.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>721.245789</td>\n",
       "      <td>121.846405</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>587.219116</td>\n",
       "      <td>64.561485</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>467.661896</td>\n",
       "      <td>67.922020</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>671.724060</td>\n",
       "      <td>...</td>\n",
       "      <td>695.163635</td>\n",
       "      <td>94.794434</td>\n",
       "      <td>0.997733</td>\n",
       "      <td>583.064758</td>\n",
       "      <td>78.803604</td>\n",
       "      <td>0.998690</td>\n",
       "      <td>605.472717</td>\n",
       "      <td>48.319180</td>\n",
       "      <td>0.998719</td>\n",
       "      <td>275399.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37108</th>\n",
       "      <td>679.074097</td>\n",
       "      <td>169.885544</td>\n",
       "      <td>0.746022</td>\n",
       "      <td>696.506592</td>\n",
       "      <td>111.462242</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>619.093933</td>\n",
       "      <td>50.051315</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>626.738892</td>\n",
       "      <td>...</td>\n",
       "      <td>664.814636</td>\n",
       "      <td>161.185226</td>\n",
       "      <td>0.970159</td>\n",
       "      <td>672.147644</td>\n",
       "      <td>123.665230</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>694.438171</td>\n",
       "      <td>144.265381</td>\n",
       "      <td>0.998994</td>\n",
       "      <td>276636.1859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37109</th>\n",
       "      <td>679.212158</td>\n",
       "      <td>169.614487</td>\n",
       "      <td>0.627104</td>\n",
       "      <td>696.559998</td>\n",
       "      <td>111.513847</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>618.883423</td>\n",
       "      <td>52.940262</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>627.074768</td>\n",
       "      <td>...</td>\n",
       "      <td>663.518005</td>\n",
       "      <td>161.472198</td>\n",
       "      <td>0.945097</td>\n",
       "      <td>672.501709</td>\n",
       "      <td>123.696381</td>\n",
       "      <td>0.996318</td>\n",
       "      <td>694.466858</td>\n",
       "      <td>144.530197</td>\n",
       "      <td>0.999128</td>\n",
       "      <td>276636.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37110</th>\n",
       "      <td>603.555359</td>\n",
       "      <td>136.817764</td>\n",
       "      <td>0.970762</td>\n",
       "      <td>697.931335</td>\n",
       "      <td>112.178101</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>621.939941</td>\n",
       "      <td>51.141613</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>626.684265</td>\n",
       "      <td>...</td>\n",
       "      <td>645.553528</td>\n",
       "      <td>157.127716</td>\n",
       "      <td>0.988420</td>\n",
       "      <td>670.552734</td>\n",
       "      <td>123.600143</td>\n",
       "      <td>0.997666</td>\n",
       "      <td>694.630188</td>\n",
       "      <td>145.465958</td>\n",
       "      <td>0.999550</td>\n",
       "      <td>276636.2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37111</th>\n",
       "      <td>605.983887</td>\n",
       "      <td>136.335541</td>\n",
       "      <td>0.767845</td>\n",
       "      <td>698.152649</td>\n",
       "      <td>114.096436</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>628.783142</td>\n",
       "      <td>49.886978</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>626.778809</td>\n",
       "      <td>...</td>\n",
       "      <td>643.263794</td>\n",
       "      <td>159.036041</td>\n",
       "      <td>0.999342</td>\n",
       "      <td>670.412964</td>\n",
       "      <td>125.062004</td>\n",
       "      <td>0.999212</td>\n",
       "      <td>694.155090</td>\n",
       "      <td>146.660553</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>276636.2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37112</th>\n",
       "      <td>606.546021</td>\n",
       "      <td>136.592590</td>\n",
       "      <td>0.481296</td>\n",
       "      <td>699.769043</td>\n",
       "      <td>115.737938</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>634.334045</td>\n",
       "      <td>50.611935</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>626.678162</td>\n",
       "      <td>...</td>\n",
       "      <td>643.524536</td>\n",
       "      <td>158.329941</td>\n",
       "      <td>0.999429</td>\n",
       "      <td>670.672668</td>\n",
       "      <td>125.022133</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>695.083496</td>\n",
       "      <td>146.061264</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>276636.3192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37113 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0        nose (x)    nose (y)  nose (likelihood)  tailbase (x)  tailbase (y)  \\\n",
       "0      703.989075  109.582817           0.999959    565.206299     64.867920   \n",
       "1      705.924377  116.035568           0.999999    569.691772     65.645523   \n",
       "2      711.785583  118.557358           0.999998    575.658203     64.463608   \n",
       "3      714.602661  120.410118           0.999976    580.195007     63.737652   \n",
       "4      721.245789  121.846405           0.999992    587.219116     64.561485   \n",
       "...           ...         ...                ...           ...           ...   \n",
       "37108  679.074097  169.885544           0.746022    696.506592    111.462242   \n",
       "37109  679.212158  169.614487           0.627104    696.559998    111.513847   \n",
       "37110  603.555359  136.817764           0.970762    697.931335    112.178101   \n",
       "37111  605.983887  136.335541           0.767845    698.152649    114.096436   \n",
       "37112  606.546021  136.592590           0.481296    699.769043    115.737938   \n",
       "\n",
       "0      tailbase (likelihood)  tailtip (x)  tailtip (y)  tailtip (likelihood)  \\\n",
       "0                   0.999996   445.494476    85.937485              0.999992   \n",
       "1                   0.999984   449.193756    79.449432              0.999983   \n",
       "2                   0.999923   453.932098    72.325569              0.999981   \n",
       "3                   0.999988   459.874084    67.750328              0.999994   \n",
       "4                   0.999910   467.661896    67.922020              0.999998   \n",
       "...                      ...          ...          ...                   ...   \n",
       "37108               0.999984   619.093933    50.051315              0.999972   \n",
       "37109               0.999984   618.883423    52.940262              0.999976   \n",
       "37110               0.999958   621.939941    51.141613              0.999969   \n",
       "37111               0.999980   628.783142    49.886978              0.999981   \n",
       "37112               0.999989   634.334045    50.611935              0.999964   \n",
       "\n",
       "0      left_frontlimb_digitaltip (x)  ...  right_frontlimb_heel (x)  \\\n",
       "0                         672.765625  ...                646.727905   \n",
       "1                         670.523438  ...                666.607910   \n",
       "2                         670.901306  ...                684.069153   \n",
       "3                         670.257080  ...                690.320740   \n",
       "4                         671.724060  ...                695.163635   \n",
       "...                              ...  ...                       ...   \n",
       "37108                     626.738892  ...                664.814636   \n",
       "37109                     627.074768  ...                663.518005   \n",
       "37110                     626.684265  ...                645.553528   \n",
       "37111                     626.778809  ...                643.263794   \n",
       "37112                     626.678162  ...                643.524536   \n",
       "\n",
       "0      right_frontlimb_heel (y)  right_frontlimb_heel (likelihood)  \\\n",
       "0                     64.381477                           0.967808   \n",
       "1                     80.834373                           0.968636   \n",
       "2                     93.431816                           0.998110   \n",
       "3                     95.466553                           0.999417   \n",
       "4                     94.794434                           0.997733   \n",
       "...                         ...                                ...   \n",
       "37108                161.185226                           0.970159   \n",
       "37109                161.472198                           0.945097   \n",
       "37110                157.127716                           0.988420   \n",
       "37111                159.036041                           0.999342   \n",
       "37112                158.329941                           0.999429   \n",
       "\n",
       "0      left_hindlimb_heel (x)  left_hindlimb_heel (y)  \\\n",
       "0                  569.689392               82.955177   \n",
       "1                  572.499634               81.936455   \n",
       "2                  575.792603               79.244659   \n",
       "3                  579.551697               81.048454   \n",
       "4                  583.064758               78.803604   \n",
       "...                       ...                     ...   \n",
       "37108              672.147644              123.665230   \n",
       "37109              672.501709              123.696381   \n",
       "37110              670.552734              123.600143   \n",
       "37111              670.412964              125.062004   \n",
       "37112              670.672668              125.022133   \n",
       "\n",
       "0      left_hindlimb_heel (likelihood)  right_hindlimb_heel (x)  \\\n",
       "0                             0.999935               595.056152   \n",
       "1                             0.999638               596.521179   \n",
       "2                             0.999684               599.098511   \n",
       "3                             0.999733               601.921143   \n",
       "4                             0.998690               605.472717   \n",
       "...                                ...                      ...   \n",
       "37108                         0.996423               694.438171   \n",
       "37109                         0.996318               694.466858   \n",
       "37110                         0.997666               694.630188   \n",
       "37111                         0.999212               694.155090   \n",
       "37112                         0.999243               695.083496   \n",
       "\n",
       "0      right_hindlimb_heel (y)  right_hindlimb_heel (likelihood)    Timestamp  \n",
       "0                    47.734856                          0.998693  275399.3020  \n",
       "1                    48.103065                          0.999149  275399.3354  \n",
       "2                    49.064873                          0.999250  275399.3687  \n",
       "3                    48.129837                          0.999159  275399.4020  \n",
       "4                    48.319180                          0.998719  275399.4354  \n",
       "...                        ...                               ...          ...  \n",
       "37108               144.265381                          0.998994  276636.1859  \n",
       "37109               144.530197                          0.999128  276636.2192  \n",
       "37110               145.465958                          0.999550  276636.2525  \n",
       "37111               146.660553                          0.999359  276636.2859  \n",
       "37112               146.061264                          0.999543  276636.3192  \n",
       "\n",
       "[37113 rows x 34 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_predictions_DLC = \"C:\\\\Users\\\\user\\\\Desktop\\\\42312_2F_B2\\\\VideoProcessed2021-04-29T16_15_55DLC_resnet50_Dystonia_TestApr21shuffle1_500000.csv\"\n",
    "df_DLC = pd.read_csv(path_predictions_DLC)\n",
    "df_DLC = df_DLC.drop(columns='scorer')\n",
    "df_DLC.iloc[0] + ' ' + '(' + df_DLC.iloc[1] + ')'\n",
    "df_DLC.iloc[0] = df_DLC.iloc[0] + ' ' + '(' + df_DLC.iloc[1] + ')'\n",
    "df_DLC.drop(index=1)\n",
    "df_DLC.columns = df_DLC.iloc[0]\n",
    "df_DLC = df_DLC.drop(index=0)\n",
    "df_DLC = df_DLC.drop(index=1)\n",
    "df_DLC.reset_index(inplace = True, drop = True)\n",
    "for column in df_DLC.columns:\n",
    "    df_DLC[column] = pd.to_numeric(df_DLC[column])\n",
    "\n",
    "DLC_predictions_ready = False    \n",
    "if len(df_DLC) == len(df_framediff)+1 == total_frames:\n",
    "    print('The dataframe with DLC predictions is ready. The dimensions of this df match the total number of frames in the video :)')\n",
    "    DLC_predictions_ready = True\n",
    "else:\n",
    "    print('The DLC predictions don\\'t match the Frame diff')\n",
    "\n",
    "# complete the dataframe by adding a column with the camera timestamps\n",
    "camera_timestamps = df_acceldata['Timestamp'].loc[df_acceldata['Command']==3].loc[df_acceldata['RegisterAddress']==37]\n",
    "camera_timestamps.reset_index(inplace = True, drop = True)\n",
    "df_DLC['Timestamp'] = camera_timestamps\n",
    "\n",
    "df_DLC #dataframe with the DLC predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e95c820b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the frame diff, DLC predictions and bodypart velocity dataframes are coherent :)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vel - nose (x)</th>\n",
       "      <th>Vel - nose (y)</th>\n",
       "      <th>V_xy_nose</th>\n",
       "      <th>nose (likelihood)</th>\n",
       "      <th>Vel - tailbase (x)</th>\n",
       "      <th>Vel - tailbase (y)</th>\n",
       "      <th>V_xy_tailbase</th>\n",
       "      <th>tailbase (likelihood)</th>\n",
       "      <th>Vel - tailtip (x)</th>\n",
       "      <th>Vel - tailtip (y)</th>\n",
       "      <th>...</th>\n",
       "      <th>right_frontlimb_heel (likelihood)</th>\n",
       "      <th>Vel - left_hindlimb_heel (x)</th>\n",
       "      <th>Vel - left_hindlimb_heel (y)</th>\n",
       "      <th>V_xy_left_hindlimb_heel</th>\n",
       "      <th>left_hindlimb_heel (likelihood)</th>\n",
       "      <th>Vel - right_hindlimb_heel (x)</th>\n",
       "      <th>Vel - right_hindlimb_heel (y)</th>\n",
       "      <th>V_xy_right_hindlimb_heel</th>\n",
       "      <th>right_hindlimb_heel (likelihood)</th>\n",
       "      <th>Vel - Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.935303</td>\n",
       "      <td>6.452751</td>\n",
       "      <td>6.736720</td>\n",
       "      <td>4.005432e-05</td>\n",
       "      <td>4.485474</td>\n",
       "      <td>0.777603</td>\n",
       "      <td>4.552377</td>\n",
       "      <td>1.239777e-05</td>\n",
       "      <td>3.699280</td>\n",
       "      <td>6.488052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>2.810242</td>\n",
       "      <td>1.018723</td>\n",
       "      <td>2.989190</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>1.465027</td>\n",
       "      <td>0.368210</td>\n",
       "      <td>1.510590</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>275399.3354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.861206</td>\n",
       "      <td>2.521790</td>\n",
       "      <td>6.380686</td>\n",
       "      <td>1.192093e-07</td>\n",
       "      <td>5.966431</td>\n",
       "      <td>1.181915</td>\n",
       "      <td>6.082369</td>\n",
       "      <td>6.127357e-05</td>\n",
       "      <td>4.738342</td>\n",
       "      <td>7.123863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029474</td>\n",
       "      <td>3.292969</td>\n",
       "      <td>2.691795</td>\n",
       "      <td>4.253164</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>2.577332</td>\n",
       "      <td>0.961807</td>\n",
       "      <td>2.750947</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>275399.3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.817078</td>\n",
       "      <td>1.852760</td>\n",
       "      <td>3.371742</td>\n",
       "      <td>2.205372e-05</td>\n",
       "      <td>4.536804</td>\n",
       "      <td>0.725956</td>\n",
       "      <td>4.594519</td>\n",
       "      <td>6.592274e-05</td>\n",
       "      <td>5.941986</td>\n",
       "      <td>4.575241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>3.759094</td>\n",
       "      <td>1.803795</td>\n",
       "      <td>4.169468</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>2.822632</td>\n",
       "      <td>0.935036</td>\n",
       "      <td>2.973473</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>275399.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.643127</td>\n",
       "      <td>1.436287</td>\n",
       "      <td>6.796621</td>\n",
       "      <td>1.525879e-05</td>\n",
       "      <td>7.024109</td>\n",
       "      <td>0.823833</td>\n",
       "      <td>7.072256</td>\n",
       "      <td>7.855892e-05</td>\n",
       "      <td>7.787811</td>\n",
       "      <td>0.171692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>3.513062</td>\n",
       "      <td>2.244850</td>\n",
       "      <td>4.169047</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>3.551575</td>\n",
       "      <td>0.189342</td>\n",
       "      <td>3.556618</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>275399.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.830872</td>\n",
       "      <td>1.468178</td>\n",
       "      <td>5.049046</td>\n",
       "      <td>3.695488e-06</td>\n",
       "      <td>5.566833</td>\n",
       "      <td>0.099838</td>\n",
       "      <td>5.567729</td>\n",
       "      <td>6.186962e-05</td>\n",
       "      <td>5.539978</td>\n",
       "      <td>1.436821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>14.130554</td>\n",
       "      <td>6.424660</td>\n",
       "      <td>15.522526</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.949280</td>\n",
       "      <td>0.241886</td>\n",
       "      <td>0.979613</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>275399.4687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37107</th>\n",
       "      <td>76.738953</td>\n",
       "      <td>10.639099</td>\n",
       "      <td>77.472945</td>\n",
       "      <td>1.434436e-01</td>\n",
       "      <td>1.092590</td>\n",
       "      <td>0.824089</td>\n",
       "      <td>1.368531</td>\n",
       "      <td>1.668930e-05</td>\n",
       "      <td>4.606018</td>\n",
       "      <td>3.213882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.160950</td>\n",
       "      <td>0.131798</td>\n",
       "      <td>0.208028</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.258301</td>\n",
       "      <td>0.014069</td>\n",
       "      <td>0.258684</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>276636.1859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37108</th>\n",
       "      <td>0.138062</td>\n",
       "      <td>0.271057</td>\n",
       "      <td>0.304192</td>\n",
       "      <td>1.189179e-01</td>\n",
       "      <td>0.053406</td>\n",
       "      <td>0.051605</td>\n",
       "      <td>0.074265</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>0.210510</td>\n",
       "      <td>2.888947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025063</td>\n",
       "      <td>0.354065</td>\n",
       "      <td>0.031151</td>\n",
       "      <td>0.355433</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.028687</td>\n",
       "      <td>0.264816</td>\n",
       "      <td>0.266366</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>276636.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37109</th>\n",
       "      <td>75.656799</td>\n",
       "      <td>32.796722</td>\n",
       "      <td>82.459543</td>\n",
       "      <td>3.436582e-01</td>\n",
       "      <td>1.371338</td>\n",
       "      <td>0.664253</td>\n",
       "      <td>1.523745</td>\n",
       "      <td>2.586842e-05</td>\n",
       "      <td>3.056519</td>\n",
       "      <td>1.798649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043323</td>\n",
       "      <td>1.948975</td>\n",
       "      <td>0.096237</td>\n",
       "      <td>1.951349</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.163330</td>\n",
       "      <td>0.935760</td>\n",
       "      <td>0.949908</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>276636.2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37110</th>\n",
       "      <td>2.428528</td>\n",
       "      <td>0.482224</td>\n",
       "      <td>2.475942</td>\n",
       "      <td>2.029172e-01</td>\n",
       "      <td>0.221313</td>\n",
       "      <td>1.918335</td>\n",
       "      <td>1.931059</td>\n",
       "      <td>2.181530e-05</td>\n",
       "      <td>6.843201</td>\n",
       "      <td>1.254635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.139771</td>\n",
       "      <td>1.461861</td>\n",
       "      <td>1.468527</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.475098</td>\n",
       "      <td>1.194595</td>\n",
       "      <td>1.285603</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>276636.2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37111</th>\n",
       "      <td>0.562134</td>\n",
       "      <td>0.257050</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>2.865489e-01</td>\n",
       "      <td>1.616394</td>\n",
       "      <td>1.641502</td>\n",
       "      <td>2.303749</td>\n",
       "      <td>8.702278e-06</td>\n",
       "      <td>5.550903</td>\n",
       "      <td>0.724957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.259705</td>\n",
       "      <td>0.039871</td>\n",
       "      <td>0.262747</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>0.599289</td>\n",
       "      <td>1.105027</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>276636.3192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37112 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      Vel - nose (x)  Vel - nose (y)  V_xy_nose  nose (likelihood)  \\\n",
       "0            1.935303        6.452751   6.736720       4.005432e-05   \n",
       "1            5.861206        2.521790   6.380686       1.192093e-07   \n",
       "2            2.817078        1.852760   3.371742       2.205372e-05   \n",
       "3            6.643127        1.436287   6.796621       1.525879e-05   \n",
       "4            4.830872        1.468178   5.049046       3.695488e-06   \n",
       "...               ...             ...        ...                ...   \n",
       "37107       76.738953       10.639099  77.472945       1.434436e-01   \n",
       "37108        0.138062        0.271057   0.304192       1.189179e-01   \n",
       "37109       75.656799       32.796722  82.459543       3.436582e-01   \n",
       "37110        2.428528        0.482224   2.475942       2.029172e-01   \n",
       "37111        0.562134        0.257050   0.618117       2.865489e-01   \n",
       "\n",
       "0      Vel - tailbase (x)  Vel - tailbase (y)  V_xy_tailbase  \\\n",
       "0                4.485474            0.777603       4.552377   \n",
       "1                5.966431            1.181915       6.082369   \n",
       "2                4.536804            0.725956       4.594519   \n",
       "3                7.024109            0.823833       7.072256   \n",
       "4                5.566833            0.099838       5.567729   \n",
       "...                   ...                 ...            ...   \n",
       "37107            1.092590            0.824089       1.368531   \n",
       "37108            0.053406            0.051605       0.074265   \n",
       "37109            1.371338            0.664253       1.523745   \n",
       "37110            0.221313            1.918335       1.931059   \n",
       "37111            1.616394            1.641502       2.303749   \n",
       "\n",
       "0      tailbase (likelihood)  Vel - tailtip (x)  Vel - tailtip (y)  ...  \\\n",
       "0               1.239777e-05           3.699280           6.488052  ...   \n",
       "1               6.127357e-05           4.738342           7.123863  ...   \n",
       "2               6.592274e-05           5.941986           4.575241  ...   \n",
       "3               7.855892e-05           7.787811           0.171692  ...   \n",
       "4               6.186962e-05           5.539978           1.436821  ...   \n",
       "...                      ...                ...                ...  ...   \n",
       "37107           1.668930e-05           4.606018           3.213882  ...   \n",
       "37108           3.576279e-07           0.210510           2.888947  ...   \n",
       "37109           2.586842e-05           3.056519           1.798649  ...   \n",
       "37110           2.181530e-05           6.843201           1.254635  ...   \n",
       "37111           8.702278e-06           5.550903           0.724957  ...   \n",
       "\n",
       "0      right_frontlimb_heel (likelihood)  Vel - left_hindlimb_heel (x)  \\\n",
       "0                               0.000828                      2.810242   \n",
       "1                               0.029474                      3.292969   \n",
       "2                               0.001307                      3.759094   \n",
       "3                               0.001684                      3.513062   \n",
       "4                               0.000104                     14.130554   \n",
       "...                                  ...                           ...   \n",
       "37107                           0.008292                      0.160950   \n",
       "37108                           0.025063                      0.354065   \n",
       "37109                           0.043323                      1.948975   \n",
       "37110                           0.010922                      0.139771   \n",
       "37111                           0.000087                      0.259705   \n",
       "\n",
       "0      Vel - left_hindlimb_heel (y)  V_xy_left_hindlimb_heel  \\\n",
       "0                          1.018723                 2.989190   \n",
       "1                          2.691795                 4.253164   \n",
       "2                          1.803795                 4.169468   \n",
       "3                          2.244850                 4.169047   \n",
       "4                          6.424660                15.522526   \n",
       "...                             ...                      ...   \n",
       "37107                      0.131798                 0.208028   \n",
       "37108                      0.031151                 0.355433   \n",
       "37109                      0.096237                 1.951349   \n",
       "37110                      1.461861                 1.468527   \n",
       "37111                      0.039871                 0.262747   \n",
       "\n",
       "0      left_hindlimb_heel (likelihood)  Vel - right_hindlimb_heel (x)  \\\n",
       "0                             0.000296                       1.465027   \n",
       "1                             0.000046                       2.577332   \n",
       "2                             0.000049                       2.822632   \n",
       "3                             0.001043                       3.551575   \n",
       "4                             0.001295                       0.949280   \n",
       "...                                ...                            ...   \n",
       "37107                         0.000575                       0.258301   \n",
       "37108                         0.000105                       0.028687   \n",
       "37109                         0.001347                       0.163330   \n",
       "37110                         0.001547                       0.475098   \n",
       "37111                         0.000031                       0.928406   \n",
       "\n",
       "0      Vel - right_hindlimb_heel (y)  V_xy_right_hindlimb_heel  \\\n",
       "0                           0.368210                  1.510590   \n",
       "1                           0.961807                  2.750947   \n",
       "2                           0.935036                  2.973473   \n",
       "3                           0.189342                  3.556618   \n",
       "4                           0.241886                  0.979613   \n",
       "...                              ...                       ...   \n",
       "37107                       0.014069                  0.258684   \n",
       "37108                       0.264816                  0.266366   \n",
       "37109                       0.935760                  0.949908   \n",
       "37110                       1.194595                  1.285603   \n",
       "37111                       0.599289                  1.105027   \n",
       "\n",
       "0      right_hindlimb_heel (likelihood)  Vel - Timestamp  \n",
       "0                              0.000456      275399.3354  \n",
       "1                              0.000100      275399.3687  \n",
       "2                              0.000091      275399.4020  \n",
       "3                              0.000440      275399.4354  \n",
       "4                              0.000475      275399.4687  \n",
       "...                                 ...              ...  \n",
       "37107                          0.000207      276636.1859  \n",
       "37108                          0.000135      276636.2192  \n",
       "37109                          0.000422      276636.2525  \n",
       "37110                          0.000191      276636.2859  \n",
       "37111                          0.000184      276636.3192  \n",
       "\n",
       "[37112 rows x 45 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#don't run this cell more than once (if you did, re-run the previous cell before running the present one)\n",
    "import numpy as np\n",
    "df_vel = df_DLC.copy(deep=False)\n",
    "\n",
    "for column in df_vel.columns:\n",
    "    if ('likelihood' and 'Timestamp') not in column :\n",
    "        df_vel[column] = np.abs(df_vel[column].diff())\n",
    "\n",
    "my_list=[]\n",
    "for col in df_vel.columns:\n",
    "    if 'likelihood' not in col:\n",
    "        my_list.append('Vel - ' + col)\n",
    "\n",
    "for col in df_vel.columns:\n",
    "    for new_name in my_list:\n",
    "        if col in new_name:\n",
    "            df_vel.rename({col:new_name}, axis=1, inplace=True)\n",
    "            \n",
    "for col in df_vel.columns:\n",
    "    if '(likelihood)' in col:\n",
    "        loc = df_vel.columns.get_loc(col)\n",
    "        V_xy = np.sqrt(df_vel[df_vel.columns[loc-2]]**2+df_vel[df_vel.columns[loc-1]]**2)\n",
    "        name_column = 'V_xy_'+df_vel.columns[loc].split(\" \")[0]\n",
    "        df_vel.insert(loc, name_column, V_xy)\n",
    "\n",
    "# I dropped the first row (NaN values) since, every row represents a diff between the coordinates of consecutive frames\n",
    "df_vel = df_vel.drop(index=0)\n",
    "df_vel.reset_index(inplace = True, drop = True)\n",
    "        \n",
    "# programm a green sign test to see if everything is ok with the data from \n",
    "# the current step\n",
    "Velocity_data_ready = False\n",
    "if len(df_framediff)+1 == len(df_vel)+1 == len(df_DLC):\n",
    "    print('The dimensions of the frame diff, DLC predictions and bodypart velocity dataframes are coherent :)')\n",
    "    Velocity_data_ready = True\n",
    "else:\n",
    "    print('The dimensions of the frame diff, DLC predictions and bodypart velocity dataframes are NOT coherent :(')\n",
    "    \n",
    "df_vel #dataframe with the velocities (x, y and absolute - px/frame) obtained from the DLC predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc426b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1f9cf",
   "metadata": {},
   "source": [
    "## Final test before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f446ff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready for analysis :)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Command</th>\n",
       "      <th>RegisterAddress</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>DataElement0</th>\n",
       "      <th>Accel_y</th>\n",
       "      <th>Accel_z</th>\n",
       "      <th>Gyr_x</th>\n",
       "      <th>Gyr_y</th>\n",
       "      <th>Gyr_z</th>\n",
       "      <th>Magn_x</th>\n",
       "      <th>Magn_y</th>\n",
       "      <th>Magn_z</th>\n",
       "      <th>Counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>275406.7676</td>\n",
       "      <td>16416.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>275406.7684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>275406.7702</td>\n",
       "      <td>-2751.0</td>\n",
       "      <td>-373.0</td>\n",
       "      <td>-7766.0</td>\n",
       "      <td>-2003.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-904.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>-333.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>275406.7745</td>\n",
       "      <td>-3438.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-7687.0</td>\n",
       "      <td>-2653.0</td>\n",
       "      <td>-859.0</td>\n",
       "      <td>-1133.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>-333.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>275406.7801</td>\n",
       "      <td>-4283.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-7370.0</td>\n",
       "      <td>-2616.0</td>\n",
       "      <td>-1464.0</td>\n",
       "      <td>-1255.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>-335.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335216</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276628.4267</td>\n",
       "      <td>-7471.0</td>\n",
       "      <td>-4691.0</td>\n",
       "      <td>-649.0</td>\n",
       "      <td>769.0</td>\n",
       "      <td>-2091.0</td>\n",
       "      <td>-1176.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>-302.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335217</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276628.4309</td>\n",
       "      <td>-7069.0</td>\n",
       "      <td>-4282.0</td>\n",
       "      <td>-418.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>-1561.0</td>\n",
       "      <td>-662.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>-302.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335218</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276628.4365</td>\n",
       "      <td>-6429.0</td>\n",
       "      <td>-4132.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>-1368.0</td>\n",
       "      <td>-231.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335219</th>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>276628.4409</td>\n",
       "      <td>-6941.0</td>\n",
       "      <td>-4165.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-1486.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335220</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>276628.4436</td>\n",
       "      <td>33884.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335221 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Command  RegisterAddress    Timestamp  DataElement0  Accel_y  Accel_z  \\\n",
       "0           3.0             35.0  275406.7676       16416.0      NaN      NaN   \n",
       "1           3.0             37.0  275406.7684           1.0      NaN      NaN   \n",
       "2           3.0             34.0  275406.7702       -2751.0   -373.0  -7766.0   \n",
       "3           3.0             34.0  275406.7745       -3438.0    -52.0  -7687.0   \n",
       "4           3.0             34.0  275406.7801       -4283.0      5.0  -7370.0   \n",
       "...         ...              ...          ...           ...      ...      ...   \n",
       "335216      3.0             34.0  276628.4267       -7471.0  -4691.0   -649.0   \n",
       "335217      3.0             34.0  276628.4309       -7069.0  -4282.0   -418.0   \n",
       "335218      3.0             34.0  276628.4365       -6429.0  -4132.0    151.0   \n",
       "335219      3.0             34.0  276628.4409       -6941.0  -4165.0    992.0   \n",
       "335220      3.0             35.0  276628.4436       33884.0      NaN      NaN   \n",
       "\n",
       "         Gyr_x   Gyr_y   Gyr_z  Magn_x  Magn_y  Magn_z  Counter  \n",
       "0          NaN     NaN     NaN     NaN     NaN     NaN      NaN  \n",
       "1          NaN     NaN     NaN     NaN     NaN     NaN      NaN  \n",
       "2      -2003.0  -134.0  -904.0   109.0   215.0  -333.0     45.0  \n",
       "3      -2653.0  -859.0 -1133.0   109.0   215.0  -333.0     46.0  \n",
       "4      -2616.0 -1464.0 -1255.0   110.0   216.0  -335.0     47.0  \n",
       "...        ...     ...     ...     ...     ...     ...      ...  \n",
       "335216   769.0 -2091.0 -1176.0   104.0   305.0  -302.0    105.0  \n",
       "335217   383.0 -1561.0  -662.0   104.0   305.0  -302.0    106.0  \n",
       "335218   285.0 -1368.0  -231.0   107.0   306.0  -300.0    107.0  \n",
       "335219  -164.0 -1486.0    54.0   107.0   306.0  -300.0    108.0  \n",
       "335220     NaN     NaN     NaN     NaN     NaN     NaN      NaN  \n",
       "\n",
       "[335221 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a bool variable the gives an overall approval of the data for analysis\n",
    "# for example, if everything is ok, all dimensions, no missed data, etc\n",
    "# it should be TRUE\n",
    "can_advance = False\n",
    "\n",
    "tests = [neuron_data_ready, raw_neuron_data_ready, accel_TTL_correct, camera_TTL_correct, inscopix_TTL_correct, DLC_predictions_ready, Velocity_data_ready]\n",
    "\n",
    "if sum(tests) == len(tests):\n",
    "    can_advance = True\n",
    "    print('Data is ready for analysis :)')\n",
    "else:\n",
    "    print('Either there is missing data or you haven\\'t yet run all the necessary cells preceding the analysis!')\n",
    "\n",
    "first_TTL_inscopix = df_acceldata.loc[df_acceldata['Command']==3].loc[df_acceldata['RegisterAddress']==35].index[0]\n",
    "last_TTL_inscopix = df_acceldata.loc[df_acceldata['Command']==3].loc[df_acceldata['RegisterAddress']==35].index[-1]\n",
    "\n",
    "if can_advance:\n",
    "    # this df contains the TTL information of the session (from the first to the last inscopix TTL)\n",
    "    df_session = df_acceldata[first_TTL_inscopix:last_TTL_inscopix+1]\n",
    "    df_session.reset_index(inplace = True, drop = True)\n",
    "df_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbf513",
   "metadata": {},
   "source": [
    "I think I don't need the df_session dataframe. The first_TTL_inscopix and the last_TTL_inscopix will allow me to build the plots containing only information from the session :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc834f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4198c52f",
   "metadata": {},
   "source": [
    "# 2. Align initiations to neuronal data\n",
    "\n",
    "### This should be divided in two main problems:\n",
    "##### A) Initiation detection (more technical problem)\n",
    "Which of the lesioned paw initiations (DLC velocity) are 'associated' with initiations from the accelerometer?\n",
    "##### B) Alignment itself (more scientific problem)\n",
    "To what should I align the initiations; Groups of neurons?, and should they always fire?, ... ; What are the scientific questions I want answered? (psth)\n",
    "\n",
    "### ...from now on, you should only consider the data from the first to the last Inscopix TTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1276e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a function that calculates moving averages\n",
    "# the result will have a len = len(original data) - (window - 1)\n",
    "import numpy as np\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d8e2f",
   "metadata": {},
   "source": [
    "# A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6719db6",
   "metadata": {},
   "source": [
    "## 2.1 Detection itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b1000",
   "metadata": {},
   "source": [
    "## 2.1.1 Detecting initiations using the accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77aeb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this window should be carefully tuned\n",
    "filtering_window = 20\n",
    "accel_filtered = moving_average(df_acceldata_accel['Total_accel'], filtering_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5dc57b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228ac8fb9a0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.plot(df_acceldata_accel['Total_accel'])\n",
    "plt.plot(accel_filtered)'''\n",
    "\n",
    "# filtered 'total_body_accel' aligned to the not-filtered 'total_body_accel' \n",
    "plt.plot(df_acceldata_accel['Total_accel'])\n",
    "plt.plot(range(19, len(df_acceldata_accel)), accel_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020cd65",
   "metadata": {},
   "source": [
    "### Initiations - total body acceleration (original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f248b50",
   "metadata": {},
   "source": [
    "###### Local minimum between the two modes of a bimodal distribution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4e84be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292.58955151948896\n"
     ]
    }
   ],
   "source": [
    "#consider a movement initiation every time the acceleration raises above \n",
    "#...the beginning of a local minimum in the log distribution of total body accelerations\n",
    "#...the local minimum is to be found in the valley forming the two peaks of\n",
    "#...the log_scale distribution\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# raw acceleration data (total body acceleration)\n",
    "ax = sns.kdeplot(df_acceldata_accel['Total_accel'], log_scale=True)\n",
    "\n",
    "kde_curve = ax.lines[0]\n",
    "\n",
    "x = kde_curve.get_xdata()\n",
    "y = kde_curve.get_ydata()\n",
    "\n",
    "plt.plot(x, y)\n",
    "peaks = np.where((y[1:-1] > y[0:-2]) * (y[1:-1] > y[2:]))[0] + 1\n",
    "dips = np.where((y[1:-1] < y[0:-2]) * (y[1:-1] < y[2:]))[0] + 1\n",
    "\n",
    "plt.plot(x, y, color='cyan')\n",
    "plt.plot(x[peaks], y[peaks], 'o')\n",
    "plt.plot(x[dips], y[dips], 'o')\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(peaks)):\n",
    "    # this is tricky, since some distributions may be multimodal\n",
    "    # ...or have multiple local minimums which would make this computation not trivial\n",
    "    cutOff_accel = x[dips[1]]\n",
    "    break\n",
    "print(cutOff_accel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc60c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movement bouts detected from the accelerometer data\n",
    "moving_accel = []\n",
    "for timestamp in range(len(df_acceldata_accel['Total_accel'])):\n",
    "    if df_acceldata_accel['Total_accel'][timestamp] >= cutOff_accel:\n",
    "        moving_accel.append(1)\n",
    "    else:\n",
    "        moving_accel.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99969a6",
   "metadata": {},
   "source": [
    "###### Crossing point between two gaussians fitted to the kernel density estimation... (not correct yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd11362c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.150227326915803"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the treshold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "y,x,_=plt.hist(np.log(df_acceldata_accel['Total_accel']), bins=100, color='lightblue')\n",
    "\n",
    "x=(x[1:]+x[:-1])/2 \n",
    "\n",
    "def gauss(x, mu, sigma, A):\n",
    "    return A*np.exp(-(x-mu)**2/2/sigma**2)\n",
    "\n",
    "def bimodal(x, mu1, sigma1, A1, mu2, sigma2, A2):\n",
    "    return gauss(x, mu1, sigma1, A1)+gauss(x, mu2, sigma2, A2)\n",
    "\n",
    "# maybe define the expected values from the data: in this case, I can find the max count value and use it or A1 and A2\n",
    "expected = (4, .1, max(y)/2, 7, .1, max(y)/2)\n",
    "params, cov = curve_fit(bimodal, x, y, expected, \n",
    "                        #[[lower], [upper]] bounds for mu1, sigma1, A1, mu2, sigma2, A2\n",
    "                        bounds=[[-np.inf, 0, 0, -np.inf, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf]]) \n",
    "sigma=np.sqrt(np.diag(cov))\n",
    "x_fit = np.linspace(x.min(), x.max(), 500)\n",
    "f = gauss(x_fit, *params[:3])\n",
    "g = gauss(x_fit, *params[3:])\n",
    "#print(pd.DataFrame(data={'params': params, 'sigma': sigma}, index=bimodal.__code__.co_varnames[1:]))\n",
    "plt.plot(x_fit, bimodal(x_fit, *params), color='red', lw=3, label='model')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[:3]), color='red', ls='--')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[3:]), color='red', ls=':')\n",
    "\n",
    "first_line = LineString(np.column_stack((x_fit, f)))\n",
    "second_line = LineString(np.column_stack((x_fit, g)))\n",
    "intersection = first_line.intersection(second_line)\n",
    "\n",
    "if intersection.geom_type == 'MultiPoint':\n",
    "    plt.plot(*LineString(intersection).xy, 'o')\n",
    "elif intersection.geom_type == 'Point':\n",
    "    plt.plot(*intersection.xy, 'o', color='orange')\n",
    "\n",
    "cutOff_cg = intersection.xy[0][0]\n",
    "cutOff_cg #not the real cutoff since I used the log o the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fc19520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain periods of movement (cg - cross gaussian)\n",
    "moving_accel_cg = []\n",
    "for timestamp in range(len(df_acceldata_accel['Total_accel'])):\n",
    "    if np.log(df_acceldata_accel['Total_accel'][timestamp]) >= cutOff_cg:\n",
    "        moving_accel_cg.append(1)\n",
    "    else:\n",
    "        moving_accel_cg.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344c469",
   "metadata": {},
   "source": [
    "### Initiations - total body acceleration (filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf208f47",
   "metadata": {},
   "source": [
    "##### Local minimum between the two modes of a bimodal distribution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48cc5262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298.5213760263762\n"
     ]
    }
   ],
   "source": [
    "#consider a movement initiation every time the acceleration raises above \n",
    "#...the beginning of a local minimum in the log distribution of total body accelerations\n",
    "#...the local minimum is to be found in the valley forming the two peaks of\n",
    "#...the log_scale distribution\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# raw acceleration data (total body acceleration)\n",
    "ax = sns.kdeplot(accel_filtered,  log_scale=True)\n",
    "\n",
    "kde_curve = ax.lines[0]\n",
    "\n",
    "x = kde_curve.get_xdata()\n",
    "y = kde_curve.get_ydata()\n",
    "\n",
    "plt.plot(x, y)\n",
    "peaks = np.where((y[1:-1] > y[0:-2]) * (y[1:-1] > y[2:]))[0] + 1\n",
    "dips = np.where((y[1:-1] < y[0:-2]) * (y[1:-1] < y[2:]))[0] + 1\n",
    "\n",
    "plt.plot(x, y, color='cyan')\n",
    "plt.plot(x[peaks], y[peaks], 'o')\n",
    "plt.plot(x[dips], y[dips], 'o')\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(peaks)):\n",
    "    # this is tricky, since some distributions may be multimodal\n",
    "    cutOff_accel_filtered = x[dips[0]]\n",
    "    break\n",
    "print(cutOff_accel_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e52cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_accel_filtered = []\n",
    "for timestamp in range(len(accel_filtered)):\n",
    "    if accel_filtered[timestamp] >= cutOff_accel_filtered:\n",
    "        moving_accel_filtered.append(1)\n",
    "    else:\n",
    "        moving_accel_filtered.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f1a5a",
   "metadata": {},
   "source": [
    "##### Crossing point between two gaussians fitted to the kernel density estimation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "066d253e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.097450096855663"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the treshold \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "y,x,_=plt.hist(np.log(accel_filtered), bins=100, color='lightblue')\n",
    "\n",
    "x=(x[1:]+x[:-1])/2 \n",
    "\n",
    "def gauss(x, mu, sigma, A):\n",
    "    return A*np.exp(-(x-mu)**2/2/sigma**2)\n",
    "\n",
    "def bimodal(x, mu1, sigma1, A1, mu2, sigma2, A2):\n",
    "    return gauss(x, mu1, sigma1, A1)+gauss(x, mu2, sigma2, A2)\n",
    "\n",
    "# maybe define the expected values from the data: in this case, I can find the max count value and use it or A1 and A2\n",
    "expected = (4, .1, max(y)/2, 7, .1, max(y)/2)\n",
    "params, cov = curve_fit(bimodal, x, y, expected, \n",
    "                        #[[lower], [upper]] bounds for mu1, sigma1, A1, mu2, sigma2, A2\n",
    "                        bounds=[[-np.inf, 0, 0, -np.inf, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf]]) \n",
    "sigma=np.sqrt(np.diag(cov))\n",
    "x_fit = np.linspace(x.min(), x.max(), 500)\n",
    "f = gauss(x_fit, *params[:3])\n",
    "g = gauss(x_fit, *params[3:])\n",
    "#print(pd.DataFrame(data={'params': params, 'sigma': sigma}, index=bimodal.__code__.co_varnames[1:]))\n",
    "plt.plot(x_fit, bimodal(x_fit, *params), color='red', lw=3, label='model')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[:3]), color='red', ls='--')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[3:]), color='red', ls=':')\n",
    "\n",
    "first_line = LineString(np.column_stack((x_fit, f)))\n",
    "second_line = LineString(np.column_stack((x_fit, g)))\n",
    "intersection = first_line.intersection(second_line)\n",
    "\n",
    "if intersection.geom_type == 'MultiPoint':\n",
    "    plt.plot(*LineString(intersection).xy, 'o')\n",
    "elif intersection.geom_type == 'Point':\n",
    "    plt.plot(*intersection.xy, 'o', color='orange')\n",
    "\n",
    "#not the real cutoff since I used the log of the data (as such, it should be applied to the log accel series)\n",
    "cutOff_filtered_cg = intersection.xy[0][0]\n",
    "cutOff_filtered_cg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "958da145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain periods of movement (cg - cross gaussian)\n",
    "moving_accel_filtered_cg = []\n",
    "for timestamp in range(len(accel_filtered)):\n",
    "    if np.log(accel_filtered[timestamp]) >= cutOff_filtered_cg:\n",
    "        moving_accel_filtered_cg.append(1)\n",
    "    else:\n",
    "        moving_accel_filtered_cg.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08173452",
   "metadata": {},
   "source": [
    "##### Comparing the two (original vs filtered total body acceleration) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a749bbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228c36888b0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local minimum between the two modes of a bimodal distribution...\n",
    "plt.plot(moving_accel)\n",
    "plt.plot(moving_accel_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48c4dfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228c37e8370>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crossing point between the two gaussians (cg - cross gaussian)\n",
    "plt.plot(moving_accel_cg)\n",
    "plt.plot(moving_accel_filtered_cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9dcb8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228c3858c40>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "plt.plot(st.zscore(df_acceldata_accel['Total_accel']))\n",
    "plt.plot(st.zscore(accel_filtered))\n",
    "plt.plot(st.zscore(moving_accel_filtered_cg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7cef7f",
   "metadata": {},
   "source": [
    "##### Trying to work out the criteria for defining initiations from the acceleration data based on the 0/1s defined from the crossing point of two gaussians...\n",
    "**First Approach:** 300 ms of log(acceleration) under the selected treshold, followed by 500 ms of log(acceleration) above the treshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20305b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moving_accel_cg)-len(moving_accel_filtered_cg) #with a 20 window moving average filter (low pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0061e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of initiations detected using the accelerometer is: 78\n",
      "\n",
      "The initiations were corrected according to the window of the filter used :)\n"
     ]
    }
   ],
   "source": [
    "# create an arrary with the sequence of interest\n",
    "# fs # accel sampling rate\n",
    "sec_stopped = 0.3 #300 ms\n",
    "num_points_stopped = fs*sec_stopped\n",
    "\n",
    "sec_moving = 0.5 #500 ms\n",
    "num_points_moving = fs*sec_moving\n",
    "\n",
    "sequence_0_1 = (num_points_stopped, num_points_moving)\n",
    "sequence=np.concatenate([np.zeros(int(sequence_0_1[0])),np.ones(int(sequence_0_1[1]))])\n",
    "\n",
    "# iterate through the moving_accel_filtered_cg to find the places where the sequence is found\n",
    "movement_initiations_accel = []\n",
    "index_first_element_last_seq = len(moving_accel_filtered_cg)-len(sequence)\n",
    "for timestamp in range(index_first_element_last_seq + 1): # because range excludes the last value\n",
    "    if sum(moving_accel_filtered_cg[timestamp:timestamp+len(sequence)] == sequence) == len(sequence):\n",
    "        movement_initiations_accel.append(timestamp+(sequence_0_1[0]-1)) #+(sequence_0_1[0]-1) considers the last zero as the initiation; +sequence_0_1[0] considers the first 1 as the init\n",
    "print('The number of initiations detected using the accelerometer is: {}'.format(len(movement_initiations_accel)))\n",
    "\n",
    "# correct the shift associated to the filtering process\n",
    "initiations_accel_corrected = []\n",
    "for init in movement_initiations_accel:\n",
    "    initiations_accel_corrected.append(init+(filtering_window-1))\n",
    "if len(initiations_accel_corrected) == len(movement_initiations_accel):\n",
    "    print('\\nThe initiations were corrected according to the window of the filter used :)')\n",
    "\n",
    "# plot only the periods of movement that fulfill the criteria/sequence\n",
    "\n",
    "# the end - you now have the initiations detected from the accelerometer :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7278a64",
   "metadata": {},
   "source": [
    "###### Skip till section 2.1.1.1\n",
    "This is for detecting a complete movement bout... not finished!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53d38515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descobrir indices onde o diff do indice+1 e igual a '-1', ou seja, desocbri a sequencia e depois dentro dessa sequencia\n",
    "# so vai a zero quando o original for a zero. assim nao estou a plotar apenas a sequencia mas o movimento original\n",
    "\n",
    "moving_accel_filtered_cg_diff = []\n",
    "for i in range(len(moving_accel_filtered_cg)):\n",
    "    moving_accel_filtered_cg_diff.append(moving_accel_filtered_cg[i]-moving_accel_filtered_cg[i-1])\n",
    "\n",
    "end_movement_sequences = []\n",
    "for i in range(len(moving_accel_filtered_cg_diff)):\n",
    "    if moving_accel_filtered_cg_diff[i] == -1:\n",
    "        end_movement_sequences.append(i-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9640dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_movement_sequences = []\n",
    "for i in range(len(moving_accel_filtered_cg_diff)):\n",
    "    if moving_accel_filtered_cg_diff[i] == -1:\n",
    "        end_movement_sequences.append(i-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only the periods of movement that fulfill the criteria/sequence - it is only coded to plot the sequence and not the \n",
    "# whole movin period\n",
    "movement_plot = np.zeros(len(moving_accel_filtered_cg))\n",
    "index_first_element_last_seq = len(moving_accel_filtered_cg)-len(sequence)\n",
    "for timestamp in range(index_first_element_last_seq + 1): # because range excludes the last value\n",
    "    if sum(moving_accel_filtered_cg[timestamp:timestamp+len(sequence)] == sequence) == len(sequence):\n",
    "        movement_plot[timestamp:timestamp+len(sequence)] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dfd304",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(movement_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d9a073",
   "metadata": {},
   "source": [
    "### 2.1.1.1 Plot - superimposing movement initiations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5fb813",
   "metadata": {},
   "source": [
    "##### Start by linearly interpolating the missing data... - this step should be performed in section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad3fd365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the diff() values of the timestamps are ideally multiples of the period of the signal, however it should be noted that \n",
    "# the real values are not perfect multiples\n",
    "\n",
    "# let's build a function that finds the nearest multiple of the accel's period, so that we can find the number of missing \n",
    "# 'timestamps' as (accel_ts/period - 1) - so, for example, a diff of 0.015 will stand for 2 missing ts\n",
    "def closestMultiple(n, x):\n",
    "    if x >= n:\n",
    "        return round(x/n)*n;\n",
    "    else:\n",
    "        return math.ceil(x/n)*n;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b242f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_accel = 1/fs\n",
    "round_accel_ts = []\n",
    "for i in range(1, len(df_acceldata_accel)):\n",
    "    round_accel_ts.append(closestMultiple(period_accel, df_acceldata_accel['Timestamp'].diff()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04078059",
   "metadata": {},
   "source": [
    "Total Accel..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bf3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array containing the number of data points missing in the correct index in which those points should be added\n",
    "missing_accel_ts = [0]\n",
    "for diff in round_accel_ts:\n",
    "    missing_accel_ts.append(diff/period_accel-1)\n",
    "\n",
    "# create a new array that has the value -1000 in the places in which data point values should be interpoalted\n",
    "total_accel_interpolation = []\n",
    "for missing, total_accel in zip(missing_accel_ts, df_acceldata_accel['Total_accel']):\n",
    "    # if no data point is missing in the current index of the array, then append the current value of acceleration\n",
    "    if missing == 0:\n",
    "        total_accel_interpolation.append(total_accel)\n",
    "    # if there is missing data, first add the value -1000 as many times as the number of missing data points and only than, add the current value of acceleration\n",
    "    else:\n",
    "        # for example, if missing == 2, two temporary points with the value -1000 will be appended to the array, to later be assinged an interpolated value\n",
    "        for i in range(int(missing)):\n",
    "            total_accel_interpolation.append(-1000)\n",
    "        total_accel_interpolation.append(total_accel)\n",
    "\n",
    "# make sure the array sizes match your predictions\n",
    "if len(total_accel_interpolation)-len(missing_accel_ts) == sum(missing_accel_ts):\n",
    "    print('We know where data is missing and the new array of accelerations was created correctly :). Now, I shall assign a linearly interpolated value of aceleration to every -1000!')\n",
    "else:\n",
    "    print('There is something wrong. Do not proceed until this criteria is met!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f376949",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(2)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e482586d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_accel_ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mmissing_accel_ts\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'missing_accel_ts' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(missing_accel_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "plt.plot(df_acceldata_accel[\"Total_accel\"])\n",
    "plt.plot(total_accel_interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8232c60",
   "metadata": {},
   "source": [
    "Timestamps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696258ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_accel_ts = [0]\n",
    "for diff in round_accel_ts:\n",
    "    missing_accel_ts.append(diff/period_accel-1)\n",
    "\n",
    "timestamps_accel_interpolation = []\n",
    "for missing, ts_accel in zip(missing_accel_ts, df_acceldata_accel['Timestamp']):\n",
    "    if missing == 0:\n",
    "        timestamps_accel_interpolation.append(ts_accel)\n",
    "    else:\n",
    "        for i in range(int(missing)):\n",
    "            timestamps_accel_interpolation.append(-1000)\n",
    "        timestamps_accel_interpolation.append(ts_accel)\n",
    "\n",
    "if len(timestamps_accel_interpolation)-len(missing_accel_ts) == sum(missing_accel_ts):\n",
    "    print('We know where timestamps are missing and the new array of timestamps was created correctly :). Now, I shall assign a linearly interpolated value of timestamp to every -1000!')\n",
    "else:\n",
    "    print('There is something wrong. Do not proceed until this criteria is met!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_indices_2study = []\n",
    "for i, value in enumerate(missing_accel_ts):\n",
    "    if value != 0:\n",
    "        print(i, value)\n",
    "        temp_indices_2study.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb01e7",
   "metadata": {},
   "source": [
    "Total Accel..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7fbb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finds the indices where the missing that is and assigns it the average point using the previous and the next accel values\n",
    "# if the number of missing timestamps is higher than one, compute the average point and than two other average point \n",
    "# ... (previous_non_negative to average and average to next_non_negative)\n",
    "\n",
    "# only works for non-consecutive missing data\n",
    "orig_idx_missing_data = []\n",
    "for i, accel_inst in zip(range(len(total_accel_interpolation)), total_accel_interpolation):\n",
    "    if accel_inst < 0 and total_accel_interpolation[i-1] >= 0 and total_accel_interpolation[i+1] >= 0:\n",
    "        orig_idx_missing_data.append(i)\n",
    "        total_accel_interpolation[i] = (total_accel_interpolation[i+1]+total_accel_interpolation[i-1])/2\n",
    "        print(i, round(total_accel_interpolation[i-1]-total_accel_interpolation[i],2), round(total_accel_interpolation[i]-total_accel_interpolation[i+1],2))\n",
    "        \n",
    "still_missing = []\n",
    "for i, accel_inst in zip(range(len(total_accel_interpolation)), total_accel_interpolation):\n",
    "    if accel_inst < 0:\n",
    "        still_missing.append(i)\n",
    "        orig_idx_missing_data.append(i)\n",
    "        \n",
    "still_missing = np.array(still_missing)\n",
    "still_missing = still_missing.reshape((int(len(still_missing)/2), 2))\n",
    "\n",
    "for tuple_missing in still_missing:\n",
    "    average_point = (total_accel_interpolation[tuple_missing[0]-1]+total_accel_interpolation[tuple_missing[1]+1])/2\n",
    "    first_tuple = (total_accel_interpolation[tuple_missing[0]-1]+average_point)/2\n",
    "    second_tuple = (average_point+total_accel_interpolation[tuple_missing[1]+1])/2\n",
    "    total_accel_interpolation[tuple_missing[0]] = first_tuple\n",
    "    total_accel_interpolation[tuple_missing[1]] = second_tuple\n",
    "    \n",
    "if -1000 not in total_accel_interpolation:\n",
    "    print('All missing data was linearly interpolated.')\n",
    "    print(\"\\nNow that we've corrected the acceleration signal, let's plot the initiations detected -+ 8 seconds\")\n",
    "    \n",
    "# IMPORTANT: this code assumes a maximum of 2 consecutive timestamps missing, if an error in this step emerges for other \n",
    "# videos, the first thing to check would be if there is 3 or more consecutive missing ts's in the accel data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67958f",
   "metadata": {},
   "source": [
    "Timestamps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the indices where the missing timestamps are and assigns it the average point using the previous and the next timestamp values\n",
    "# if the number of missing timestamps is higher than one, compute the average point and than two other average point\n",
    "# ... (previous_non_negative to average and average to next_non_negative)\n",
    "\n",
    "# only works for non-consecutive missing data\n",
    "orig_idx_missing_data = []\n",
    "for i, ts_inst in zip(range(len(timestamps_accel_interpolation)), timestamps_accel_interpolation):\n",
    "    if ts_inst < 0 and timestamps_accel_interpolation[i-1] >= 0 and timestamps_accel_interpolation[i+1] >= 0:\n",
    "        orig_idx_missing_data.append(i)\n",
    "        timestamps_accel_interpolation[i] = (\n",
    "            timestamps_accel_interpolation[i+1]+timestamps_accel_interpolation[i-1])/2\n",
    "        #print(i, round(timestamps_accel_interpolation[i-1]-timestamps_accel_interpolation[i], 2), round(\n",
    "            #timestamps_accel_interpolation[i]-timestamps_accel_interpolation[i+1], 2))\n",
    "\n",
    "still_missing = []\n",
    "for i, ts_inst in zip(range(len(timestamps_accel_interpolation)), timestamps_accel_interpolation):\n",
    "    if ts_inst < 0:\n",
    "        still_missing.append(i)\n",
    "        #print(i)\n",
    "        orig_idx_missing_data.append(i)\n",
    "\n",
    "still_missing = np.array(still_missing)\n",
    "still_missing = still_missing.reshape((int(len(still_missing)/2), 2))\n",
    "\n",
    "for tuple_missing in still_missing:\n",
    "    average_point = (\n",
    "        timestamps_accel_interpolation[tuple_missing[0]-1]+timestamps_accel_interpolation[tuple_missing[1]+1])/2\n",
    "    #print(average_point)\n",
    "    first_tuple = (\n",
    "        timestamps_accel_interpolation[tuple_missing[0]-1]+average_point)/2\n",
    "    #print(first_tuple)\n",
    "    second_tuple = (\n",
    "        average_point+timestamps_accel_interpolation[tuple_missing[1]+1])/2\n",
    "    #print(second_tuple)\n",
    "    timestamps_accel_interpolation[tuple_missing[0]] = first_tuple\n",
    "    timestamps_accel_interpolation[tuple_missing[1]] = second_tuple\n",
    "    #print(total_accel_interpolation[tuple_missing[0]], total_accel_interpolation[tuple_missing[1]])\n",
    "\n",
    "if -1000 not in timestamps_accel_interpolation:\n",
    "    print('All missing timestamps were linearly interpolated.')\n",
    "    print(\"\\nNow that we've corrected the acceleration signal, as well as the timestamps, let's plot the initiations detected -+ 8 seconds\")\n",
    "\n",
    "# IMPORTANT: this code assumes a maximum of 2 consecutive timestamps missing, if an error in this step emerges for other\n",
    "# videos, the first thing to check would be if there is 3 or more consecutive missing ts's in the accel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80608a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_acceldata_accel[\"Total_accel\"])\n",
    "plt.plot(df_timestamps_accel_interpolation[\"Total_accel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd28510",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_acceldata_accel[\"Timestamp\"].diff())\n",
    "plt.plot(df_timestamps_accel_interpolation[\"Timestamps\"].diff())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa464ce",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4862359",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -fs*8\n",
    "# initiation plus 8 sec\n",
    "end_plot = fs*8+1\n",
    "\n",
    "for init_corrected in initiations_accel_corrected:\n",
    "    if init_corrected < fs*8:\n",
    "        plt.plot(range(-init_corrected, end_plot), total_accel_interpolation[0:init_corrected+end_plot])\n",
    "        count_1+=1\n",
    "    # check if it should be < or <= !!!\n",
    "    elif len(total_accel_interpolation) - init_corrected < fs*8:\n",
    "        plt.plot(range(int(beg_plot), int(len(total_accel_interpolation)-init_corrected)), total_accel_interpolation[int(init_corrected+beg_plot) : int(len(total_accel_interpolation)+end_plot)])\n",
    "        count_2+=1\n",
    "    else:\n",
    "        plt.plot(range(beg_plot, end_plot), total_accel_interpolation[int(init_corrected+beg_plot):int(init_corrected+end_plot)])\n",
    "        count_3+=1\n",
    "        \n",
    "plt.title('Movement initiation obtained from the total body acceleration')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Acceleration')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')  #vertical line\n",
    "\n",
    "# make sure no initiation is missing\n",
    "print((count_1+count_2+count_3)==len(initiations_accel_corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c15bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe where both the timestamps and accel values interpolated will be stored\n",
    "df_timestamps_accel_interpolation = pd.DataFrame(\n",
    "    timestamps_accel_interpolation)\n",
    "\n",
    "# change the name of the column containing the timestamps\n",
    "df_timestamps_accel_interpolation = df_timestamps_accel_interpolation.rename(\n",
    "    columns={0: 'Timestamps'})\n",
    "# add the complete (interpolated) total body acceleration data to the df\n",
    "df_timestamps_accel_interpolation['Total_accel'] = total_accel_interpolation\n",
    "\n",
    "# show the df\n",
    "df_timestamps_accel_interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37773b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_acceldata_accel[\"Total_accel\"])\n",
    "plt.plot(df_timestamps_accel_interpolation[\"Total_accel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d0d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1, constrained_layout=False)\n",
    "\n",
    "ax1.set_title(\"df_timestamps_accel_interpolation['Timestamps'].diff()\")\n",
    "ax1.plot(df_timestamps_accel_interpolation[\"Timestamps\"].diff())\n",
    "ax1.scatter(temp_indices_2study, 0.005*np.ones(len(temp_indices_2study)), c=\"r\")\n",
    "\n",
    "ax2.set_title(\"df_acceldata_accel['Timestamps'].diff()\")\n",
    "ax2.plot(df_acceldata_accel[\"Timestamp\"].diff())\n",
    "ax2.scatter(temp_indices_2study, 0.005*np.ones(len(temp_indices_2study)), c=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79267363",
   "metadata": {},
   "source": [
    "### 2.1.1.2 Plot - average of the initiations above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e897566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_initiations_accel_sequence_interest = pd.DataFrame()\n",
    "\n",
    "time_sec = 2\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -fs*time_sec\n",
    "# initiation plus 8 sec\n",
    "end_plot = fs*time_sec+1\n",
    "\n",
    "for init_corrected in initiations_accel_corrected:\n",
    "    if init_corrected < fs*time_sec:\n",
    "        arr = np.array(total_accel_interpolation[0:int(init_corrected+end_plot)])\n",
    "        zeros_ = (fs*time_sec*2+1) - len(arr)\n",
    "        df_initiations_accel_sequence_interest[init_corrected] = np.concatenate((np.zeros(zeros_), arr))\n",
    "    elif len(total_accel_interpolation) - init_corrected < fs*time_sec:\n",
    "        arr = np.array(total_accel_interpolation[int(init_corrected+beg_plot):int(len(total_accel_interpolation)+1)])\n",
    "        zeros_ = (fs*time_sec*2+1) - len(arr)\n",
    "        df_initiations_accel_sequence_interest[init_corrected] = np.concatenate((arr, np.zeros(zeros_)))\n",
    "    else:\n",
    "        arr = np.array(total_accel_interpolation[int(init_corrected+beg_plot):int(init_corrected+end_plot)])\n",
    "        df_initiations_accel_sequence_interest[init_corrected] = arr\n",
    "\n",
    "mean_accel = df_initiations_accel_sequence_interest.mean(axis=1)\n",
    "\n",
    "std_accel = df_initiations_accel_sequence_interest.std(axis=1)\n",
    "\n",
    "std_error_accel = std_accel/math.sqrt(len(initiations_accel_corrected))\n",
    "\n",
    "df_initiations_accel_sequence_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to look at these line!!!\n",
    "# example of initiation\n",
    "\n",
    "df_initiations_accel_sequence_interest[6835.0][fs*time_sec] == total_accel_interpolation[6835] #CORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c9e51",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sec=2\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -fs*time_sec\n",
    "# initiation plus 8 sec\n",
    "end_plot = fs*time_sec+1\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_initiations_accel_sequence_interest.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_accel - std_error_accel,\n",
    "                 mean_accel + std_error_accel, alpha = 0.2)\n",
    "\n",
    "plt.title('Movement initiation obtained from the total body acceleration')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Acceleration')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -num_points_stopped\n",
    "end_seq = num_points_moving\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', \"alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b499f0",
   "metadata": {},
   "source": [
    "### 2.1.1.3 Right hindlimb heel velocity aligned to the initiations detected using the total body acceleration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_timestamps_accel_interpolation[\"Timestamps\"])-len(df_acceldata_accel['Timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c133093",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_timestamps_accel_interpolation['Timestamps'].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the timestamps of the initiations - accelerometer\n",
    "ts_initiations_accel = []\n",
    "for i in range(len(df_acceldata_accel['Timestamp'])):\n",
    "    if i in initiations_accel_corrected:\n",
    "        ts_initiations_accel.append(df_acceldata_accel['Timestamp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(arr, val):\n",
    "    idx = np.abs(arr - val).argmin()\n",
    "    return arr[idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7092a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closest_ts_to_accel_init = []\n",
    "for ts in ts_initiations_accel:\n",
    "    closest_ts = find_closest(df_vel['Vel - Timestamp'], ts)\n",
    "    closest_ts_to_accel_init.append(closest_ts)\n",
    "    \n",
    "indices_closest_ts_to_accel_init = []\n",
    "for ts in closest_ts_to_accel_init:\n",
    "    indices_closest_ts_to_accel_init.append(df_vel['Vel - Timestamp'].loc[df_vel['Vel - Timestamp']==ts])\n",
    "    \n",
    "for i, j in zip(indices_closest_ts_to_accel_init, range(len(indices_closest_ts_to_accel_init))):\n",
    "    indices_closest_ts_to_accel_init[j] = i.index[0] \n",
    "    \n",
    "# this array represents the indices of the velocity (right_hindlimb_heel) whose timestamps are the closest to the \n",
    "# timestamps of the initiations calculated using data from the accelerometer\n",
    "indices_closest_ts_to_accel_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "# -8 segundos\n",
    "beg_plot = -240\n",
    "# +8 segundos\n",
    "end_plot = 241\n",
    "\n",
    "for index in indices_closest_ts_to_accel_init:\n",
    "    if index < 240:\n",
    "        plt.plot(range(-index, end_plot), df_vel['V_xy_right_hindlimb_heel'][0:index+end_plot])\n",
    "        count_1+=1\n",
    "    # check if it should be < or <= !!!\n",
    "    elif len(df_vel) - index < 240:\n",
    "        plt.plot(range(beg_plot, len(df_vel)-index), df_vel['V_xy_right_hindlimb_heel'][index+beg_plot : len(df_vel)+end_plot])\n",
    "        count_2+=1\n",
    "    else:\n",
    "        plt.plot(range(beg_plot, end_plot), df_vel['V_xy_right_hindlimb_heel'][index+beg_plot:index+end_plot])\n",
    "        count_3+=1\n",
    "        \n",
    "plt.title('Velocity of the right hindlimb heel aligned to accelerometer initiations')\n",
    "plt.xlabel('Time (fr)')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')  #vertical line\n",
    "\n",
    "# make sure no initiation is missing\n",
    "print((count_1+count_2+count_3)==len(indices_closest_ts_to_accel_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_velocities_aligned_to_accel = pd.DataFrame()\n",
    "\n",
    "camera_aq_rate = 30 #Hz\n",
    "\n",
    "time_sec = 2\n",
    "beg_plot = -camera_aq_rate*time_sec\n",
    "end_plot = camera_aq_rate*time_sec+1\n",
    "\n",
    "for index in indices_closest_ts_to_accel_init:\n",
    "    if index < camera_aq_rate*time_sec:\n",
    "        arr = np.array(df_vel['V_xy_right_hindlimb_heel'][0:int(index+end_plot)])\n",
    "        zeros_ = (camera_aq_rate*time_sec+1) - len(arr)\n",
    "        df_velocities_aligned_to_accel[index] = np.concatenate((np.zeros(zeros_), arr))\n",
    "    elif len(df_vel['V_xy_right_hindlimb_heel']) - index < camera_aq_rate*time_sec:\n",
    "        arr = np.array(df_vel['V_xy_right_hindlimb_heel'][int(index+beg_plot):int(len(df_vel['V_xy_right_hindlimb_heel'])+1)])\n",
    "        zeros_ = (camera_aq_rate*time_sec+1) - len(arr)\n",
    "        df_velocities_aligned_to_accel[index] = np.concatenate((arr, np.zeros(zeros_)))\n",
    "    else:\n",
    "        arr = np.array(df_vel['V_xy_right_hindlimb_heel'][int(index+beg_plot):int(index+end_plot)])\n",
    "        df_velocities_aligned_to_accel[index] = arr\n",
    "\n",
    "mean_velocity = df_velocities_aligned_to_accel.mean(axis=1)\n",
    "\n",
    "std_velocity = df_velocities_aligned_to_accel.std(axis=1)\n",
    "\n",
    "std_error_velocity = std_velocity/math.sqrt(len(indices_closest_ts_to_accel_init))\n",
    "\n",
    "df_velocities_aligned_to_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe56ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to look at these line!!!\n",
    "# example of initiation\n",
    "\n",
    "df_velocities_aligned_to_accel[1024][60] == df_vel['V_xy_right_hindlimb_heel'][1024] #CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4536002e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(beg_plot, end_plot), df_velocities_aligned_to_accel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_velocity - std_error_velocity,\n",
    "                 mean_velocity + std_error_velocity, alpha = 0.2)\n",
    "\n",
    "plt.title('Velocity psth aligned to accelerometer initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240ac5a",
   "metadata": {},
   "source": [
    "##### Plot the initiations detected using the acceleration data, as well as the velocities aligned to the moments of initiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "mean_accel = df_initiations_accel_sequence_interest.mean(axis=1)\n",
    "\n",
    "std_accel = df_initiations_accel_sequence_interest.std(axis=1)\n",
    "\n",
    "std_error_accel = std_accel/math.sqrt(len(initiations_accel_corrected))\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -fs*8\n",
    "# initiation plus 8 sec\n",
    "end_plot = fs*8+1\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_initiations_accel_sequence_interest.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_accel - std_error_accel,\n",
    "                 mean_accel + std_error_accel, alpha = 0.2)\n",
    "\n",
    "plt.title('Movement initiation obtained from the total body acceleration')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Acceleration')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -num_points_stopped\n",
    "end_seq = num_points_moving\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)\n",
    "\n",
    "#########################################################################################################################\n",
    "plt.subplot(2,1,2)\n",
    "mean_velocity = df_velocities_aligned_to_accel.mean(axis=1)\n",
    "\n",
    "std_velocity = df_velocities_aligned_to_accel.std(axis=1)\n",
    "\n",
    "std_error_velocity = std_velocity/math.sqrt(len(indices_closest_ts_to_accel_init))\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot = 241\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_velocities_aligned_to_accel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_velocity - std_error_velocity,\n",
    "                 mean_velocity + std_error_velocity, alpha = 0.2)\n",
    "\n",
    "plt.title('Velocity aligned to accelerometer initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d68b8",
   "metadata": {},
   "source": [
    "## 2.1.2 Detecting initiations using the velocities (DLC predictions) - right hind paw\n",
    "\n",
    "Define a criteria with the likelihood of the DLC predictions (for example, only consider initiations in which all the elements of the sequence of interest (300 ms stoped and 500 ms moving) have a likelihood of at least 0.99) - round the likelihoods to 2 decimal cases -> on the current version, not criteria was yet implemented regarding likelihood of DLC predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de034d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a new dataframe containing the V_xy filtered with a window of 10 \n",
    "# frames for detection of movement bouts\n",
    "df_vel_filtered = pd.DataFrame()\n",
    "\n",
    "window_vel_filtered = 10\n",
    "for column in df_vel.columns:\n",
    "    if 'V_xy' in column:\n",
    "        velocity_filtered = moving_average(df_vel[column], window_vel_filtered)\n",
    "        df_vel_filtered[column] = velocity_filtered\n",
    "    elif 'likelihood' in column:\n",
    "        df_vel_filtered[column] = df_vel[column]\n",
    "        \n",
    "if len(df_vel_filtered) == len(df_vel)-(window_vel_filtered-1):\n",
    "    print('The dataframe with the filtered velocities has the correct length.')\n",
    "else:\n",
    "    print('The length of the dataframe with the filtered velocities is incorrect!')\n",
    "\n",
    "df_vel_filtered['Timestamp'] = df_vel['Vel - Timestamp'][:-9]\n",
    "    \n",
    "df_vel_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e3df20",
   "metadata": {},
   "source": [
    "##### Local minimum between the two modes of a bimodal distribution (ideally) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider a movement initiation every time the velocity raises above \n",
    "#...the beginning of a local minimum in the log distribution of velocities\n",
    "#...the local minimum is to be found in the valley forming the two peaks of\n",
    "#...the log_scale distribution\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# velocity regularly calculated (from the original predicitons of x,y)\n",
    "ax1_heel = sns.kdeplot(df_vel['V_xy_right_hindlimb_heel']+0.000001, log_scale = True)\n",
    "# velocity filtered using a simple moving average of 10 frames \n",
    "ax2_heel = sns.kdeplot(df_vel_filtered['V_xy_right_hindlimb_heel'], log_scale=True)\n",
    "\n",
    "kde_curve1_heel = ax1_heel.lines[0]\n",
    "kde_curve2_heel = ax2_heel.lines[1]\n",
    "\n",
    "x1_heel = kde_curve1_heel.get_xdata()\n",
    "y1_heel = kde_curve1_heel.get_ydata()\n",
    "\n",
    "x2_heel = kde_curve2_heel.get_xdata()\n",
    "y2_heel = kde_curve2_heel.get_ydata()\n",
    "\n",
    "plt.plot(x1_heel, y1_heel)\n",
    "peaks1_heel = np.where((y1_heel[1:-1] > y1_heel[0:-2]) * (y1_heel[1:-1] > y1_heel[2:]))[0] + 1\n",
    "dips1_heel = np.where((y1_heel[1:-1] < y1_heel[0:-2]) * (y1_heel[1:-1] < y1_heel[2:]))[0] + 1\n",
    "\n",
    "plt.plot(x1_heel, y1_heel, color='cyan')\n",
    "plt.plot(x1_heel[peaks1_heel], y1_heel[peaks1_heel], 'o')\n",
    "plt.plot(x1_heel[dips1_heel], y1_heel[dips1_heel], 'o')\n",
    "plt.show()\n",
    "\n",
    "peaks2_heel = np.where((y2_heel[1:-1] > y2_heel[0:-2]) * (y2_heel[1:-1] > y2_heel[2:]))[0] + 1\n",
    "dips2_heel = np.where((y2_heel[1:-1] < y2_heel[0:-2]) * (y2_heel[1:-1] < y2_heel[2:]))[0] + 1\n",
    "\n",
    "plt.plot(x2_heel, y2_heel, color='orange')\n",
    "plt.plot(x2_heel[peaks2_heel], y2_heel[peaks2_heel], 'o')\n",
    "plt.plot(x2_heel[dips2_heel], y2_heel[dips2_heel], 'o')\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(peaks2_heel)):\n",
    "    # this is tricky, since some distributions may be multimodal\n",
    "    cutOff2_heel = x2_heel[dips2_heel[-1]]\n",
    "    break\n",
    "print(cutOff2_heel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b948338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# creates an array of 1s and 0s according to the cutOff from the previous cell\n",
    "# to get an overall ideia of what is being captured: movement bouts, individual paw movements,...\n",
    "moving_with_paw = []\n",
    "for inst_vel in range(len(df_vel_filtered)):\n",
    "    if df_vel_filtered['V_xy_right_hindlimb_heel'][inst_vel] >= cutOff2_heel:\n",
    "        moving_with_paw.append(1)\n",
    "        #moving_with_paw.append(10) #for better visualization, temporarily change to .append(10)\n",
    "    else:\n",
    "        moving_with_paw.append(0)\n",
    "\n",
    "plt.plot(df_vel['V_xy_right_hindlimb_heel'])\n",
    "plt.plot(df_vel_filtered['V_xy_right_hindlimb_heel'])\n",
    "plt.plot(moving_with_paw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdcd4c4",
   "metadata": {},
   "source": [
    "##### Crossing point between two gaussians fitted to the kernel density estimation... - working on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b169094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the treshold - working on it\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "y,x,_=plt.hist(np.log(velocity_filtered), bins=100, color='lightblue')\n",
    "\n",
    "x=(x[1:]+x[:-1])/2 \n",
    "\n",
    "def gauss(x, mu, sigma, A):\n",
    "    return A*np.exp(-(x-mu)**2/2/sigma**2) \n",
    "\n",
    "def bimodal(x, mu1, sigma1, A1, mu2, sigma2, A2):\n",
    "    return gauss(x, mu1, sigma1, A1)+gauss(x, mu2, sigma2, A2)\n",
    "\n",
    "def multimodal_3(x, mu1, sigma1, A1, mu2, sigma2, A2, mu3, sigma3, A3):\n",
    "    return gauss(x, mu1, sigma1, A1)+gauss(x, mu2, sigma2, A2)+gauss(x, mu3, sigma3, A3)\n",
    "    \n",
    "# maybe define the expected values from the data: in this case, I can find the max count value and use it or A1 and A2\n",
    "expected = (-1, .1, max(y)/2, 2, .1, max(y)/2)\n",
    "params, cov = curve_fit(bimodal, x, y, expected, \n",
    "                        #[[lower], [upper]] bounds for mu1, sigma1, A1, mu2, sigma2, A2\n",
    "                        bounds=[[-np.inf, 0, 0, -np.inf, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf]]) \n",
    "sigma=np.sqrt(np.diag(cov))\n",
    "x_fit = np.linspace(x.min(), x.max(), 500)\n",
    "f = gauss(x_fit, *params[:3])\n",
    "g = gauss(x_fit, *params[3:])\n",
    "#print(pd.DataFrame(data={'params': params, 'sigma': sigma}, index=bimodal.__code__.co_varnames[1:]))\n",
    "plt.plot(x_fit, bimodal(x_fit, *params), color='red', lw=3, label='model')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[:3]), color='red', ls='--')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[3:]), color='red', ls=':')\n",
    "\n",
    "first_line = LineString(np.column_stack((x_fit, f)))\n",
    "second_line = LineString(np.column_stack((x_fit, g)))\n",
    "intersection = first_line.intersection(second_line)\n",
    "\n",
    "if intersection.geom_type == 'MultiPoint':\n",
    "    plt.plot(*LineString(intersection).xy, 'o')\n",
    "elif intersection.geom_type == 'Point':\n",
    "    plt.plot(*intersection.xy, 'o', color='orange')\n",
    "\n",
    "#not the real cutoff since I used the log of the data (as such, it should be applied to the log accel series)\n",
    "cutOff_heel_filtered_cg = LineString(intersection).xy[0][0]\n",
    "cutOff_heel_filtered_cg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6dce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# creates an array of 1s and 0s according to the cutOff from the previous cell\n",
    "# to get an overall ideia of what is being captured: movement bouts, individual paw movements,...\n",
    "moving_with_paw_cg = []\n",
    "for inst_vel in range(len(df_vel_filtered)):\n",
    "    if np.log(df_vel_filtered['V_xy_right_hindlimb_heel'][inst_vel]) >= cutOff_heel_filtered_cg:\n",
    "        moving_with_paw_cg.append(1)\n",
    "    else:\n",
    "        moving_with_paw_cg.append(0)\n",
    "\n",
    "plt.plot(st.zscore(df_vel['V_xy_right_hindlimb_heel']))\n",
    "plt.plot(st.zscore(df_vel_filtered['V_xy_right_hindlimb_heel']))\n",
    "plt.plot(st.zscore(moving_with_paw_cg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e4c6e",
   "metadata": {},
   "source": [
    "#### The sequence of interest was first created as 300 ms of velocity under the selected treshold, followed by 500 ms of velocity above the treshold. Another approach could be 300 ms of velocity under the selected treshold, followed by 15 frames (500 ms) from which at least 12 have to be above the velocity treshold (to reduce the number of false negatives - less specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481aef4",
   "metadata": {},
   "source": [
    "#### Using moving_with_paw (10 window filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b0ded",
   "metadata": {},
   "source": [
    "##### a) 300ms 0, followed by 500ms 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb5d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_of_interest = []\n",
    "for i in range(9):\n",
    "    sequence_of_interest.append(0)\n",
    "for i in range(15):\n",
    "    sequence_of_interest.append(1)\n",
    "sequence_of_interest # len(sequence_of_interest) == 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all sequences following the criteria\n",
    "initiation_right_paw = []\n",
    "index_first_element_last_seq = len(moving_with_paw)-24\n",
    "for frame in range(index_first_element_last_seq + 1): # because range excludes the last value\n",
    "    if moving_with_paw[frame:frame+24] == sequence_of_interest:\n",
    "        initiation_right_paw.append(frame+8) #+8 considers the last zero as the initiation; +9 considers the first 1 as the init\n",
    "initiation_right_paw\n",
    "\n",
    "'''# sequences following the criteria that have max 5 elements \n",
    "# of likelihood < 0.5\n",
    "initiation_right_paw = []\n",
    "index_first_element_last_seq = len(moving_with_paw)-24\n",
    "for frame in range(index_first_element_last_seq + 1): # because range excludes the last value\n",
    "    if moving_with_paw[frame:frame+24] == sequence_of_interest:\n",
    "        count=0\n",
    "        for likelihood in df_vel_filtered['V_xy_right_hindlimb_heel'][frame:frame+24]:\n",
    "            if round(likelihood, 2) < 0.5:\n",
    "                count+=1\n",
    "        if count > 5:\n",
    "            break\n",
    "        initiation_right_paw.append(frame+8) #+8 considers the last zero as the initiation; +9 considers the first 1 as the init\n",
    "initiation_right_paw'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(moving_with_paw, color = 'g')\n",
    "for init in initiation_right_paw:\n",
    "    plt.axvline(x=init, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d52b8",
   "metadata": {},
   "source": [
    "#### Now, notice that there is a correction to be made: the filter introduced a positive phase in the signal, and so I will sum the proper amount to every result from initiations_right_paw and visually inspect the signal again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97852e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "initiation_right_paw_corrected = []\n",
    "for init in initiation_right_paw:\n",
    "    initiation_right_paw_corrected.append(init+9)\n",
    "initiation_right_paw_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocities calculated directly from the x,y DLC predictions\n",
    "plt.plot(df_vel['V_xy_right_hindlimb_heel'])\n",
    "# velocity filtered with a moving average (with a 10 fr window)\n",
    "plt.plot(df_vel_filtered['V_xy_right_hindlimb_heel'])\n",
    "# treshold for movement initiation (of the heel - DLC predictions)\n",
    "plt.hlines(cutOff2_heel, 0, len(df_vel), color='green')\n",
    "# here, initiations are correct \n",
    "for init in initiation_right_paw_corrected:\n",
    "    plt.axvline(x=init, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e515bd",
   "metadata": {},
   "source": [
    "### 2.1.2.1 Plot - superimposing movement initiations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad79da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "beg_plot = -60\n",
    "end_plot = 61\n",
    "\n",
    "for init_corrected in initiation_right_paw_corrected:\n",
    "    if init_corrected < 60:\n",
    "        plt.plot(range(-init_corrected, end_plot), df_vel['V_xy_right_hindlimb_heel'][0:init_corrected+end_plot])\n",
    "        count_1+=1\n",
    "    # check if it should be < or <= !!!\n",
    "    elif len(df_vel) - init_corrected < 60:\n",
    "        plt.plot(range(beg_plot, len(df_vel)-init_corrected), df_vel['V_xy_right_hindlimb_heel'][init_corrected+beg_plot : len(df_vel)+end_plot])\n",
    "        count_2+=1\n",
    "    else:\n",
    "        plt.plot(range(beg_plot, end_plot), df_vel['V_xy_right_hindlimb_heel'][init_corrected+beg_plot:init_corrected+end_plot])\n",
    "        count_3+=1\n",
    "        \n",
    "plt.title('Initiation of movement bouts involving the right paw')\n",
    "plt.xlabel('Time (fr)')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "'''#2. Remove ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])'''\n",
    "\n",
    "X_POSITION = 0\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')  #vertical line\n",
    "\n",
    "# make sure no initiation is missing\n",
    "print((count_1+count_2+count_3)==len(initiation_right_paw_corrected))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1a269",
   "metadata": {},
   "source": [
    "### 2.1.2.2 Plot - average of the initiations above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf225fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_initiations_sequence_interest = pd.DataFrame()\n",
    "\n",
    "beg_plot = -60\n",
    "end_plot = 61\n",
    "\n",
    "for init_corrected in initiation_right_paw_corrected:\n",
    "    if init_corrected < 60:\n",
    "        arr = np.array(df_vel['V_xy_right_hindlimb_heel'][0:init_corrected+end_plot])\n",
    "        zeros_ = 121 - len(arr)\n",
    "        df_initiations_sequence_interest[init_corrected] = np.concatenate((np.zeros(zeros_), arr))\n",
    "    elif len(df_vel) - init_corrected < 60:\n",
    "        arr = np.array(df_vel['V_xy_right_hindlimb_heel'][init_corrected+beg_plot:len(df_vel)+1])\n",
    "        zeros_ = 121 - len(arr)\n",
    "        df_initiations_sequence_interest[init_corrected] = np.concatenate((arr, np.zeros(zeros_)))\n",
    "    else:\n",
    "        arr = np.array(df_vel['V_xy_right_hindlimb_heel'][init_corrected+beg_plot:init_corrected+end_plot])\n",
    "        df_initiations_sequence_interest[init_corrected] = arr\n",
    "\n",
    "mean_ = df_initiations_sequence_interest.mean(axis=1)\n",
    "\n",
    "std_ = df_initiations_sequence_interest.std(axis=1)\n",
    "\n",
    "std_error = std_/math.sqrt(len(initiation_right_paw_corrected))\n",
    "\n",
    "df_initiations_sequence_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a56e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to look at these line!!!\n",
    "# example of initiation\n",
    "\n",
    "df_initiations_sequence_interest[567][60] == df_vel['V_xy_right_hindlimb_heel'][567] \n",
    "# CORRECT - after 120 frames (2sec; indexes: 0-119); initiation is frame 120, which should correspond to the frame of index\n",
    "# init_corrected from list initiations_right_paw_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ce675",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(beg_plot, end_plot), df_initiations_sequence_interest.mean(axis=1))\n",
    "mean_ = df_initiations_sequence_interest.mean(axis=1)\n",
    "std_error = (df_initiations_sequence_interest.std(axis=1)/math.sqrt(len(initiation_right_paw_corrected))) #standard error\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_ - std_error,\n",
    "                 mean_ + std_error, alpha = 0.2)\n",
    "\n",
    "plt.title('Movement initiations involving the right paw')\n",
    "plt.xlabel('Time (fr)')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a411f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "range(beg_plot, end_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da241be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2,2,121), df_initiations_sequence_interest.mean(axis=1))\n",
    "mean_ = df_initiations_sequence_interest.mean(axis=1)\n",
    "std_error = (df_initiations_sequence_interest.std(axis=1)/math.sqrt(len(initiation_right_paw_corrected))) #standard error\n",
    "plt.fill_between(np.linspace(-2,2,121), \n",
    "                 mean_ - std_error,\n",
    "                 mean_ + std_error, alpha = 0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de530b82",
   "metadata": {},
   "source": [
    "### 2.1.2.3 Total body acceleration aligned to the initiations detected using the velocities calculated from the DLC predicted coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_initiations_vel = []\n",
    "for i in range(len(df_vel['Vel - Timestamp'][:-9])):\n",
    "    if i in initiation_right_paw_corrected:\n",
    "        ts_initiations_vel.append(df_vel['Vel - Timestamp'][i])\n",
    "        \n",
    "# another method could be...\n",
    "# ts_initiations_vel = df_vel['Vel - Timestamp'][initiation_right_paw_corrected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(arr, val):\n",
    "    idx = np.abs(arr - val).argmin()\n",
    "    return arr[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d427ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_ts_to_vel_init = []\n",
    "for ts in ts_initiations_vel:\n",
    "    closest_ts = find_closest(df_timestamps_accel_interpolation['Timestamps'], ts)\n",
    "    closest_ts_to_vel_init.append(closest_ts)\n",
    "    \n",
    "indices_closest_ts_to_vel_init = []\n",
    "for ts in closest_ts_to_vel_init:\n",
    "    indices_closest_ts_to_vel_init.append(df_timestamps_accel_interpolation['Timestamps'].loc[df_timestamps_accel_interpolation['Timestamps']==ts])\n",
    "    \n",
    "for i, j in zip(indices_closest_ts_to_vel_init, range(len(indices_closest_ts_to_vel_init))):\n",
    "    indices_closest_ts_to_vel_init[j] = i.index[0] \n",
    "    \n",
    "indices_closest_ts_to_vel_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d219657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "time_sec=2\n",
    "# -8 segundos\n",
    "beg_plot = -fs*time_sec\n",
    "# +8 segundos\n",
    "end_plot = fs*time_sec+1\n",
    "\n",
    "for index in indices_closest_ts_to_vel_init:\n",
    "    if index < fs*time_sec:\n",
    "        plt.plot(range(-index, end_plot), df_timestamps_accel_interpolation['Total_accel'][0:index+end_plot])\n",
    "        count_1+=1\n",
    "    # check if it should be < or <= !!!\n",
    "    elif len(df_timestamps_accel_interpolation) - index < fs*time_sec:\n",
    "        plt.plot(range(beg_plot, len(df_timestamps_accel_interpolation)-index), df_timestamps_accel_interpolation['Total_accel'][index+beg_plot:len(df_timestamps_accel_interpolation)+end_plot])\n",
    "        count_2+=1\n",
    "    else:\n",
    "        plt.plot(range(beg_plot, end_plot), df_timestamps_accel_interpolation['Total_accel'][index+beg_plot:index+end_plot])\n",
    "        count_3+=1\n",
    "        \n",
    "plt.title('Total body acceleration aligned to velocity initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total body acceleration')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')  #vertical line\n",
    "\n",
    "# make sure no initiation is missing\n",
    "print((count_1+count_2+count_3)==len(indices_closest_ts_to_vel_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_accel_aligned_to_vel = pd.DataFrame()\n",
    "\n",
    "for index in indices_closest_ts_to_vel_init:\n",
    "    if index < fs*time_sec:\n",
    "        arr = np.array(df_timestamps_accel_interpolation['Total_accel'][0:int(index+end_plot)])\n",
    "        zeros_ = (fs*time_sec*2+1) - len(arr)\n",
    "        df_accel_aligned_to_vel[index] = np.concatenate((np.zeros(zeros_), arr))\n",
    "    elif len(df_timestamps_accel_interpolation['Total_accel']) - index < fs*time_sec:\n",
    "        arr = np.array(df_timestamps_accel_interpolation['Total_accel'][int(index+beg_plot):int(len(df_timestamps_accel_interpolation)+1)])\n",
    "        zeros_ = (fs*time_sec*2+1) - len(arr)\n",
    "        df_accel_aligned_to_vel[index] = np.concatenate((arr, np.zeros(zeros_)))\n",
    "    else:\n",
    "        arr = np.array(df_timestamps_accel_interpolation['Total_accel'][int(index+beg_plot):int(index+end_plot)])\n",
    "        df_accel_aligned_to_vel[index] = arr\n",
    "\n",
    "mean_accel_ = df_accel_aligned_to_vel.mean(axis=1)\n",
    "\n",
    "std_accel_ = df_accel_aligned_to_vel.std(axis=1)\n",
    "\n",
    "std_error_accel_ = std_accel_/math.sqrt(len(indices_closest_ts_to_vel_init))\n",
    "\n",
    "df_accel_aligned_to_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d06f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to look at these line!!!\n",
    "# example of initiation\n",
    "\n",
    "df_accel_aligned_to_vel[1456][fs*time_sec] == df_timestamps_accel_interpolation['Total_accel'][1456] #CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515be9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_accel_aligned_to_vel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_accel_ - std_error_accel_,\n",
    "                 mean_accel_ + std_error_accel_, alpha = 0.2)\n",
    "\n",
    "plt.title('Total body acceleration psth aligned to velocity initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total body acceleration')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -num_points_stopped\n",
    "end_seq = num_points_moving\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e5ff8",
   "metadata": {},
   "source": [
    "##### Plot the initiations detected using the velocities (DLC), as well as the total body acceleration aligned to the moments of initiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74582e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_vel_8sec = pd.DataFrame()\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot_8 = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot_8 = 241\n",
    "\n",
    "for init in initiation_right_paw_corrected:\n",
    "    if init < 240:\n",
    "        arr = np.array(df_vel['V_xy_right_hindlimb_heel'][0:int(init+end_plot_8)])\n",
    "        zeros_ = (240*2+1) - len(arr)\n",
    "        df_vel_8sec[init] = np.concatenate((np.zeros(zeros_), arr))\n",
    "    elif len(df_vel['V_xy_right_hindlimb_heel']) - init < 240:\n",
    "        arr = np.array(df_vel['V_xy_right_hindlimb_heel'][int(init+beg_plot_8):int(len(df_vel['V_xy_right_hindlimb_heel'])+1)])\n",
    "        zeros_ = (240*2+1) - len(arr)\n",
    "        df_vel_8sec[init] = np.concatenate((arr, np.zeros(zeros_)))\n",
    "    else:\n",
    "        arr = np.array(df_vel['V_xy_right_hindlimb_heel'][int(init+beg_plot_8):int(init+end_plot_8)])\n",
    "        df_vel_8sec[init] = arr\n",
    "\n",
    "mean_velocity_8sec = df_vel_8sec.mean(axis=1)\n",
    "\n",
    "std_velocity_8sec = df_vel_8sec.std(axis=1)\n",
    "\n",
    "std_error_velocity_8sec = std_velocity_8sec/math.sqrt(len(initiation_right_paw_corrected))\n",
    "\n",
    "df_vel_8sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to look at these line!!!\n",
    "# example of initiation\n",
    "\n",
    "df_vel_8sec[218][240] == df_vel['V_xy_right_hindlimb_heel'][218] #CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ef5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiation minus 8 sec\n",
    "beg_plot_8 = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot_8 = 241\n",
    "\n",
    "print(beg_plot_8, end_plot_8)\n",
    "\n",
    "plt.plot(range(beg_plot_8, end_plot_8), df_vel_8sec.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot_8, end_plot_8), \n",
    "                 mean_velocity_8sec - std_error_velocity_8sec,\n",
    "                 mean_velocity_8sec + std_error_velocity_8sec, alpha = 0.2)\n",
    "\n",
    "plt.title('Movement initiations with the right paw')\n",
    "plt.xlabel('Time (fr)')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4669b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "# initiation minus 8 sec\n",
    "beg_plot_8 = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot_8 = 241\n",
    "\n",
    "print(beg_plot_8, end_plot_8)\n",
    "\n",
    "plt.plot(range(beg_plot_8, end_plot_8), df_vel_8sec.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot_8, end_plot_8), \n",
    "                 mean_velocity_8sec - std_error_velocity_8sec,\n",
    "                 mean_velocity_8sec + std_error_velocity_8sec, alpha = 0.2)\n",
    "\n",
    "plt.title('Movement initiations with the right paw')\n",
    "plt.xlabel('Time (fr)')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)\n",
    "##########################################################################################################################\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -fs*8\n",
    "# initiation plus 8 sec\n",
    "end_plot = fs*8+1\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_accel_aligned_to_vel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_accel_ - std_error_accel_,\n",
    "                 mean_accel_ + std_error_accel_, alpha = 0.2)\n",
    "\n",
    "plt.title('Total body acceleration aligned to velocity initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total body acceleration')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -num_points_stopped\n",
    "end_seq = num_points_moving\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380aca8",
   "metadata": {},
   "source": [
    "## 2.2 Seeing both sets of initiations for this session (accelerometer vs DLC velocity)\n",
    "...and detecting only initiations of the acccelerometer which invole the lesioned paw (maybe produce analogous information for the other paw and the nose) - not implemented yet\n",
    "\n",
    "**Important:** consider the timestamps and the aquisition rate of both the accel sensor and the camera and build the x axis accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for init in initiation_right_paw_corrected:\n",
    "    plt.axvline(x=init, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d097aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for init in initiations_accel_corrected:\n",
    "    plt.axvline(x=init, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_initiations_accel = []\n",
    "for i in range(len(df_acceldata_accel['Timestamp'])):\n",
    "    if i in initiations_accel_corrected:\n",
    "        ts_initiations_accel.append(df_acceldata_accel['Timestamp'][i])\n",
    "\n",
    "ts_initiations_vel = []\n",
    "for i in range(len(df_vel['Vel - Timestamp'][:-9])):\n",
    "    if i in initiation_right_paw_corrected:\n",
    "        ts_initiations_vel.append(df_vel['Vel - Timestamp'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646a436",
   "metadata": {},
   "source": [
    "Some plots..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ts_initiations_accel), len(ts_initiations_vel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ts_initiations_accel, np.ones(len(initiations_accel_corrected)), color='orange')\n",
    "plt.plot(df_acceldata_accel['Timestamp'], df_acceldata_accel['Total_accel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeda090",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ts_initiations_accel, np.ones(len(initiations_accel_corrected)))\n",
    "plt.scatter(ts_initiations_vel, np.ones(len(initiation_right_paw_corrected)))\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ts_initiations_accel, np.ones(len(initiations_accel_corrected)))\n",
    "plt.scatter(ts_initiations_vel, np.zeros(len(initiation_right_paw_corrected)))\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed335ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df_vel['Vel - Timestamp'], df_vel['V_xy_right_hindlimb_heel'])\n",
    "plt.scatter(ts_initiations_vel, np.zeros(len(initiation_right_paw_corrected)), color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc1880",
   "metadata": {},
   "source": [
    "### Both sets of initiations in the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da68c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total body accceleration (not filtered)\n",
    "plt.plot(df_acceldata_accel['Timestamp'], st.zscore(df_acceldata_accel['Total_accel']))\n",
    "# velocity (not filtered)\n",
    "plt.plot(df_vel['Vel - Timestamp'], st.zscore(df_vel['V_xy_right_hindlimb_heel'])-3)\n",
    "\n",
    "# initiations of the accelerometer with phase correction\n",
    "plt.scatter(ts_initiations_accel, np.zeros(len(initiations_accel_corrected)), color = 'green')\n",
    "# initiations of the DLC (velocity)\n",
    "plt.scatter(ts_initiations_vel, -3*np.ones(len(initiation_right_paw_corrected)), color = 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394cc903",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba65404",
   "metadata": {},
   "source": [
    "##### Replicate the calculation of movement initiations from DLC predictions for the 'nose' and 'left hind limb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77883865",
   "metadata": {},
   "source": [
    "### Nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_nose = 3\n",
    "velocity_filtered_nose = moving_average(df_vel['V_xy_nose'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee4507",
   "metadata": {},
   "source": [
    "##### Crossing point between two gaussians fitted to the kernel density estimation... - working on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf418e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the treshold - working on it\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "y,x,_=plt.hist(np.log(velocity_filtered_nose), bins=100, color='lightblue')\n",
    "\n",
    "x=(x[1:]+x[:-1])/2 \n",
    "\n",
    "def gauss(x, mu, sigma, A):\n",
    "    return A*np.exp(-(x-mu)**2/2/sigma**2) \n",
    "\n",
    "def bimodal(x, mu1, sigma1, A1, mu2, sigma2, A2):\n",
    "    return gauss(x, mu1, sigma1, A1)+gauss(x, mu2, sigma2, A2)\n",
    "\n",
    "def multimodal_3(x, mu1, sigma1, A1, mu2, sigma2, A2, mu3, sigma3, A3):\n",
    "    return gauss(x, mu1, sigma1, A1)+gauss(x, mu2, sigma2, A2)+gauss(x, mu3, sigma3, A3)\n",
    "    \n",
    "# maybe define the expected values from the data: in this case, I can find the max count value and use it or A1 and A2\n",
    "expected = (-1, .1, max(y)/2, 2, .1, max(y)/2)\n",
    "params, cov = curve_fit(bimodal, x, y, expected, \n",
    "                        #[[lower], [upper]] bounds for mu1, sigma1, A1, mu2, sigma2, A2\n",
    "                        bounds=[[-np.inf, 0, 0, -np.inf, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf]]) \n",
    "sigma=np.sqrt(np.diag(cov))\n",
    "x_fit = np.linspace(x.min(), x.max(), 500)\n",
    "f = gauss(x_fit, *params[:3])\n",
    "g = gauss(x_fit, *params[3:])\n",
    "#print(pd.DataFrame(data={'params': params, 'sigma': sigma}, index=bimodal.__code__.co_varnames[1:]))\n",
    "plt.plot(x_fit, bimodal(x_fit, *params), color='red', lw=3, label='model')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[:3]), color='red', ls='--')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[3:]), color='red', ls=':')\n",
    "\n",
    "first_line = LineString(np.column_stack((x_fit, f)))\n",
    "second_line = LineString(np.column_stack((x_fit, g)))\n",
    "intersection = first_line.intersection(second_line)\n",
    "\n",
    "if intersection.geom_type == 'MultiPoint':\n",
    "    plt.plot(*LineString(intersection).xy, 'o')\n",
    "elif intersection.geom_type == 'Point':\n",
    "    plt.plot(*intersection.xy, 'o', color='orange')\n",
    "\n",
    "#not the real cutoff since I used the log of the data (as such, it should be applied to the log accel series)\n",
    "cutOff_nose_filtered_cg = intersection.xy[0][0]\n",
    "cutOff_nose_filtered_cg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# creates an array of 1s and 0s according to the cutOff from the previous cell\n",
    "# to get an overall ideia of what is being captured: movement bouts, individual paw movements,...\n",
    "moving_nose_cg = []\n",
    "for inst_vel in range(len(velocity_filtered_nose)):\n",
    "    if np.log(velocity_filtered_nose[inst_vel]) >= cutOff_nose_filtered_cg:\n",
    "        moving_nose_cg.append(1)\n",
    "    else:\n",
    "        moving_nose_cg.append(0)\n",
    "\n",
    "plt.plot(st.zscore(df_vel['V_xy_nose']))\n",
    "plt.plot(st.zscore(velocity_filtered_nose))\n",
    "plt.plot(st.zscore(moving_nose_cg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c180108",
   "metadata": {},
   "source": [
    "#### Using moving_nose_cg (3 window filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287c8b3",
   "metadata": {},
   "source": [
    "##### 300ms 0, followed by 500ms 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6638c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_of_interest = []\n",
    "for i in range(9):\n",
    "    sequence_of_interest.append(0)\n",
    "for i in range(15):\n",
    "    sequence_of_interest.append(1)\n",
    "sequence_of_interest # len(sequence_of_interest) == 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a716c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all sequences following the criteria\n",
    "initiations_nose = []\n",
    "index_first_element_last_seq = len(moving_nose_cg)-24\n",
    "for frame in range(index_first_element_last_seq + 1): # because range excludes the last value\n",
    "    if moving_nose_cg[frame:frame+24] == sequence_of_interest:\n",
    "        initiations_nose.append(frame+8) #+8 considers the last zero as the initiation; +9 considers the first 1 as the init\n",
    "initiations_nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(moving_nose_cg, color = 'g')\n",
    "for init in initiations_nose:\n",
    "    plt.axvline(x=init, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ed785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initiations_nose_corrected = []\n",
    "for init in initiations_nose:\n",
    "    initiations_nose_corrected.append(init+window_nose-1)\n",
    "initiations_nose_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2263fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocities calculated directly from the x,y DLC predictions\n",
    "plt.plot(df_vel['V_xy_nose'])\n",
    "# velocity filtered with a moving average (with a 3 fr window)\n",
    "plt.plot(velocity_filtered_nose)\n",
    "# treshold for movement initiation (of the nose - DLC predictions)\n",
    "plt.hlines(cutOff_nose_filtered_cg, 0, len(df_vel), color='green')\n",
    "# here, initiations are correct \n",
    "for init in initiations_nose_corrected:\n",
    "    plt.axvline(x=init, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot containing the average of the nose movement initiations detected\n",
    "time_sec = 2\n",
    "wind1 = -camera_aq_rate*time_sec\n",
    "wind2 = camera_aq_rate*time_sec+1\n",
    "\n",
    "matrix_initiations_nose = np.tile(np.vstack(initiations_nose_corrected), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_nose = np.tile(range(wind1, wind2), (len(initiations_nose_corrected),1))\n",
    "matrix_sequences_nose = matrix_initiations_nose + matrix_operation_nose\n",
    "\n",
    "nose_peth = np.array(df_vel['V_xy_nose'])[matrix_sequences_nose]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52466daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), sum(nose_peth))\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nose = sum(nose_peth)/len(initiations_nose)\n",
    "std_nose = nose_peth.std(axis=0) \n",
    "std_error_nose = std_nose/math.sqrt(len(initiations_nose))\n",
    "\n",
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_nose)\n",
    "plt.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_nose - std_error_nose,\n",
    "                 mean_nose + std_error_nose, alpha = 0.2)\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94218f9e",
   "metadata": {},
   "source": [
    "##### Total body acceleration aligned to the initiations detected using the velocities calculated from the DLC predicted coordinates (nose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5424bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_initiations_vel_nose = []\n",
    "for i in range(len(df_vel['Vel - Timestamp'][:-9])):\n",
    "    if i in initiations_nose_corrected:\n",
    "        ts_initiations_vel_nose.append(df_vel['Vel - Timestamp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91df13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closest_ts_2nose_vel_init = []\n",
    "for ts in ts_initiations_vel_nose:\n",
    "    closest_ts = find_closest(df_timestamps_accel_interpolation['Timestamps'], ts)\n",
    "    closest_ts_2nose_vel_init.append(closest_ts)\n",
    "    \n",
    "indices_closest_ts_2nose_vel_init = []\n",
    "for ts in closest_ts_2nose_vel_init:\n",
    "    indices_closest_ts_2nose_vel_init.append(df_timestamps_accel_interpolation['Timestamps'].loc[df_timestamps_accel_interpolation['Timestamps']==ts])\n",
    "    \n",
    "for i, j in zip(indices_closest_ts_2nose_vel_init, range(len(indices_closest_ts_2nose_vel_init))):\n",
    "    indices_closest_ts_2nose_vel_init[j] = i.index[0] \n",
    "\n",
    "indices_closest_ts_2nose_vel_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8605418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot containing the average of the TBA's aligned to the initiations \n",
    "# detected using the velocity of the nose\n",
    "\n",
    "time_sec = 2\n",
    "wind1 = -fs*time_sec\n",
    "wind2 = fs*time_sec+1\n",
    "\n",
    "matrix_accel_aligned_2nose = np.tile(np.vstack(indices_closest_ts_2nose_vel_init), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_nose = np.tile(range(wind1, wind2), (len(indices_closest_ts_2nose_vel_init),1))\n",
    "matrix_sequences_nose = matrix_accel_aligned_2nose + matrix_operation_nose\n",
    "\n",
    "TBA_aligned_2nose_peth = np.array(total_accel_interpolation)[matrix_sequences_nose]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26185bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), sum(TBA_aligned_2nose_peth))\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tba_aligned_2nose = sum(TBA_aligned_2nose_peth)/(len(indices_closest_ts_2nose_vel_init))\n",
    "std_tba_aligned_2nose = TBA_aligned_2nose_peth.std(axis=0) \n",
    "std_error_tba_aligned_2nose = std_tba_aligned_2nose/math.sqrt(len(indices_closest_ts_2nose_vel_init))\n",
    "\n",
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_tba_aligned_2nose)\n",
    "plt.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_tba_aligned_2nose - std_error_tba_aligned_2nose,\n",
    "                 mean_tba_aligned_2nose + std_error_tba_aligned_2nose, alpha = 0.2)\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cae180",
   "metadata": {},
   "source": [
    "##### Nose velocity aligned to the initiations detected using the total body acceleration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cede14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot containing the average of the velocity of the nose aligned to the initiations \n",
    "# detected using the total body acceleration\n",
    "\n",
    "time_sec = 2\n",
    "wind1 = -camera_aq_rate*time_sec\n",
    "wind2 = camera_aq_rate*time_sec+1\n",
    "\n",
    "matrix_nose_aligned_2accel = np.tile(np.vstack(indices_closest_ts_to_accel_init), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_nose_aligned_2accel = np.tile(range(wind1, wind2), (len(indices_closest_ts_to_accel_init),1))\n",
    "matrix_sequences_nose_aligned_2accel = matrix_nose_aligned_2accel + matrix_operation_nose_aligned_2accel\n",
    "\n",
    "nose_vel_aligned_2accel_peth = np.array(df_vel['V_xy_nose'])[matrix_sequences_nose_aligned_2accel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6215949",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), sum(nose_vel_aligned_2accel_peth))\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bce61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nose_aligned_2accel = sum(nose_vel_aligned_2accel_peth)/(len(indices_closest_ts_to_accel_init))\n",
    "std_nose_aligned_2accel = nose_vel_aligned_2accel_peth.std(axis=0) \n",
    "std_error_nose_aligned_2accel = std_nose_aligned_2accel/math.sqrt(len(indices_closest_ts_to_accel_init))\n",
    "\n",
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_nose_aligned_2accel, color = 'yellow')\n",
    "plt.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_nose_aligned_2accel - std_error_nose_aligned_2accel,\n",
    "                 mean_nose_aligned_2accel + std_error_nose_aligned_2accel, alpha = 0.2, color = 'yellow')\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002220c",
   "metadata": {},
   "source": [
    "### Left hind paw (lhp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ee176",
   "metadata": {},
   "source": [
    "##### Crossing point between two gaussians fitted to the kernel density estimation... - working on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the treshold - working on it\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "y,x,_=plt.hist(np.log(df_vel_filtered['V_xy_left_hindlimb_heel']), bins=100, color='lightblue')\n",
    "\n",
    "x=(x[1:]+x[:-1])/2 \n",
    "\n",
    "def gauss(x, mu, sigma, A):\n",
    "    return A*np.exp(-(x-mu)**2/2/sigma**2) \n",
    "\n",
    "def bimodal(x, mu1, sigma1, A1, mu2, sigma2, A2):\n",
    "    return gauss(x, mu1, sigma1, A1)+gauss(x, mu2, sigma2, A2)\n",
    "\n",
    "def multimodal_3(x, mu1, sigma1, A1, mu2, sigma2, A2, mu3, sigma3, A3):\n",
    "    return gauss(x, mu1, sigma1, A1)+gauss(x, mu2, sigma2, A2)+gauss(x, mu3, sigma3, A3)\n",
    "    \n",
    "# maybe define the expected values from the data: in this case, I can find the max count value and use it or A1 and A2\n",
    "expected = (-1, .1, max(y)/2, 2, .1, max(y)/2)\n",
    "params, cov = curve_fit(bimodal, x, y, expected, \n",
    "                        #[[lower], [upper]] bounds for mu1, sigma1, A1, mu2, sigma2, A2\n",
    "                        bounds=[[-np.inf, 0, 0, -np.inf, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf]]) \n",
    "sigma=np.sqrt(np.diag(cov))\n",
    "x_fit = np.linspace(x.min(), x.max(), 500)\n",
    "f = gauss(x_fit, *params[:3])\n",
    "g = gauss(x_fit, *params[3:])\n",
    "#print(pd.DataFrame(data={'params': params, 'sigma': sigma}, index=bimodal.__code__.co_varnames[1:]))\n",
    "plt.plot(x_fit, bimodal(x_fit, *params), color='red', lw=3, label='model')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[:3]), color='red', ls='--')\n",
    "plt.plot(x_fit, gauss(x_fit, *params[3:]), color='red', ls=':')\n",
    "\n",
    "first_line = LineString(np.column_stack((x_fit, f)))\n",
    "second_line = LineString(np.column_stack((x_fit, g)))\n",
    "intersection = first_line.intersection(second_line)\n",
    "\n",
    "if intersection.geom_type == 'MultiPoint':\n",
    "    plt.plot(*LineString(intersection).xy, 'o')\n",
    "elif intersection.geom_type == 'Point':\n",
    "    plt.plot(*intersection.xy, 'o', color='orange')\n",
    "\n",
    "#not the real cutoff since I used the log of the data (as such, it should be applied to the log accel series)\n",
    "cutOff_lhp_filtered_cg = intersection.xy[0][0]\n",
    "cutOff_lhp_filtered_cg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# creates an array of 1s and 0s according to the cutOff from the previous cell\n",
    "# to get an overall ideia of what is being captured: movement bouts, individual paw movements,...\n",
    "moving_lhp_cg = []\n",
    "for inst_vel in range(len(df_vel_filtered['V_xy_left_hindlimb_heel'])):\n",
    "    if np.log(df_vel_filtered['V_xy_left_hindlimb_heel'][inst_vel]) >= cutOff_lhp_filtered_cg:\n",
    "        moving_lhp_cg.append(1)\n",
    "    else:\n",
    "        moving_lhp_cg.append(0)\n",
    "\n",
    "plt.plot(st.zscore(df_vel['V_xy_left_hindlimb_heel']))\n",
    "plt.plot(st.zscore(df_vel_filtered['V_xy_left_hindlimb_heel']))\n",
    "plt.plot(st.zscore(moving_lhp_cg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5d943",
   "metadata": {},
   "source": [
    "#### Using moving_lhp_cg (10 window filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0e3cd",
   "metadata": {},
   "source": [
    "##### 300ms 0, followed by 500ms 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_of_interest = []\n",
    "for i in range(9):\n",
    "    sequence_of_interest.append(0)\n",
    "for i in range(15):\n",
    "    sequence_of_interest.append(1)\n",
    "sequence_of_interest # len(sequence_of_interest) == 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec155d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all sequences following the criteria\n",
    "initiations_lhp = []\n",
    "index_first_element_last_seq = len(moving_lhp_cg)-24\n",
    "for frame in range(index_first_element_last_seq + 1): # because range excludes the last value\n",
    "    if moving_lhp_cg[frame:frame+24] == sequence_of_interest:\n",
    "        initiations_lhp.append(frame+8) #+8 considers the last zero as the initiation; +9 considers the first 1 as the init\n",
    "initiations_lhp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb9f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(moving_lhp_cg, color = 'g')\n",
    "for init in initiations_lhp:\n",
    "    plt.axvline(x=init, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05509f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initiations_lhp_corrected = []\n",
    "for init in initiations_lhp:\n",
    "    initiations_lhp_corrected.append(init+window_vel_filtered-1)\n",
    "initiations_lhp_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba5d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocities calculated directly from the x,y DLC predictions\n",
    "plt.plot(df_vel['V_xy_left_hindlimb_heel'])\n",
    "# velocity filtered with a moving average (with a 3 fr window)\n",
    "plt.plot(df_vel_filtered['V_xy_left_hindlimb_heel'])\n",
    "# treshold for movement initiation (of the nose - DLC predictions)\n",
    "plt.hlines(cutOff_lhp_filtered_cg, 0, len(df_vel), color='green')\n",
    "# here, initiations are correct \n",
    "for init in initiations_lhp_corrected:\n",
    "    plt.axvline(x=init, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot containing the average of the nose movement initiations detected\n",
    "matrix_initiations_lhp = np.tile(np.vstack(initiations_lhp_corrected), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_lhp = np.tile(range(wind1, wind2), (len(initiations_lhp_corrected),1))\n",
    "matrix_sequences_lhp = matrix_initiations_lhp + matrix_operation_lhp\n",
    "\n",
    "lhp_peth = np.array(df_vel['V_xy_left_hindlimb_heel'])[matrix_sequences_lhp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564653b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), sum(lhp_peth))\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97fa43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lhp = sum(lhp_peth)/len(initiations_lhp)\n",
    "std_lhp = lhp_peth.std(axis=0) \n",
    "std_error_lhp = std_lhp/math.sqrt(len(initiations_lhp))\n",
    "\n",
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_lhp)\n",
    "plt.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_lhp - std_error_lhp,\n",
    "                 mean_lhp + std_error_lhp, alpha = 0.2)\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ed626",
   "metadata": {},
   "source": [
    "##### Total body acceleration aligned to the initiations detected using the velocities calculated from the DLC predicted coordinates (left hind paw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_initiations_vel_lhp = []\n",
    "for i in range(len(df_vel['Vel - Timestamp'][:-9])):\n",
    "    if i in initiations_lhp_corrected:\n",
    "        ts_initiations_vel_lhp.append(df_vel['Vel - Timestamp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04342d00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closest_ts_2lhp_vel_init = []\n",
    "for ts in ts_initiations_vel_lhp:\n",
    "    closest_ts = find_closest(df_timestamps_accel_interpolation['Timestamps'], ts)\n",
    "    closest_ts_2lhp_vel_init.append(closest_ts)\n",
    "    \n",
    "indices_closest_ts_2lhp_vel_init = []\n",
    "for ts in closest_ts_2lhp_vel_init:\n",
    "    indices_closest_ts_2lhp_vel_init.append(df_timestamps_accel_interpolation['Timestamps'].loc[df_timestamps_accel_interpolation['Timestamps']==ts])\n",
    "    \n",
    "for i, j in zip(indices_closest_ts_2lhp_vel_init, range(len(indices_closest_ts_2lhp_vel_init))):\n",
    "    indices_closest_ts_2lhp_vel_init[j] = i.index[0] \n",
    "\n",
    "indices_closest_ts_2lhp_vel_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81785be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot containing the average of the TBA's aligned to the initiations \n",
    "# detected using the velocity of the left hind paw\n",
    "\n",
    "time_sec = 2\n",
    "wind1 = -fs*time_sec\n",
    "wind2 = fs*time_sec+1\n",
    "\n",
    "matrix_accel_aligned_2lhp = np.tile(np.vstack(indices_closest_ts_2lhp_vel_init), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_lhp = np.tile(range(wind1, wind2), (len(indices_closest_ts_2lhp_vel_init),1))\n",
    "matrix_sequences_lhp = matrix_accel_aligned_2lhp + matrix_operation_lhp\n",
    "\n",
    "TBA_aligned_2lhp_peth = np.array(total_accel_interpolation)[matrix_sequences_lhp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3d6c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), sum(TBA_aligned_2lhp_peth))\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f09239",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tba_aligned_2lhp = sum(TBA_aligned_2lhp_peth)/(len(indices_closest_ts_2lhp_vel_init))\n",
    "std_tba_aligned_2lhp = TBA_aligned_2lhp_peth.std(axis=0) \n",
    "std_error_tba_aligned_2lhp = std_tba_aligned_2lhp/math.sqrt(len(indices_closest_ts_2lhp_vel_init))\n",
    "\n",
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_tba_aligned_2lhp)\n",
    "plt.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_tba_aligned_2lhp - std_error_tba_aligned_2lhp,\n",
    "                 mean_tba_aligned_2lhp + std_error_tba_aligned_2lhp, alpha = 0.2)\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7126648",
   "metadata": {},
   "source": [
    "##### Left hindlimb heel velocity aligned to the initiations detected using the total body acceleration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot containing the average of the velocity of the left hind paw\n",
    "# aligned to the initiations detected using the total body acceleration\n",
    "\n",
    "time_sec = 2\n",
    "wind1 = -camera_aq_rate*time_sec\n",
    "wind2 = camera_aq_rate*time_sec+1\n",
    "\n",
    "matrix_lhp_aligned_2accel = np.tile(np.vstack(indices_closest_ts_to_accel_init), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_lhp_aligned_2accel = np.tile(range(wind1, wind2), (len(indices_closest_ts_to_accel_init),1))\n",
    "matrix_sequences_lhp_aligned_2accel = matrix_lhp_aligned_2accel + matrix_operation_lhp_aligned_2accel\n",
    "\n",
    "lhp_vel_aligned_2accel_peth = np.array(df_vel['V_xy_left_hindlimb_heel'])[matrix_sequences_lhp_aligned_2accel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), sum(lhp_vel_aligned_2accel_peth))\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38528d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lhp_aligned_2accel = sum(lhp_vel_aligned_2accel_peth)/(len(indices_closest_ts_to_accel_init))\n",
    "std_lhp_aligned_2accel = lhp_vel_aligned_2accel_peth.std(axis=0) \n",
    "std_error_lhp_aligned_2accel = std_lhp_aligned_2accel/math.sqrt(len(indices_closest_ts_to_accel_init))\n",
    "\n",
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_lhp_aligned_2accel, color = 'deeppink')\n",
    "plt.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_lhp_aligned_2accel - std_error_lhp_aligned_2accel,\n",
    "                 mean_lhp_aligned_2accel + std_error_lhp_aligned_2accel, alpha = 0.2, color = 'deeppink')\n",
    "plt.axvline(0, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83e755",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b1726",
   "metadata": {},
   "source": [
    "# 2.3 Px change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ce6ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vidcap.set(1,0)\n",
    "ret, frame = vidcap.read()\n",
    "previousFrame = frame\n",
    "previousFrame #get the first previousFrame (frame 0) which will be fed into the following loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fee92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# don't forget to run the cell that sets the first 'previousFrame'\n",
    "# carefully define what the starting point of this array should be\n",
    "video_px_change_sum_nonzeros = []\n",
    "\n",
    "for fr in range(1, int(total_frames)): #from 0 to 18863\n",
    "    vidcap.set(1,fr)\n",
    "    ret, frame = vidcap.read()\n",
    "    a = np.absolute(np.subtract(frame.astype(int)[:,:,0], previousFrame.astype(int)[:,:,0]))\n",
    "        \n",
    "    nonzero_values = 0\n",
    "    for nonzero_pixel in np.nonzero(a.flatten()):\n",
    "        nonzero_values+=a.flatten()[nonzero_pixel]\n",
    "    sum_nonzero = np.sum(nonzero_values)\n",
    "   \n",
    "    #once the calculation is performed, save the value in the array\n",
    "    video_px_change_sum_nonzeros.append(sum_nonzero)\n",
    "    \n",
    "    #after performing the operation, 'frame' will get a new value and the currentFrame of this iteration will be the previous\n",
    "    #...frame in the following iteration\n",
    "    previousFrame = frame\n",
    "    print(fr)\n",
    "    if fr == 1 or fr == 2:\n",
    "        print(sum_nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae410ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px_change_filtered = []\n",
    "sum_above_cutOff = 0\n",
    "cutOff_temp = 20\n",
    "\n",
    "# carefully define what the first element of this array should be\n",
    "for fr in range(1, int(total_frames)):\n",
    "    vidcap.set(1,fr)\n",
    "    ret, frame = vidcap.read()\n",
    "    a = np.absolute(np.subtract(frame.astype(int)[:,:,0], previousFrame.astype(int)[:,:,0]))\n",
    "        \n",
    "    occurences_above_cutoff = a.flatten()>cutOff_temp #TRY HIGHER CUTOFF!!\n",
    "    value_per_frame = occurences_above_cutoff.sum()\n",
    "\n",
    "    px_change_filtered.append(value_per_frame)\n",
    "    \n",
    "    #after performing the operation, 'frame' will get a new value and the currentFrame of this iteration will be the previous\n",
    "    #...frame in the following iteration\n",
    "    previousFrame = frame\n",
    "    print(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d315d",
   "metadata": {},
   "source": [
    "##### Plot the initiations detected using the acceleration data, as well as the velocities and px change aligned to the moments of initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_px_change_aligned_to_accel = pd.DataFrame()\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot = 241\n",
    "\n",
    "for index in indices_closest_ts_to_accel_init:\n",
    "    if index < 240:\n",
    "        arr = np.array(px_change_filtered[0:int(index+end_plot)])\n",
    "        zeros_ = (240*2+1) - len(arr)\n",
    "        df_px_change_aligned_to_accel[index] = np.concatenate((np.zeros(zeros_), arr))\n",
    "    elif len(px_change_filtered) - index < 240:\n",
    "        arr = np.array(px_change_filtered[int(index+beg_plot):int(len(px_change_filtered)+1)])\n",
    "        zeros_ = (240*2+1) - len(arr)\n",
    "        df_px_change_aligned_to_accel[index] = np.concatenate((arr, np.zeros(zeros_)))\n",
    "    else:\n",
    "        arr = np.array(px_change_filtered[int(index+beg_plot):int(index+end_plot)])\n",
    "        df_px_change_aligned_to_accel[index] = arr\n",
    "\n",
    "mean_px_change = df_px_change_aligned_to_accel.mean(axis=1)\n",
    "\n",
    "std_px_change = df_px_change_aligned_to_accel.std(axis=1)\n",
    "\n",
    "std_error_px_change = std_px_change/math.sqrt(len(indices_closest_ts_to_accel_init))\n",
    "\n",
    "df_px_change_aligned_to_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b20c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiation minus 8 sec\n",
    "beg_plot = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot = 241\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_px_change_aligned_to_accel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_px_change - std_error_px_change,\n",
    "                 mean_px_change + std_error_px_change, alpha = 0.2)\n",
    "\n",
    "plt.title('Px change aligned to accelerometer initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Px change')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(3,1,1)\n",
    "mean_accel = df_initiations_accel_sequence_interest.mean(axis=1)\n",
    "\n",
    "std_accel = df_initiations_accel_sequence_interest.std(axis=1)\n",
    "\n",
    "std_error_accel = std_accel/math.sqrt(len(initiations_accel_corrected))\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -fs*8\n",
    "# initiation plus 8 sec\n",
    "end_plot = fs*8+1\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_initiations_accel_sequence_interest.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_accel - std_error_accel,\n",
    "                 mean_accel + std_error_accel, alpha = 0.2)\n",
    "\n",
    "plt.title('Movement initiation obtained from the total body acceleration')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Acceleration')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -num_points_stopped\n",
    "end_seq = num_points_moving\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)\n",
    "\n",
    "#########################################################################################################################\n",
    "plt.subplot(3,1,2)\n",
    "mean_velocity = df_velocities_aligned_to_accel.mean(axis=1)\n",
    "\n",
    "std_velocity = df_velocities_aligned_to_accel.std(axis=1)\n",
    "\n",
    "std_error_velocity = std_velocity/math.sqrt(len(indices_closest_ts_to_accel_init))\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot = 241\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_velocities_aligned_to_accel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_velocity - std_error_velocity,\n",
    "                 mean_velocity + std_error_velocity, alpha = 0.2)\n",
    "\n",
    "plt.title('Velocity aligned to accelerometer initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)\n",
    "#############################################################################################################################\n",
    "plt.subplot(3,1,3)\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot = 241\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_px_change_aligned_to_accel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_px_change - std_error_px_change,\n",
    "                 mean_px_change + std_error_px_change, alpha = 0.2)\n",
    "\n",
    "plt.title('Px change aligned to accelerometer initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Px change')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41149a9",
   "metadata": {},
   "source": [
    "##### Plot the initiations detected using the velocities (DLC), as well as the total body acceleration and px change aligned to the moments of initiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c93562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_px_change_aligned_to_vel = pd.DataFrame()\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot_8 = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot_8 = 241\n",
    "\n",
    "for init in initiation_right_paw_corrected:\n",
    "    if init < 240:\n",
    "        arr = np.array(px_change_filtered[0:int(init+end_plot_8)])\n",
    "        zeros_ = (240*2+1) - len(arr)\n",
    "        df_px_change_aligned_to_vel[init] = np.concatenate((np.zeros(zeros_), arr))\n",
    "    elif len(px_change_filtered) - init < 240:\n",
    "        arr = np.array(px_change_filtered[int(init+beg_plot_8):int(len(px_change_filtered)+1)])\n",
    "        zeros_ = (240*2+1) - len(arr)\n",
    "        df_px_change_aligned_to_vel[init] = np.concatenate((arr, np.zeros(zeros_)))\n",
    "    else:\n",
    "        arr = np.array(px_change_filtered[int(init+beg_plot_8):int(init+end_plot_8)])\n",
    "        df_px_change_aligned_to_vel[init] = arr\n",
    "\n",
    "mean_px_change_aligned_vel = df_px_change_aligned_to_vel.mean(axis=1)\n",
    "\n",
    "std_px_change_aligned_vel = df_px_change_aligned_to_vel.std(axis=1)\n",
    "\n",
    "std_error_px_change_aligned_vel = std_px_change_aligned_vel/math.sqrt(len(initiation_right_paw_corrected))\n",
    "\n",
    "df_px_change_aligned_to_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiation minus 8 sec\n",
    "beg_plot = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot = 241\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_px_change_aligned_to_vel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_px_change_aligned_vel - std_error_px_change_aligned_vel,\n",
    "                 mean_px_change_aligned_vel + std_error_px_change_aligned_vel, alpha = 0.2)\n",
    "\n",
    "plt.title('Px change aligned to velocity initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Px change')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df295e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the initiations detected from the velocity data (DLC)\n",
    "plt.subplot(3,1,1)\n",
    "# initiation minus 8 sec\n",
    "beg_plot_8 = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot_8 = 241\n",
    "\n",
    "print(beg_plot_8, end_plot_8)\n",
    "\n",
    "plt.plot(range(beg_plot_8, end_plot_8), df_vel_8sec.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot_8, end_plot_8), \n",
    "                 mean_velocity_8sec - std_error_velocity_8sec,\n",
    "                 mean_velocity_8sec + std_error_velocity_8sec, alpha = 0.2)\n",
    "\n",
    "plt.title('Movement initiations with the right paw')\n",
    "plt.xlabel('Time (fr)')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)\n",
    "##########################################################################################################################\n",
    "# plot of the acceleration data aligned to the initiations of the velocity\n",
    "plt.subplot(3,1,2)\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -fs*8\n",
    "# initiation plus 8 sec\n",
    "end_plot = fs*8+1\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_accel_aligned_to_vel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_accel_ - std_error_accel_,\n",
    "                 mean_accel_ + std_error_accel_, alpha = 0.2)\n",
    "\n",
    "plt.title('Total body acceleration aligned to velocity initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total body acceleration')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -num_points_stopped\n",
    "end_seq = num_points_moving\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)\n",
    "##########################################################################################################################\n",
    "# plot of the px change aligned to the initiations detected with the velocities (DLC)\n",
    "plt.subplot(3,1,3)\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot = 241\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_px_change_aligned_to_vel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_px_change_aligned_vel - std_error_px_change_aligned_vel,\n",
    "                 mean_px_change_aligned_vel + std_error_px_change_aligned_vel, alpha = 0.2)\n",
    "\n",
    "plt.title('Px change aligned to velocity initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Px change')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa412e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda8f40",
   "metadata": {},
   "source": [
    "## 2.4 Probability density function - Movement initiations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365c8c2",
   "metadata": {},
   "source": [
    "## 2.4.1 Total body acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "time_sec = 2\n",
    "wind1 = -fs*time_sec\n",
    "wind2 = fs*time_sec+1\n",
    "\n",
    "matrix_initiations = np.tile(np.vstack(initiations_accel_corrected), (1, len(range(wind1, wind2))))\n",
    "matrix_operation = np.tile(range(wind1, wind2), (len(initiations_accel_corrected),1))\n",
    "matrix_sequences = matrix_initiations + matrix_operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fe696",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "flatten_temp_density = np.zeros(matrix_sequences.size) #array of zeros the size of the matrix_sequences which will: \n",
    "# 1) be subjected to iteration;\n",
    "# 2) test the presence of every element in the vector of initiations\n",
    "# 3) if present, then assign 1\n",
    "for x, i in zip(np.nditer(matrix_sequences), range(matrix_sequences.size)):\n",
    "    if x in initiations_accel_corrected:\n",
    "        flatten_temp_density[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86420443",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_pre_probability_density = flatten_temp_density.reshape(matrix_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0954e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density)/matrix_pre_probability_density.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c154f5",
   "metadata": {},
   "source": [
    "## 2.4.2 Right hind paw (DLC velocity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "time_sec = 2\n",
    "wind1 = -camera_aq_rate*time_sec\n",
    "wind2 = camera_aq_rate*time_sec+1\n",
    "\n",
    "matrix_initiations_rhp = np.tile(np.vstack(initiation_right_paw_corrected), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_rhp = np.tile(range(wind1, wind2), (len(initiation_right_paw_corrected),1))\n",
    "matrix_sequences_rhp = matrix_initiations_rhp + matrix_operation_rhp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e6914",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_temp_density_rhp = np.zeros(matrix_sequences_rhp.size)\n",
    "\n",
    "for x, i in zip(np.nditer(matrix_sequences_rhp), range(matrix_sequences_rhp.size)):\n",
    "    if x in initiation_right_paw_corrected:\n",
    "        flatten_temp_density_rhp[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b398b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_pre_probability_density_rhp = flatten_temp_density_rhp.reshape(matrix_sequences_rhp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85778ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density_rhp)/matrix_pre_probability_density_rhp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb49793",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(matrix_pre_probability_density_rhp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430383e9",
   "metadata": {},
   "source": [
    "## 2.4.3 Nose (DLC velocity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sec = 2\n",
    "wind1 = -camera_aq_rate*time_sec\n",
    "wind2 = camera_aq_rate*time_sec+1\n",
    "\n",
    "matrix_initiations_nose = np.tile(np.vstack(initiations_nose_corrected), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_nose = np.tile(range(wind1, wind2), (len(initiations_nose_corrected),1))\n",
    "matrix_sequences_nose = matrix_initiations_nose + matrix_operation_nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a100243",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_temp_density_nose = np.zeros(matrix_sequences_nose.size)\n",
    "\n",
    "for x, i in zip(np.nditer(matrix_sequences_nose), range(matrix_sequences_nose.size)):\n",
    "    if x in initiations_nose_corrected:\n",
    "        flatten_temp_density_nose[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22176075",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_pre_probability_density_nose = flatten_temp_density_nose.reshape(matrix_sequences_nose.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density_nose)/matrix_pre_probability_density_nose.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60956f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(matrix_pre_probability_density_nose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79a06e",
   "metadata": {},
   "source": [
    "## 2.4.4 Left hind paw (DLC velocity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f395d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sec = 2\n",
    "wind1 = -camera_aq_rate*time_sec\n",
    "wind2 = camera_aq_rate*time_sec+1\n",
    "\n",
    "matrix_initiations_lhp = np.tile(np.vstack(initiations_lhp_corrected), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_lhp = np.tile(range(wind1, wind2), (len(initiations_lhp_corrected),1))\n",
    "matrix_sequences_lhp = matrix_initiations_lhp + matrix_operation_lhp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abcc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_temp_density_lhp = np.zeros(matrix_sequences_lhp.size)\n",
    "\n",
    "for x, i in zip(np.nditer(matrix_sequences_lhp), range(matrix_sequences_lhp.size)):\n",
    "    if x in initiations_lhp_corrected:\n",
    "        flatten_temp_density_lhp[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_pre_probability_density_lhp = flatten_temp_density_lhp.reshape(matrix_sequences_lhp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density_lhp)/matrix_pre_probability_density_lhp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66513668",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(matrix_pre_probability_density_lhp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8365315",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43809878",
   "metadata": {},
   "source": [
    "# One neuron... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fda41",
   "metadata": {},
   "source": [
    "##  2.5 Align the calcium traces to the initiations\n",
    "\n",
    "- ...calculated using the acceleration data\n",
    "- ...calculated using the velocities (DLC)\n",
    "\n",
    "**Remember:** I can now access all four variables: 'A', 'S', 'C', 'C_raw' (A and S directly, and C/C_raw using neuron_mat_info['C']/neuron_mat_info['C_raw']); Furthermore, 'C' is structured in df_calcium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5390c9",
   "metadata": {},
   "source": [
    "## 2.5.1 Aligned to initiations detected using the total body acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(arr, val):\n",
    "    idx = np.abs(arr - val).argmin()\n",
    "    return arr[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64179840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the inscopix timestamps which are the closest to the timestamps ocrresponting to initiations detected using the \n",
    "# total body acceleration\n",
    "closest_inscop_ts_to_accel_init = []\n",
    "for ts in ts_initiations_accel:\n",
    "    closest_ts = find_closest(df_calcium_raw['Timestamp'], ts)\n",
    "    closest_inscop_ts_to_accel_init.append(closest_ts)\n",
    "    \n",
    "indices_inscop_closest_ts_to_accel_init = []\n",
    "for ts in closest_inscop_ts_to_accel_init:\n",
    "    indices_inscop_closest_ts_to_accel_init.append(df_calcium_raw['Timestamp'].loc[df_calcium_raw['Timestamp']==ts])\n",
    "    \n",
    "for i, j in zip(indices_inscop_closest_ts_to_accel_init, range(len(indices_inscop_closest_ts_to_accel_init))):\n",
    "    indices_inscop_closest_ts_to_accel_init[j] = i.index[0] \n",
    "    \n",
    "# this array represents the indices of the Inscopix dataframe whose timestamps are the closest to the \n",
    "# timestamps of the initiations calculated using data from the accelerometer\n",
    "indices_inscop_closest_ts_to_accel_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "time_sec = 2\n",
    "# initiation minus 8 seconds\n",
    "beg_plot = -inscopix_aq_rate*time_sec\n",
    "# initiation plus 8 seconds\n",
    "end_plot = inscopix_aq_rate*time_sec + 1\n",
    "\n",
    "for index in indices_inscop_closest_ts_to_accel_init:\n",
    "    if index < inscopix_aq_rate*time_sec:\n",
    "        plt.plot(range(-index, end_plot), df_calcium_raw['neuron_1'][0:index+end_plot])\n",
    "        count_1+=1\n",
    "    # check if it should be < or <= !!!\n",
    "    elif len(df_calcium) - index < inscopix_aq_rate*time_sec:\n",
    "        plt.plot(range(beg_plot, len(df_calcium)-index), df_calcium_raw['neuron_1'][index+beg_plot:len(df_calcium)+end_plot])\n",
    "        count_2+=1\n",
    "    else:\n",
    "        plt.plot(range(beg_plot, end_plot), df_calcium_raw['neuron_1'][index+beg_plot:index+end_plot])\n",
    "        count_3+=1\n",
    "        \n",
    "plt.title('Neuron 1')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')  #vertical line\n",
    "\n",
    "# make sure no initiation is missing\n",
    "print((count_1+count_2+count_3)==len(indices_inscop_closest_ts_to_accel_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf99e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_neuron1_aligned_to_accel = pd.DataFrame()\n",
    "\n",
    "time_sec = 2\n",
    "# initiation minus 8 seconds\n",
    "beg_plot = -inscopix_aq_rate*time_sec\n",
    "# initiation plus 8 seconds\n",
    "end_plot = inscopix_aq_rate*time_sec + 1\n",
    "\n",
    "for index in indices_inscop_closest_ts_to_accel_init:\n",
    "    if index < inscopix_aq_rate*time_sec:\n",
    "        arr = np.array(df_calcium_raw['neuron_1'][0:int(index+end_plot)])\n",
    "        zeros_ = (-beg_plot+end_plot) - len(arr)\n",
    "        df_neuron1_aligned_to_accel[index] = np.concatenate((np.zeros(zeros_), arr))\n",
    "    elif len(df_calcium) - index < inscopix_aq_rate*time_sec:\n",
    "        arr = np.array(df_calcium_raw['neuron_1'][int(index+beg_plot):int(len(df_calcium)+1)])\n",
    "        zeros_ = (-beg_plot+end_plot) - len(arr)\n",
    "        df_neuron1_aligned_to_accel[index] = np.concatenate((arr, np.zeros(zeros_)))\n",
    "    else:\n",
    "        arr = np.array(df_calcium_raw['neuron_1'][int(index+beg_plot):int(index+end_plot)])\n",
    "        df_neuron1_aligned_to_accel[index] = arr\n",
    "\n",
    "mean_neuron1 = df_neuron1_aligned_to_accel.mean(axis=1)\n",
    "\n",
    "std_neuron1 = df_neuron1_aligned_to_accel.std(axis=1)\n",
    "\n",
    "std_error_neuron1 = std_neuron1/math.sqrt(len(indices_inscop_closest_ts_to_accel_init))\n",
    "\n",
    "df_neuron1_aligned_to_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to look at these line!!!\n",
    "# example of initiation\n",
    "\n",
    "df_neuron1_aligned_to_accel[534][inscopix_aq_rate*time_sec] == df_calcium_raw['neuron_1'][534] #CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6dc761",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sec = 2\n",
    "# initiation minus 2 seconds\n",
    "beg_plot = -inscopix_aq_rate*time_sec\n",
    "# initiation plus 2 seconds\n",
    "end_plot = inscopix_aq_rate*time_sec + 1\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_neuron1_aligned_to_accel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_neuron1 - std_error_neuron1,\n",
    "                 mean_neuron1 + std_error_neuron1, alpha = 0.2)\n",
    "\n",
    "plt.title('Neuron 1 aligned to the initiations of the accelerometer')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(4,1,1)\n",
    "mean_accel = df_initiations_accel_sequence_interest.mean(axis=1)\n",
    "\n",
    "std_accel = df_initiations_accel_sequence_interest.std(axis=1)\n",
    "\n",
    "std_error_accel = std_accel/math.sqrt(len(initiations_accel_corrected))\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -fs*8\n",
    "# initiation plus 8 sec\n",
    "end_plot = fs*8+1\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_initiations_accel_sequence_interest.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_accel - std_error_accel,\n",
    "                 mean_accel + std_error_accel, alpha = 0.2)\n",
    "\n",
    "plt.title('Movement initiation obtained from the total body acceleration')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Acceleration')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -num_points_stopped\n",
    "end_seq = num_points_moving\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)\n",
    "\n",
    "#########################################################################################################################\n",
    "plt.subplot(4,1,2)\n",
    "mean_velocity = df_velocities_aligned_to_accel.mean(axis=1)\n",
    "\n",
    "std_velocity = df_velocities_aligned_to_accel.std(axis=1)\n",
    "\n",
    "std_error_velocity = std_velocity/math.sqrt(len(indices_closest_ts_to_accel_init))\n",
    "\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot = 241\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_velocities_aligned_to_accel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_velocity - std_error_velocity,\n",
    "                 mean_velocity + std_error_velocity, alpha = 0.2)\n",
    "\n",
    "plt.title('Velocity aligned to accelerometer initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Velocity (px/fr)')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)\n",
    "#############################################################################################################################\n",
    "plt.subplot(4,1,3)\n",
    "# initiation minus 8 sec\n",
    "beg_plot = -240\n",
    "# initiation plus 8 sec\n",
    "end_plot = 241\n",
    "\n",
    "print(beg_plot, end_plot)\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_px_change_aligned_to_accel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_px_change - std_error_px_change,\n",
    "                 mean_px_change + std_error_px_change, alpha = 0.2)\n",
    "\n",
    "plt.title('Px change aligned to accelerometer initiations')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Px change')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "beg_seq = -9\n",
    "end_seq = 15\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)\n",
    "############################################################################################################################\n",
    "plt.subplot(4,1,4)\n",
    "time_sec = 8 #keep in mind that to run this code you need to set the previous cells to 8 seconds\n",
    "# initiation minus 8 seconds\n",
    "beg_plot = -inscopix_aq_rate*time_sec\n",
    "# initiation plus 8 seconds\n",
    "end_plot = inscopix_aq_rate*time_sec + 1\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_neuron1_aligned_to_accel.mean(axis=1))\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_neuron1 - std_error_neuron1,\n",
    "                 mean_neuron1 + std_error_neuron1, alpha = 0.2)\n",
    "\n",
    "plt.title('Neuron 1 aligned to the initiations of the accelerometer')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "'''beg_seq = -9\n",
    "end_seq = 15'''\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "#plt.axvline(beg_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "#plt.axvline(end_seq, linestyle = '--', color = 'black', alpha = 0.2) \n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "#plt.fill_betweenx(np.arange(ymin, ymax), beg_seq, end_seq, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc57c2",
   "metadata": {},
   "source": [
    "## 2.5.2 Aligned to initiations detected using the velocity of the right hind paw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ce136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the inscopix timestamps which are the closest to the timestamps corresponting to initiations detected using the \n",
    "# total body acceleration\n",
    "closest_inscop_ts_to_vel_init = []\n",
    "for ts in ts_initiations_vel:\n",
    "    closest_ts = find_closest(df_calcium_raw['Timestamp'], ts)\n",
    "    closest_inscop_ts_to_vel_init.append(closest_ts)\n",
    "    \n",
    "indices_inscop_closest_ts_to_vel_init = []\n",
    "for ts in closest_inscop_ts_to_vel_init:\n",
    "    indices_inscop_closest_ts_to_vel_init.append(df_calcium_raw['Timestamp'].loc[df_calcium['Timestamp']==ts])\n",
    "    \n",
    "for i, j in zip(indices_inscop_closest_ts_to_vel_init, range(len(indices_inscop_closest_ts_to_vel_init))):\n",
    "    indices_inscop_closest_ts_to_vel_init[j] = i.index[0] \n",
    "\n",
    "# this array represents the indices of the Inscopix dataframe whose timestamps are the closest to the \n",
    "# timestamps of the initiations calculated using data from the accelerometer\n",
    "indices_inscop_closest_ts_to_vel_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "time_sec = 2\n",
    "# initiation minus 8 seconds\n",
    "beg_plot = -inscopix_aq_rate*time_sec\n",
    "# initiation plus 8 seconds\n",
    "end_plot = inscopix_aq_rate*time_sec + 1\n",
    "\n",
    "for index in indices_inscop_closest_ts_to_vel_init:\n",
    "    if index < inscopix_aq_rate*time_sec:\n",
    "        plt.plot(range(-index, end_plot), df_calcium_raw['neuron_1'][0:index+end_plot])\n",
    "        count_1+=1\n",
    "    # check if it should be < or <= !!!\n",
    "    elif len(df_calcium) - index < inscopix_aq_rate*time_sec:\n",
    "        plt.plot(range(beg_plot, len(df_calcium)-index), df_calcium_raw['neuron_1'][index+beg_plot:len(df_calcium)+end_plot])\n",
    "        count_2+=1\n",
    "    else:\n",
    "        plt.plot(range(beg_plot, end_plot), df_calcium_raw['neuron_1'][index+beg_plot:index+end_plot])\n",
    "        count_3+=1\n",
    "        \n",
    "plt.title('Neuron 1')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')  #vertical line\n",
    "\n",
    "# make sure no initiation is missing\n",
    "print((count_1+count_2+count_3)==len(indices_inscop_closest_ts_to_vel_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e505f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_neuron1_aligned_to_vel = pd.DataFrame()\n",
    "\n",
    "time_sec = 2\n",
    "# initiation minus 2 seconds\n",
    "beg_plot = -inscopix_aq_rate*time_sec\n",
    "# initiation plus 2 seconds\n",
    "end_plot = inscopix_aq_rate*time_sec + 1\n",
    "\n",
    "for index in indices_inscop_closest_ts_to_vel_init:\n",
    "    if index < inscopix_aq_rate*time_sec:\n",
    "        arr = np.array(df_calcium_raw['neuron_1'][0:int(index+end_plot)])\n",
    "        zeros_ = (-beg_plot+end_plot) - len(arr)\n",
    "        df_neuron1_aligned_to_vel[index] = np.concatenate((np.zeros(zeros_), arr))\n",
    "    elif len(df_calcium) - index < inscopix_aq_rate*time_sec:\n",
    "        arr = np.array(df_calcium_raw['neuron_1'][int(index+beg_plot):int(len(df_calcium)+1)])\n",
    "        zeros_ = (-beg_plot+end_plot) - len(arr)\n",
    "        df_neuron1_aligned_to_vel[index] = np.concatenate((arr, np.zeros(zeros_)))\n",
    "    else:\n",
    "        arr = np.array(df_calcium_raw['neuron_1'][int(index+beg_plot):int(index+end_plot)])\n",
    "        df_neuron1_aligned_to_vel[index] = arr\n",
    "\n",
    "mean_neuron1_vel = df_neuron1_aligned_to_vel.mean(axis=1)\n",
    "std_neuron1_vel = df_neuron1_aligned_to_vel.std(axis=1)\n",
    "std_error_neuron1_vel = std_neuron1_vel/math.sqrt(len(indices_inscop_closest_ts_to_vel_init))\n",
    "\n",
    "df_neuron1_aligned_to_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to look at these line!!!\n",
    "# example of initiation\n",
    "\n",
    "df_neuron1_aligned_to_vel[1136][inscopix_aq_rate*time_sec] == df_calcium_raw['neuron_1'][1136] #CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74dcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sec = 2\n",
    "# initiation minus 2 seconds\n",
    "beg_plot = -inscopix_aq_rate*time_sec\n",
    "# initiation plus 2 seconds\n",
    "end_plot = inscopix_aq_rate*time_sec + 1\n",
    "\n",
    "plt.plot(range(beg_plot, end_plot), df_neuron1_aligned_to_vel.mean(axis=1), color = 'red')\n",
    "plt.fill_between(range(beg_plot, end_plot), \n",
    "                 mean_neuron1_vel - std_error_neuron1_vel,\n",
    "                 mean_neuron1_vel + std_error_neuron1_vel, alpha = 0.2, color='red')\n",
    "\n",
    "plt.title('Neuron 1 aligned to the initiations of the velocity')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e4d15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c4747",
   "metadata": {},
   "source": [
    "### Plot both on the same plot\n",
    "\n",
    "For example, -2 sec. init +2 sec., in which 0 sec. represents an initiation, and where the two previous plots are represented (aligned to the initiations from the acceleration - **BLUE**; aligned to the initiations from the velocity - **RED**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ef58c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.linspace(-2,2,81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0eee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALIGNED TO INITIATIONS DETECTED USING THE VELOCITY OF THE LESIONED PAW\n",
    "time_sec = 2\n",
    "# initiation minus 2 seconds\n",
    "beg_plot = -inscopix_aq_rate*time_sec\n",
    "# initiation plus 2 seconds\n",
    "end_plot = inscopix_aq_rate*time_sec + 1\n",
    "\n",
    "plt.plot(np.linspace(-2,2,81), df_neuron1_aligned_to_accel.mean(axis=1), label='Aligned to the initiations detected using the total body acceleration')\n",
    "plt.fill_between(np.linspace(-2,2,81), \n",
    "                 mean_neuron1 - std_error_neuron1,\n",
    "                 mean_neuron1 + std_error_neuron1, alpha = 0.2)\n",
    "\n",
    "### ALIGNED TO INITIATIONS DETECTED USING THE VELOCITY OF THE LESIONED PAW\n",
    "plt.plot(np.linspace(-2,2,81), df_neuron1_aligned_to_vel.mean(axis=1), color = 'red', label='Aligned to the initiations detected using the velocity of the lesioned paw')\n",
    "plt.fill_between(np.linspace(-2,2,81), \n",
    "                 mean_neuron1_vel - std_error_neuron1_vel,\n",
    "                 mean_neuron1_vel + std_error_neuron1_vel, alpha = 0.2, color='red')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.title('Neuron 1')\n",
    "plt.xlabel('time (s)')\n",
    "plt.legend(fontsize=8)\n",
    "\n",
    "#plt.gca().get_yaxis().set_visible(False)\n",
    "#plt.gca().yaxis(False)\n",
    "\n",
    "X_POSITION = 0\n",
    "plt.axvline(X_POSITION, linestyle = '--', color = 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfe045",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d24198",
   "metadata": {},
   "source": [
    "## 2.5.3  Aligned to initiations detected using the velocity of the nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_initiations_nose = []\n",
    "for i in range(len(df_vel_filtered['Timestamp'])):\n",
    "    if i in initiations_nose_corrected:\n",
    "        ts_initiations_nose.append(df_vel_filtered['Timestamp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33bf00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the inscopix timestamps which are the closest to the timestamps corresponting to initiations detected using the \n",
    "# velocity of the nose (DLC)\n",
    "closest_inscop_ts_to_nose_init = []\n",
    "for ts in ts_initiations_nose:\n",
    "    closest_ts = find_closest(df_calcium_raw['Timestamp'], ts)\n",
    "    closest_inscop_ts_to_nose_init.append(closest_ts)\n",
    "    \n",
    "indices_inscop_closest_ts_to_nose_init = []\n",
    "for ts in closest_inscop_ts_to_nose_init:\n",
    "    indices_inscop_closest_ts_to_nose_init.append(df_calcium_raw['Timestamp'].loc[df_calcium['Timestamp']==ts])\n",
    "    \n",
    "for i, j in zip(indices_inscop_closest_ts_to_nose_init, range(len(indices_inscop_closest_ts_to_nose_init))):\n",
    "    indices_inscop_closest_ts_to_nose_init[j] = i.index[0] \n",
    "\n",
    "# this array represents the indices of the Inscopix dataframe whose timestamps are the closest to the \n",
    "# timestamps of the initiations calculated using data from the accelerometer\n",
    "indices_inscop_closest_ts_to_nose_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ae97c",
   "metadata": {},
   "source": [
    "## 2.5.4 Aligned to initiations detected using the velocity of the left hind paw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f173c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_initiations_lhp = []\n",
    "for i in range(len(df_vel_filtered['Timestamp'])):\n",
    "    if i in initiations_lhp_corrected:\n",
    "        ts_initiations_lhp.append(df_vel_filtered['Timestamp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c315938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the inscopix timestamps which are the closest to the timestamps corresponting to initiations detected using the \n",
    "# velocity of the left hind paw\n",
    "closest_inscop_ts_to_lhp_init = []\n",
    "for ts in ts_initiations_lhp:\n",
    "    closest_ts = find_closest(df_calcium_raw['Timestamp'], ts)\n",
    "    closest_inscop_ts_to_lhp_init.append(closest_ts)\n",
    "    \n",
    "indices_inscop_closest_ts_to_lhp_init = []\n",
    "for ts in closest_inscop_ts_to_lhp_init:\n",
    "    indices_inscop_closest_ts_to_lhp_init.append(df_calcium_raw['Timestamp'].loc[df_calcium['Timestamp']==ts])\n",
    "    \n",
    "for i, j in zip(indices_inscop_closest_ts_to_lhp_init, range(len(indices_inscop_closest_ts_to_lhp_init))):\n",
    "    indices_inscop_closest_ts_to_lhp_init[j] = i.index[0] \n",
    "\n",
    "# this array represents the indices of the Inscopix dataframe whose timestamps are the closest to the \n",
    "# timestamps of the initiations calculated using data from the accelerometer\n",
    "indices_inscop_closest_ts_to_lhp_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99351d",
   "metadata": {},
   "source": [
    "# All neurons...\n",
    "Generalize the implementation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2140c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# create a dataframe containing the z score of the raw calcium traces \n",
    "df_C_raw_zscore = pd.DataFrame()\n",
    "for col in df_calcium_raw.columns[:-1]:\n",
    "    df_C_raw_zscore[col] = st.zscore(df_calcium_raw[col])\n",
    "df_C_raw_zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f60a4d",
   "metadata": {},
   "source": [
    "### Total body acceleration (tba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this step I need to create a new 'matrix_sequences_tba', suited to \n",
    "# the Inscopix aq rate\n",
    "time_sec = 2\n",
    "wind1 = -inscopix_aq_rate*time_sec\n",
    "wind2 = inscopix_aq_rate*time_sec+1\n",
    "\n",
    "matrix_initiations_tba_inscopix = np.tile(np.vstack(indices_inscop_closest_ts_to_accel_init), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_tba_inscopix = np.tile(range(wind1, wind2), (len(indices_inscop_closest_ts_to_accel_init),1))\n",
    "matrix_sequences_tba_inscopix = matrix_initiations_tba_inscopix + matrix_operation_tba_inscopix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep in mind that if there are negative elements in a sequence OR\n",
    "# elements surpassing the lenth of the data, those sequences should not \n",
    "# be counted ...\n",
    "# this is a temporary solution for this problem, since I only check the first and last initiations\n",
    "for i in range(5):\n",
    "    if matrix_sequences_tba_inscopix[0][0]<0:\n",
    "        matrix_sequences_tba_inscopix = np.delete(matrix_sequences_tba_inscopix, 0, 0)\n",
    "    elif matrix_sequences_tba_inscopix[-1][-1]>=neuron_mat_info['C_raw'].shape[1]:\n",
    "        matrix_sequences_tba_inscopix = np.delete(matrix_sequences_tba_inscopix, -1, 0)\n",
    "len(matrix_sequences_tba_inscopix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sec = 2\n",
    "wind1=-inscopix_aq_rate*time_sec\n",
    "accel_peth_neurons = np.empty([int(neuron_mat_info['C_raw'].shape[0]), np.abs(wind1)*2+1])\n",
    "for i, neuron in zip(np.arange(int(neuron_mat_info['C_raw'].shape[0])), df_C_raw_zscore.columns):\n",
    "    accel_peth_neurons[i, :] = np.mean(np.array(df_C_raw_zscore[neuron])[matrix_sequences_tba_inscopix], axis=0)\n",
    "accel_peth_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_peth_neurons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_after_event = []\n",
    "for neuron in accel_peth_neurons:\n",
    "    activity_after_event.append(np.mean(neuron[40:61]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [i[0] for i in sorted(enumerate(activity_after_event), key=lambda x:x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5829a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_peth_neurons_ordered = []\n",
    "for index in order:\n",
    "    accel_peth_neurons_ordered.append(accel_peth_neurons[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b2780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "custom_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"custom\", [\"#29bbd9\",\"black\", \"#fbff00\"])\n",
    "plt.imshow(accel_peth_neurons_ordered, cmap=custom_cmap, vmin=-0.8, vmax=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866cba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_peth_accel = np.mean(accel_peth_neurons_ordered, axis=0)\n",
    "std_error_peth_accel = np.std(accel_peth_neurons_ordered, axis=0)/math.sqrt(len(accel_peth_neurons_ordered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d671305",
   "metadata": {},
   "source": [
    "### Right hind paw (rhp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e8576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this step I need to create a new 'matrix_sequences_rhp', suited to \n",
    "# the Inscopix aq rate\n",
    "time_sec = 2\n",
    "wind1 = -inscopix_aq_rate*time_sec\n",
    "wind2 = inscopix_aq_rate*time_sec+1\n",
    "\n",
    "matrix_initiations_rhp_inscopix = np.tile(np.vstack(indices_inscop_closest_ts_to_vel_init), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_rhp_inscopix = np.tile(range(wind1, wind2), (len(indices_inscop_closest_ts_to_vel_init),1))\n",
    "matrix_sequences_rhp_inscopix = matrix_initiations_rhp_inscopix + matrix_operation_rhp_inscopix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep in mind that if there are negative elements in a sequence OR\n",
    "# elements surpassing the lenth of the data, those sequences should not \n",
    "# be counted ...\n",
    "# this is a temporary solution for this problem, since I only check the first and last initiations\n",
    "for i in range(5):\n",
    "    if matrix_sequences_rhp_inscopix[0][0]<0:\n",
    "        matrix_sequences_rhp_inscopix = np.delete(matrix_sequences_rhp_inscopix, 0, 0)\n",
    "    elif matrix_sequences_rhp_inscopix[-1][-1]>=neuron_mat_info['C_raw'].shape[1]:\n",
    "        matrix_sequences_rhp_inscopix = np.delete(matrix_sequences_rhp_inscopix, -1, 0)\n",
    "len(matrix_sequences_rhp_inscopix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71648d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhp_peth_neurons = np.empty([int(neuron_mat_info['C_raw'].shape[0]), np.abs(wind1)*2+1])\n",
    "for i, neuron in zip(np.arange(int(neuron_mat_info['C_raw'].shape[0])), df_C_raw_zscore.columns):\n",
    "    rhp_peth_neurons[i, :] = np.mean(np.array(df_C_raw_zscore[neuron])[matrix_sequences_rhp_inscopix], axis=0)\n",
    "rhp_peth_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhp_peth_neurons_ordered = []\n",
    "for index in order:\n",
    "    rhp_peth_neurons_ordered.append(rhp_peth_neurons[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_peth_rhp = np.mean(rhp_peth_neurons_ordered, axis=0)\n",
    "std_error_peth_rhp = np.std(rhp_peth_neurons_ordered, axis=0)/math.sqrt(len(rhp_peth_neurons_ordered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83522eeb",
   "metadata": {},
   "source": [
    "### Nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49014795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this step I need to create a new 'matrix_sequences_nose', suited to \n",
    "# the Inscopix aq rate\n",
    "time_sec = 2\n",
    "wind1 = -inscopix_aq_rate*time_sec\n",
    "wind2 = inscopix_aq_rate*time_sec+1\n",
    "\n",
    "matrix_initiations_nose_inscopix = np.tile(np.vstack(indices_inscop_closest_ts_to_nose_init), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_nose_inscopix = np.tile(range(wind1, wind2), (len(indices_inscop_closest_ts_to_nose_init),1))\n",
    "matrix_sequences_nose_inscopix = matrix_initiations_nose_inscopix + matrix_operation_nose_inscopix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep in mind that if there are negative elements in a sequence OR\n",
    "# elements surpassing the lenth of the data, those sequences should not \n",
    "# be counted ...\n",
    "# this is a temporary solution for this problem, since I only check the first and last initiations\n",
    "for i in range(5):\n",
    "    if matrix_sequences_nose_inscopix[0][0]<0:\n",
    "        matrix_sequences_nose_inscopix = np.delete(matrix_sequences_nose_inscopix, 0, 0)\n",
    "    elif matrix_sequences_nose_inscopix[-1][-1]>=neuron_mat_info['C_raw'].shape[1]:\n",
    "        matrix_sequences_nose_inscopix = np.delete(matrix_sequences_nose_inscopix, -1, 0)\n",
    "len(matrix_sequences_nose_inscopix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nose_peth_neurons = np.empty([int(neuron_mat_info['C_raw'].shape[0]), np.abs(wind1)*2+1])\n",
    "for i, neuron in zip(np.arange(int(neuron_mat_info['C_raw'].shape[0])), df_C_raw_zscore.columns):\n",
    "    nose_peth_neurons[i, :] = np.mean(np.array(df_C_raw_zscore[neuron])[matrix_sequences_nose_inscopix], axis=0)\n",
    "nose_peth_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nose_peth_neurons_ordered = []\n",
    "for index in order:\n",
    "    nose_peth_neurons_ordered.append(nose_peth_neurons[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0307f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_peth_nose = np.mean(nose_peth_neurons_ordered, axis=0)\n",
    "std_error_peth_nose = np.std(nose_peth_neurons_ordered, axis=0)/math.sqrt(len(nose_peth_neurons_ordered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nose_peth_neurons_ordered, cmap=custom_cmap, vmin=-0.8, vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187585de",
   "metadata": {},
   "source": [
    "### Left hind paw (lhp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ea32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this step I need to create a new 'matrix_sequences_nose', suited to \n",
    "# the Inscopix aq rate\n",
    "time_sec = 2\n",
    "wind1 = -inscopix_aq_rate*time_sec\n",
    "wind2 = inscopix_aq_rate*time_sec+1\n",
    "\n",
    "matrix_initiations_lhp_inscopix = np.tile(np.vstack(indices_inscop_closest_ts_to_lhp_init), (1, len(range(wind1, wind2))))\n",
    "matrix_operation_lhp_inscopix = np.tile(range(wind1, wind2), (len(indices_inscop_closest_ts_to_lhp_init),1))\n",
    "matrix_sequences_lhp_inscopix = matrix_initiations_lhp_inscopix + matrix_operation_lhp_inscopix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhp_peth_neurons = []\n",
    "for column in df_C_raw_zscore.columns:\n",
    "    lhp_peth_neurons.append(sum(np.array(df_C_raw_zscore[column])[matrix_sequences_lhp_inscopix[2:-1]])/(len(initiations_lhp_corrected)-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daac733",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhp_peth_neurons_ordered = []\n",
    "for index in order:\n",
    "    lhp_peth_neurons_ordered.append(lhp_peth_neurons[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lhp_peth_neurons_ordered, cmap=custom_cmap, vmin=-0.8, vmax=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54deb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_peth_lhp = np.mean(lhp_peth_neurons_ordered, axis=0)\n",
    "std_error_peth_lhp = np.std(lhp_peth_neurons_ordered, axis=0)/math.sqrt(len(lhp_peth_neurons_ordered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2bbd80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17e060",
   "metadata": {},
   "source": [
    "##### Plot containing 'all' the information relative to total body acceleration, lesioned paw, nose and left hind paw (except px change) - use a similar structure to the previous plot (this is relative to only one session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf944e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the figure and define the display of the subplots\n",
    "fig, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8), (ax9, ax10, ax11, ax12), (ax13, ax14, ax15, ax16), (ax17, ax18, ax19, ax20)) = plt.subplots(5, 4, \n",
    "                       gridspec_kw={'width_ratios': [1, 1, 1, 1],'height_ratios': [4, 1, 1, 1, 1]}, constrained_layout=False)\n",
    "# need to adjust height ratios\n",
    "\n",
    "ratio = 0.7\n",
    "fig.suptitle('Mice_'+path_data.split('\\\\')[4], fontweight='bold')\n",
    "\n",
    "# set the spacing between subplots\n",
    "plt.subplots_adjust(left=0.1,bottom=0.1, right=0.5, top=0.9, wspace=0.8, hspace=0.2)\n",
    "\n",
    "### ROW_1 ### PETH ###\n",
    "\n",
    "# customize a colormap (goes from blue-negative to black-0 to yellow-positive)\n",
    "custom_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"custom\", [\"#29bbd9\",\"black\", \"#fbff00\"])\n",
    "'''# subplot 1 - PETH of the initiations detected using the accelerometer\n",
    "ax1.imshow(df_neurons_means_transposed.sort_values(by = 'activity_after_initiation', ascending=False), \n",
    "           cmap=custom_cmap, aspect=1, vmin=-0.8, vmax=0.8)\n",
    "ax1.set_title('Movement initiations\\n(total body acceleration)')\n",
    "ax1.set_ylabel('Neuron #')\n",
    "ax1.grid(False)\n",
    "ax1.set_xticks([0, 40, 80], labels = [-2,0,2])'''\n",
    "\n",
    "# subplot 1 - PETH of the initiations detected using the accelerometer\n",
    "ax1.imshow(accel_peth_neurons_ordered, \n",
    "           cmap=custom_cmap, aspect=1, vmin=-0.8, vmax=0.8)\n",
    "ax1.set_title('Movement initiations\\n(total body acceleration)')\n",
    "ax1.set_ylabel('Neuron #')\n",
    "ax1.grid(False)\n",
    "ax1.set_xticks([0, 40, 80], labels = [-2,0,2])\n",
    "\n",
    "# subplot 2 - PETH of the initiations detected using the velocity computed from the DLC predictions of the right hindpaw coordinates\n",
    "pcm_2 = ax2.imshow(rhp_peth_neurons_ordered, \n",
    "                 cmap=custom_cmap, aspect=1, vmin=-0.8, vmax=0.8)\n",
    "ax2.set_title('Movement initiations\\n(velocity of the lesioned paw)')\n",
    "ax2.grid(False)\n",
    "ax2.set_xticks([0, 40, 80], labels = [-2,0,2])\n",
    "\n",
    "'''#fig.colorbar(pcm, ax=ax2, shrink=0.6)\n",
    "# colorbar not working!!!\n",
    "cax = plt.axes([0.9, 0.1, 0.045, 0.80])\n",
    "plt.colorbar(img, ax2=ax2)'''\n",
    "\n",
    "# subplot 3 - PETH of the initiations detected using the velocity computed from the DLC predictions of the nose\n",
    "pcm_3 = ax3.imshow(nose_peth_neurons_ordered, \n",
    "                 cmap=custom_cmap, aspect=1, vmin=-0.8, vmax=0.8)\n",
    "ax3.set_title('Movement initiations\\n(velocity of the nose)')\n",
    "ax3.grid(False)\n",
    "ax3.set_xticks([0, 40, 80], labels = [-2,0,2])\n",
    "\n",
    "# subplot 4 - PETH of the initiations detected using the velocity computed from the DLC predictions of the left hindpaw coordinates\n",
    "pcm_4 = ax4.imshow(lhp_peth_neurons_ordered, \n",
    "                 cmap=custom_cmap, aspect=1, vmin=-0.8, vmax=0.8)\n",
    "ax4.set_title('Movement initiations\\n(velocity of the left hind paw)')\n",
    "ax4.grid(False)\n",
    "ax4.set_xticks([0, 40, 80], labels = [-2,0,2])\n",
    "\n",
    "### ROW_2 ### Probability density function of movement initiations\n",
    "# subplot 5 - total body acceleration\n",
    "ax5.set_ylabel('P (initiation)')\n",
    "wind2 = fs*time_sec+1\n",
    "ax5.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density)/matrix_pre_probability_density.shape[0], color = 'red')\n",
    "ax5.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax5.spines['top'].set_visible(False)\n",
    "ax5.spines['right'].set_visible(False)\n",
    "ax5.grid(False)\n",
    "x_left, x_right = ax5.get_xlim()\n",
    "y_low, y_high = ax5.get_ylim()\n",
    "ax5.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 6 - lesioned paw (DLC velocity)\n",
    "wind2 = camera_aq_rate*time_sec+1\n",
    "ax6.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density_rhp)/matrix_pre_probability_density_rhp.shape[0], color = 'red')\n",
    "ax6.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax6.spines['top'].set_visible(False)\n",
    "ax6.spines['right'].set_visible(False)\n",
    "ax6.grid(False)\n",
    "x_left, x_right = ax6.get_xlim()\n",
    "y_low, y_high = ax6.get_ylim()\n",
    "ax6.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "# subplot 7 - nose (DLC velocity)\n",
    "ax7.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density_nose)/matrix_pre_probability_density_nose.shape[0], color = 'red')\n",
    "ax7.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax7.spines['top'].set_visible(False)\n",
    "ax7.spines['right'].set_visible(False)\n",
    "ax7.grid(False)\n",
    "x_left, x_right = ax7.get_xlim()\n",
    "y_low, y_high = ax7.get_ylim()\n",
    "ax7.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "# subplot 8 - left hind paw (DLC velocity)\n",
    "ax8.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density_lhp)/matrix_pre_probability_density_lhp.shape[0], color = 'red')\n",
    "ax8.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax8.spines['top'].set_visible(False)\n",
    "ax8.spines['right'].set_visible(False)\n",
    "ax8.grid(False)\n",
    "x_left, x_right = ax8.get_xlim()\n",
    "y_low, y_high = ax8.get_ylim()\n",
    "ax8.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "\n",
    "### ROW_3 ### Average of the PETH\n",
    "# subplot 9 - Average of the PETH aligned to the initiations detected using the total body acceleration\n",
    "ax9.set_ylabel('C_raw (z-score)')\n",
    "ax9.set_ylim([-0.06,0.06])\n",
    "ax9.plot(np.linspace(-2,2,81), mean_peth_accel, label='Average of the PETH')\n",
    "ax9.fill_between(np.linspace(-2,2,81), \n",
    "                 mean_peth_accel - std_error_peth_accel,\n",
    "                 mean_peth_accel + std_error_peth_accel, alpha = 0.2)\n",
    "ax9.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax9.spines['top'].set_visible(False)\n",
    "ax9.spines['right'].set_visible(False)\n",
    "ax9.grid(False)\n",
    "x_left, x_right = ax9.get_xlim()\n",
    "y_low, y_high = ax9.get_ylim()\n",
    "ax9.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "ax9.legend(fontsize=6)\n",
    "\n",
    "# sublpot 10 - Average of the PETH aligned to the initiations detected using the velocity from the right hindpaw heel\n",
    "ax10.set_ylim([-0.06,0.06])\n",
    "ax10.plot(np.linspace(-2,2,81), mean_peth_rhp, label='Average of the PETH')\n",
    "ax10.fill_between(np.linspace(-2,2,81), \n",
    "                 mean_peth_rhp - std_error_peth_rhp,\n",
    "                 mean_peth_rhp + std_error_peth_rhp, alpha = 0.2)\n",
    "ax10.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax10.spines['top'].set_visible(False)\n",
    "ax10.spines['right'].set_visible(False)\n",
    "ax10.grid(False)\n",
    "x_left, x_right = ax10.get_xlim()\n",
    "y_low, y_high = ax10.get_ylim()\n",
    "ax10.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "ax10.legend(fontsize=6)\n",
    "\n",
    "# subplot 11 - Average of the PETH aligned to the initiations detected using the velocity from the nose\n",
    "ax11.set_ylim([-0.06,0.06])\n",
    "ax11.plot(np.linspace(-2,2,81), mean_peth_nose, label='Average of the PETH')\n",
    "ax11.fill_between(np.linspace(-2,2,81), mean_peth_nose-std_error_peth_nose, \n",
    "                  mean_peth_nose+std_error_peth_nose, alpha = 0.2)\n",
    "X_POSITION = 0\n",
    "ax11.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax11.spines['top'].set_visible(False)\n",
    "ax11.spines['right'].set_visible(False)\n",
    "ax11.grid(False)\n",
    "x_left, x_right = ax11.get_xlim()\n",
    "y_low, y_high = ax11.get_ylim()\n",
    "ax11.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "ax11.legend(fontsize=6)\n",
    "\n",
    "# subplot 12 - Average of the PETH aligned to the initiations detected using the velocity from the left hindpaw heel\n",
    "ax12.set_ylim([-0.06,0.06])\n",
    "ax12.plot(np.linspace(-2,2,81), mean_peth_lhp, label='Average of the PETH')\n",
    "ax12.fill_between(np.linspace(-2,2,81), mean_peth_lhp-std_error_peth_lhp, mean_peth_lhp+std_error_peth_lhp, alpha = 0.2)\n",
    "X_POSITION = 0\n",
    "ax12.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax12.spines['top'].set_visible(False)\n",
    "ax12.spines['right'].set_visible(False)\n",
    "ax12.grid(False)\n",
    "x_left, x_right = ax12.get_xlim()\n",
    "y_low, y_high = ax12.get_ylim()\n",
    "ax12.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "ax12.legend(fontsize=6)\n",
    "\n",
    "### ROW_4 ### Total body acceleration\n",
    "# subplot 13 - Movement initiations\n",
    "ax13.set_ylabel('Total body\\nacceleration (?)')\n",
    "time_sec=2\n",
    "beg_plot = -fs*time_sec\n",
    "end_plot = fs*time_sec+1\n",
    "ax13.set_ylim([0,2000])\n",
    "ax13.plot(np.linspace(-2,2,801), df_initiations_accel_sequence_interest.mean(axis=1), color='green')\n",
    "ax13.fill_between(np.linspace(-2,2,801), \n",
    "                 mean_accel - std_error_accel,\n",
    "                 mean_accel + std_error_accel, alpha = 0.2, color='green')\n",
    "\n",
    "ax13.spines['top'].set_visible(False)\n",
    "ax13.spines['right'].set_visible(False)\n",
    "ax13.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax13.grid(False)\n",
    "x_left, x_right = ax13.get_xlim()\n",
    "y_low, y_high = ax13.get_ylim()\n",
    "ax13.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 14 - TBA aligned to movement initiations of the right hind paw\n",
    "ax14.set_ylim([0,2000])\n",
    "ax14.plot(np.linspace(-2,2,801), df_accel_aligned_to_vel.mean(axis=1), color='green')\n",
    "ax14.fill_between(np.linspace(-2,2,801), \n",
    "                 mean_accel_ - std_error_accel_,\n",
    "                 mean_accel_ + std_error_accel_, alpha = 0.2, color='green')\n",
    "\n",
    "ax14.spines['top'].set_visible(False)\n",
    "ax14.spines['right'].set_visible(False)\n",
    "ax14.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax14.grid(False)\n",
    "x_left, x_right = ax14.get_xlim()\n",
    "y_low, y_high = ax14.get_ylim()\n",
    "ax14.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 15 - TBA aligned to movement initiations of the nose\n",
    "wind2 = fs*time_sec+1\n",
    "ax15.set_ylim([0,2000])\n",
    "mean_tba_aligned_2nose = sum(TBA_aligned_2nose_peth)/(len(indices_closest_ts_2nose_vel_init)-1)\n",
    "std_tba_aligned_2nose = TBA_aligned_2nose_peth.std(axis=0) \n",
    "std_error_tba_aligned_2nose = std_tba_aligned_2nose/math.sqrt(len(indices_closest_ts_2nose_vel_init)-1)\n",
    "ax15.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_tba_aligned_2nose, color = 'green')\n",
    "ax15.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_tba_aligned_2nose - std_error_tba_aligned_2nose,\n",
    "                 mean_tba_aligned_2nose + std_error_tba_aligned_2nose, alpha = 0.2, color = 'green')\n",
    "ax15.spines['top'].set_visible(False) \n",
    "ax15.spines['right'].set_visible(False)\n",
    "ax15.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax15.grid(False)\n",
    "x_left, x_right = ax15.get_xlim()\n",
    "y_low, y_high = ax15.get_ylim()\n",
    "ax15.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 16 - TBA aligned to movement initiations of the left hind paw\n",
    "ax16.set_ylim([0,2000])\n",
    "mean_tba_aligned_2lhp = sum(TBA_aligned_2lhp_peth)/(len(indices_closest_ts_2lhp_vel_init))\n",
    "std_tba_aligned_2lhp = TBA_aligned_2lhp_peth.std(axis=0) \n",
    "std_error_tba_aligned_2lhp = std_tba_aligned_2lhp/math.sqrt(len(indices_closest_ts_2lhp_vel_init))\n",
    "ax16.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_tba_aligned_2lhp, color = 'green')\n",
    "ax16.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_tba_aligned_2lhp - std_error_tba_aligned_2lhp,\n",
    "                 mean_tba_aligned_2lhp + std_error_tba_aligned_2lhp, alpha = 0.2, color = 'green')\n",
    "ax16.spines['top'].set_visible(False)\n",
    "ax16.spines['right'].set_visible(False)\n",
    "ax16.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax16.grid(False)\n",
    "x_left, x_right = ax16.get_xlim()\n",
    "y_low, y_high = ax16.get_ylim()\n",
    "ax16.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "### ROW_5 ### Velocity\n",
    "# subplot 17 - all velocities aligned to the movement initiations calculated form the total body acceleration\n",
    "wind2=camera_aq_rate*time_sec+1\n",
    "ax17.set_ylim([0,20])\n",
    "ax17.plot(np.linspace(-2,2,(wind2-1)*2+1), df_velocities_aligned_to_accel.mean(axis=1), label = 'right hind paw', color = 'purple')\n",
    "ax17.fill_between(np.linspace(-2,2,(wind2-1)*2+1), \n",
    "                 mean_velocity - std_error_velocity,\n",
    "                 mean_velocity + std_error_velocity, alpha = 0.2, color = 'purple')\n",
    "ax17.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_nose_aligned_2accel, color = 'yellow', label = 'nose')\n",
    "ax17.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_nose_aligned_2accel - std_error_nose_aligned_2accel,\n",
    "                 mean_nose_aligned_2accel + std_error_nose_aligned_2accel, alpha = 0.2, color = 'yellow')\n",
    "ax17.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_lhp_aligned_2accel, color = 'deeppink', label = 'left hind paw')\n",
    "ax17.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_lhp_aligned_2accel - std_error_lhp_aligned_2accel,\n",
    "                 mean_lhp_aligned_2accel + std_error_lhp_aligned_2accel, alpha = 0.2, color = 'deeppink')\n",
    "ax17.spines['top'].set_visible(False)\n",
    "ax17.spines['right'].set_visible(False)\n",
    "ax17.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax17.set_ylabel('Velocity\\n(px/frame)')\n",
    "ax17.set_xlabel('time (s)')\n",
    "ax17.grid(False)\n",
    "x_left, x_right = ax17.get_xlim()\n",
    "y_low, y_high = ax17.get_ylim()\n",
    "ax17.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "leg = ax17.legend(fontsize=6)\n",
    "\n",
    "# subplot 18 - movement initiations with the right hind paw\n",
    "ax18.set_ylim([0,20])\n",
    "ax18.plot(np.linspace(-2,2,121), df_initiations_sequence_interest.mean(axis=1), color='purple')\n",
    "mean_ = df_initiations_sequence_interest.mean(axis=1)\n",
    "std_error = (df_initiations_sequence_interest.std(axis=1)/math.sqrt(len(initiation_right_paw_corrected))) #standard error\n",
    "ax18.fill_between(np.linspace(-2,2,121), \n",
    "                 mean_ - std_error,\n",
    "                 mean_ + std_error, alpha = 0.2, color='purple')\n",
    "ax18.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax18.spines['top'].set_visible(False)\n",
    "ax18.spines['right'].set_visible(False)\n",
    "ax18.set_xlabel('time (s)')\n",
    "ax18.grid(False)\n",
    "x_left, x_right = ax18.get_xlim()\n",
    "y_low, y_high = ax18.get_ylim()\n",
    "ax18.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 19 - movement initiations with the nose\n",
    "wind2=camera_aq_rate*time_sec+1\n",
    "ax19.set_ylim([0,20])\n",
    "ax19.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_nose, color='yellow')\n",
    "ax19.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_nose - std_error_nose,\n",
    "                 mean_nose + std_error_nose, alpha = 0.2, color='yellow')\n",
    "ax19.spines['top'].set_visible(False)\n",
    "ax19.spines['right'].set_visible(False)\n",
    "ax19.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax19.set_ylabel('Velocity\\n(px/frame)')\n",
    "ax19.set_xlabel('time (s)')\n",
    "ax19.grid(False)\n",
    "x_left, x_right = ax19.get_xlim()\n",
    "y_low, y_high = ax19.get_ylim()\n",
    "ax19.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 20 - movement initiations with the left hind paw\n",
    "ax20.set_ylim([0,20])\n",
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_lhp, color='deeppink')\n",
    "plt.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_lhp - std_error_lhp,\n",
    "                 mean_lhp + std_error_lhp, alpha = 0.2, color='deeppink')\n",
    "ax20.spines['top'].set_visible(False)\n",
    "ax20.spines['right'].set_visible(False)\n",
    "ax20.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax20.set_ylabel('Velocity\\n(px/frame)')\n",
    "ax20.set_xlabel('time (s)')\n",
    "ax20.grid(False)\n",
    "x_left, x_right = ax20.get_xlim()\n",
    "y_low, y_high = ax20.get_ylim()\n",
    "ax20.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446666b2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d970c7",
   "metadata": {},
   "source": [
    "## 2.6 Classify Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30722e7a",
   "metadata": {},
   "source": [
    "Are there neurons that are modulated by only one of the following? (tba, rhp, nose, lhp movement initiations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d4eb4b",
   "metadata": {},
   "source": [
    "**Description:** \n",
    "- For every neuron, do a peth (1000 rows);\n",
    "- Each row is a mean of X 'shuffled/sham initiations';\n",
    "- X - real number of events (in this case, movement initiations) in the corresponding session; \n",
    "- From the array containing the indices where the initiations occur, extract the distances between initiations (diff); \n",
    "- With this information, shuffle the distances and get the sham initiations sequences by doing a cumsum of the suffled distances from the first initiation; \n",
    "- How to obtain the first initiation? \n",
    "    1) Keep the first original initiation; \n",
    "    2) An option would be selecting an index randomly generated from [0; a+b] (a - number of points before first initiation and after the number of point needed for half a sequence; b - number of points after last initiation until  [length of the signal minus half a sequence]); \n",
    "- Then, compute the mean of that peth, the std deviation point by point, and build a criteria for classification according to a certain amount of time in which the mean of the sequences built from real initiations (so, the real peth for a single neuron) is above the mean of the sham initiations + cutOff (defined as 2,56*std(suff) at every point of the sequence)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf2d61b",
   "metadata": {},
   "source": [
    "## 2.6.1 Total body acceleration (TBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290bbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# define the window of the peth (x axis); e.g.: wind1<->event<->wind2\n",
    "time_sec = 1\n",
    "wind1 = -inscopix_aq_rate*time_sec\n",
    "wind2 = inscopix_aq_rate*time_sec+1\n",
    "\n",
    "# create a matrix (peth) to save the baseline activity of each neuron\n",
    "baseline_C_raw_zscore_accel = np.empty(\n",
    "    [neuron_mat_info['C_raw'].shape[0], np.abs(wind1)*2+1])\n",
    "\n",
    "# define the confidence interval - in this case, 99%\n",
    "z_alpha_over2 = 2.576\n",
    "# create a matrix to save the classification cutOff of each neuron\n",
    "cutOff_modulation_accel = np.empty(\n",
    "    [neuron_mat_info['C_raw'].shape[0], np.abs(wind1)*2+1])\n",
    "\n",
    "# create two arrays: one to save positively modulated neurons and another to save the negatively modulated neurons \n",
    "# (a better description is \"neurons that follow the criteria for positively/negatively modulated\")\n",
    "posmod_accel = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "negmod_accel = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "\n",
    "# for every neuron...\n",
    "for i, neuron in enumerate(df_C_raw_zscore.columns):\n",
    "    # create an array containing the temporal distance between consecutive events \n",
    "    diff_initiations_accel = np.diff(indices_inscop_closest_ts_to_accel_init)\n",
    "    # clone the above array, so that you have a copy that can be manipulated (the shuffle method is not reversible)\n",
    "    shuffled_diffs_accel = np.diff(indices_inscop_closest_ts_to_accel_init) # inspite of the name, it is initialized with the original events\n",
    "\n",
    "    num_shuffles = 1000  # number of shuffles\n",
    "\n",
    "    # create an empty array in which the mean of the shuffled events will be stored\n",
    "    sham_accel_peth_neurons = np.zeros(\n",
    "        [num_shuffles, np.abs(wind1)*2+1])\n",
    "\n",
    "    for j in range(num_shuffles):\n",
    "        # start by shuffling the distances between the events\n",
    "        random.shuffle(shuffled_diffs_accel)\n",
    "        # create the array in which the shuffled events will be stored\n",
    "        sham_initiations_accel = np.zeros(len(indices_inscop_closest_ts_to_accel_init))\n",
    "        # in this implementation, the first initiation is fixed (corresponds to the first initiation that was detected)...\n",
    "        sham_initiations_accel[0] = indices_inscop_closest_ts_to_accel_init[0]\n",
    "        # ...and the others are the cumsum of one shuffle of the diffs between the detected initiations. \n",
    "        # Note that the first initiation should be added to the diffs, so that the cumsum starts from there\n",
    "        sham_initiations_accel[1:] = np.cumsum(\n",
    "            shuffled_diffs_accel)+indices_inscop_closest_ts_to_accel_init[0]\n",
    "        # before proceeding, notice that even though the distances between initiations were randomized, the first element of the array corresponds\n",
    "        # ...to an initiation that was in fact detected. This shouldn´t be the case so a constant will be added to every element of the array (which \n",
    "        # ...is the equivalent of translocating the structure of the shuffled initiations in the x axis and randomizes the first initiation)\n",
    "        print(sham_initiations_accel)\n",
    "        x_translocation = np.arange(-(sham_initiations_accel[0]-20), ((len(df_C_raw_zscore)-21)-sham_initiations_accel[-1])+1)\n",
    "        print(x_translocation)\n",
    "        randomize_beggining = np.random.choice(x_translocation)\n",
    "        sham_initiations_accel += randomize_beggining\n",
    "        # so, now we have the sham initiations stored in memory and we can build the peth of the current shuffle\n",
    "        matrix_initiations_sham_accel = np.tile(\n",
    "            np.vstack(sham_initiations_accel), (1, len(range(wind1, wind2))))\n",
    "        matrix_operation_sham_accel = np.tile(\n",
    "            range(wind1, wind2), (len(indices_inscop_closest_ts_to_accel_init), 1))\n",
    "        matrix_sequences_sham_accel = matrix_initiations_sham_accel + matrix_operation_sham_accel\n",
    "        # eliminate sequences (wind1<->event<->wind2) for which we don't have all the points\n",
    "        for k in range(5):\n",
    "            if matrix_sequences_sham_accel[0][0] < 0:\n",
    "                matrix_sequences_sham_accel = np.delete(\n",
    "                    matrix_sequences_sham_accel, 0, 0)\n",
    "            elif matrix_sequences_sham_accel[-1][-1] >= neuron_mat_info['C_raw'].shape[1]:\n",
    "                matrix_sequences_sham_accel = np.delete(\n",
    "                    matrix_sequences_sham_accel, -1, 0)\n",
    "        # use the indexes calculated in the previous step to obtain the z-score of the C_raw data \n",
    "        # add the mean of the events relative to the current shuffle to the structure for the final 'sham' peth \n",
    "        sham_accel_peth_neurons[j,:] = np.mean(np.array(df_C_raw_zscore[neuron])[matrix_sequences_sham_accel.astype(int)], axis = 0)\n",
    "    \n",
    "    # compute the baseline of the current neuron as the average of all the averages of shuffled/sham initiations\n",
    "    baseline_C_raw_zscore_accel[i,:] = np.mean(sham_accel_peth_neurons, axis = 0)\n",
    "    # compute the classification cutOff of the currrent neuron as 2.576 times the standard deviation - confidence interval 99% \n",
    "    cutOff_modulation_accel[i,:] = z_alpha_over2*np.std(sham_accel_peth_neurons, axis=0)\n",
    "    # classify the current neuron as positively modulated\n",
    "    posmod = accel_peth_neurons[i][20:61] > baseline_C_raw_zscore_accel[i] + cutOff_modulation_accel[i]\n",
    "    if np.sum(posmod) > 3:\n",
    "        for l, mod in enumerate(posmod):\n",
    "            if posmod[l]==1 and posmod[l+1]==1 and posmod[l+2]==1:\n",
    "                posmod_accel[i] = 1\n",
    "                break\n",
    "    # classify the current neuron as negatively modulated\n",
    "    negmod = accel_peth_neurons[i][20:61] < baseline_C_raw_zscore_accel[i] - cutOff_modulation_accel[i]\n",
    "    if np.sum(negmod) > 3:\n",
    "        for m, mod in enumerate(negmod):\n",
    "            if negmod[m] == 1 and negmod[m+1] == 1 and negmod[m+2] == 1:\n",
    "                negmod_accel[i]= 1\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040099e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2)\n",
    "\n",
    "ax1.imshow(accel_peth_neurons[posmod_accel==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2.imshow(accel_peth_neurons[negmod_accel==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "\n",
    "ax3.imshow(accel_peth_neurons[posmod_accel==0], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax4.imshow(accel_peth_neurons[negmod_accel==0], cmap=custom_cmap, vmin=-0.8, vmax=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766e853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2, ax3)) = plt.subplots(1,3)\n",
    "# baseline of all neurons\n",
    "ax1.imshow(baseline_C_raw_zscore, cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax1.set_title('Baseline')\n",
    "# cutOff of all neurons\n",
    "ax2.imshow(cutOff_modulation_accel, cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2.set_title('Classification cutOff')\n",
    "# peth of all neurons\n",
    "ax3.imshow(accel_peth_neurons, cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax3.set_title('Total body acceleration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basline -+ cutOff (example for the last neuron)\n",
    "plt.plot(np.linspace(-2, 2, 41), np.mean(sham_accel_peth_neurons, axis=0))\n",
    "plt.fill_between(np.linspace(-2, 2, 41),\n",
    "                 np.mean(sham_accel_peth_neurons, axis=0) -\n",
    "                 2.576*np.std(sham_accel_peth_neurons, axis=0),\n",
    "                 np.mean(sham_accel_peth_neurons, axis=0) + 2.576*np.std(sham_accel_peth_neurons, axis=0), alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347b761",
   "metadata": {},
   "source": [
    "## 2.6.2 Right hind paw (rhp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216549f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# define the window of the peth (x axis); e.g.: wind1<->event<->wind2\n",
    "time_sec = 1\n",
    "wind1 = -inscopix_aq_rate*time_sec\n",
    "wind2 = inscopix_aq_rate*time_sec+1\n",
    "\n",
    "# create a matrix (peth) to save the baseline activity of each neuron\n",
    "baseline_C_raw_zscore_rhp = np.empty(\n",
    "    [neuron_mat_info['C_raw'].shape[0], np.abs(wind1)*2+1])\n",
    "\n",
    "# define the confidence interval - in this case, 99%\n",
    "z_alpha_over2 = 2.576\n",
    "# create a matrix to save the classification cutOff of each neuron\n",
    "cutOff_modulation_rhp = np.empty(\n",
    "    [neuron_mat_info['C_raw'].shape[0], np.abs(wind1)*2+1])\n",
    "\n",
    "# create two arrays: one to save positively modulated neurons and another to save the negatively modulated neurons\n",
    "posmod_rhp = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "negmod_rhp = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "\n",
    "# for every neuron...\n",
    "for i, neuron in enumerate(df_C_raw_zscore.columns):\n",
    "    print(i, neuron)  # delete this\n",
    "    # create an array containing the temporal distance between consecutive events\n",
    "    diff_initiations_rhp = np.diff(indices_inscop_closest_ts_to_vel_init)\n",
    "    # clone the above array, so that you have a copy that can be manipulated (the shuffle method is not reversible)\n",
    "    # inspite of the name, it is initialized with the original events\n",
    "    shuffled_diffs_rhp = np.diff(indices_inscop_closest_ts_to_vel_init)\n",
    "\n",
    "    num_shuffles = 1000  # number of shuffles\n",
    "\n",
    "    # create an empty array in which the mean of the shuffled events will be stored\n",
    "    sham_rhp_peth_neurons = np.zeros(\n",
    "        [num_shuffles, np.abs(wind1)*2+1])\n",
    "\n",
    "    for j in range(num_shuffles):\n",
    "        # start by shuffling the distances between the events\n",
    "        random.shuffle(shuffled_diffs_rhp)\n",
    "        # create the array in which the shuffled events will be stored\n",
    "        sham_initiations_rhp = np.zeros(\n",
    "            len(indices_inscop_closest_ts_to_vel_init))\n",
    "        # in this implementation, the first initiation is fixed (corresponds to the first initiation that was detected)...\n",
    "        sham_initiations_rhp[0] = indices_inscop_closest_ts_to_vel_init[0]\n",
    "        # ...and the others are the cumsum of one shuffle of the diffs between the detected initiations.\n",
    "        # Note that the first initiation should be added to the diffs, so that the cumsum starts from there\n",
    "        sham_initiations_rhp[1:] = np.cumsum(\n",
    "            shuffled_diffs_rhp)+indices_inscop_closest_ts_to_vel_init[0]\n",
    "        # so, now we have the sham initiations stored in memory and we can build the peth of the current shuffle\n",
    "        matrix_initiations_sham_rhp = np.tile(\n",
    "            np.vstack(sham_initiations_rhp), (1, len(range(wind1, wind2))))\n",
    "        matrix_operation_sham_rhp = np.tile(\n",
    "            range(wind1, wind2), (len(indices_inscop_closest_ts_to_vel_init), 1))\n",
    "        matrix_sequences_sham_rhp = matrix_initiations_sham_rhp + matrix_operation_sham_rhp\n",
    "        # eliminate sequences (wind1<->event<->wind2) for which we don't have all the points\n",
    "        for k in range(5):\n",
    "            if matrix_sequences_sham_rhp[0][0] < 0:\n",
    "                matrix_sequences_sham_rhp = np.delete(\n",
    "                    matrix_sequences_sham_rhp, 0, 0)\n",
    "            elif matrix_sequences_sham_rhp[-1][-1] >= neuron_mat_info['C_raw'].shape[1]:\n",
    "                matrix_sequences_sham_rhp = np.delete(\n",
    "                    matrix_sequences_sham_rhp, -1, 0)\n",
    "        # use the indexes calculated in the previous step to obtain the z-score of the C_raw data\n",
    "        # add the mean of the events relative to the current shuffle to the structure for the final 'sham' peth\n",
    "        sham_rhp_peth_neurons[j, :] = np.mean(np.array(df_C_raw_zscore[neuron])[\n",
    "                                                matrix_sequences_sham_rhp.astype(int)], axis=0)\n",
    "\n",
    "    # compute the baseline of the current neuron as the average of all the averages of shuffled/sham initiations\n",
    "    baseline_C_raw_zscore_rhp[i, :] = np.mean(\n",
    "        sham_rhp_peth_neurons, axis=0)\n",
    "    # compute the classification cutOff of the currrent neuron as 2.576 times the standard deviation - confidence interval 99%\n",
    "    cutOff_modulation_rhp[i, :] = z_alpha_over2 * \\\n",
    "        np.std(sham_rhp_peth_neurons, axis=0)\n",
    "    # classify the current neuron as positively modulated\n",
    "    posmod = rhp_peth_neurons[i][20:61] > baseline_C_raw_zscore_rhp[i] + \\\n",
    "        cutOff_modulation_rhp[i]\n",
    "    if np.sum(posmod) > 3:\n",
    "        for l, mod in enumerate(posmod):\n",
    "            if posmod[l] == 1 and posmod[l+1] == 1 and posmod[l+2] == 1:\n",
    "                posmod_rhp[i] = 1\n",
    "                break\n",
    "    # classify the current neuron as negatively modulated\n",
    "    negmod = rhp_peth_neurons[i][20:61] < baseline_C_raw_zscore_rhp[i] - \\\n",
    "        cutOff_modulation_rhp[i]\n",
    "    if np.sum(negmod) > 3:\n",
    "        for m, mod in enumerate(negmod):\n",
    "            if negmod[m] == 1 and negmod[m+1] == 1 and negmod[m+2] == 1:\n",
    "                negmod_rhp[i] = 1\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2)\n",
    "\n",
    "ax1.imshow(rhp_peth_neurons[posmod_rhp==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2.imshow(rhp_peth_neurons[negmod_rhp==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "\n",
    "ax3.imshow(rhp_peth_neurons[posmod_rhp==0], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax4.imshow(rhp_peth_neurons[negmod_rhp==0], cmap=custom_cmap, vmin=-0.8, vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e637a25",
   "metadata": {},
   "source": [
    "## 2.6.3 Nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# define the window of the peth (x axis); e.g.: wind1<->event<->wind2\n",
    "time_sec = 1\n",
    "wind1 = -inscopix_aq_rate*time_sec\n",
    "wind2 = inscopix_aq_rate*time_sec+1\n",
    "\n",
    "# create a matrix (peth) to save the baseline activity of each neuron\n",
    "baseline_C_raw_zscore_nose = np.empty(\n",
    "    [neuron_mat_info['C_raw'].shape[0], np.abs(wind1)*2+1])\n",
    "\n",
    "# define the confidence interval - in this case, 99%\n",
    "z_alpha_over2 = 2.576\n",
    "# create a matrix to save the classification cutOff of each neuron\n",
    "cutOff_modulation_nose = np.empty(\n",
    "    [neuron_mat_info['C_raw'].shape[0], np.abs(wind1)*2+1])\n",
    "\n",
    "# create two arrays: one to save positively modulated neurons and another to save the negatively modulated neurons\n",
    "posmod_nose = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "negmod_nose = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "\n",
    "# for every neuron...\n",
    "for i, neuron in enumerate(df_C_raw_zscore.columns):\n",
    "    print(i, neuron)  # delete this\n",
    "    # create an array containing the temporal distance between consecutive events\n",
    "    diff_initiations_nose = np.diff(indices_inscop_closest_ts_to_nose_init)\n",
    "    # clone the above array, so that you have a copy that can be manipulated (the shuffle method is not reversible)\n",
    "    # inspite of the name, it is initialized with the original events\n",
    "    shuffled_diffs_nose = np.diff(indices_inscop_closest_ts_to_nose_init)\n",
    "\n",
    "    num_shuffles = 1000  # number of shuffles\n",
    "\n",
    "    # create an empty array in which the mean of the shuffled events will be stored\n",
    "    sham_nose_peth_neurons = np.zeros(\n",
    "        [num_shuffles, np.abs(wind1)*2+1])\n",
    "\n",
    "    for j in range(num_shuffles):\n",
    "        # start by shuffling the distances between the events\n",
    "        random.shuffle(shuffled_diffs_nose)\n",
    "        # create the array in which the shuffled events will be stored\n",
    "        sham_initiations_nose = np.zeros(\n",
    "            len(indices_inscop_closest_ts_to_nose_init))\n",
    "        # in this implementation, the first initiation is fixed (corresponds to the first initiation that was detected)...\n",
    "        sham_initiations_nose[0] = indices_inscop_closest_ts_to_nose_init[0]\n",
    "        # ...and the others are the cumsum of one shuffle of the diffs between the detected initiations.\n",
    "        # Note that the first initiation should be added to the diffs, so that the cumsum starts from there\n",
    "        sham_initiations_nose[1:] = np.cumsum(\n",
    "            shuffled_diffs_nose)+indices_inscop_closest_ts_to_nose_init[0]\n",
    "        # so, now we have the sham initiations stored in memory and we can build the peth of the current shuffle\n",
    "        matrix_initiations_sham_nose = np.tile(\n",
    "            np.vstack(sham_initiations_nose), (1, len(range(wind1, wind2))))\n",
    "        matrix_operation_sham_nose = np.tile(\n",
    "            range(wind1, wind2), (len(indices_inscop_closest_ts_to_nose_init), 1))\n",
    "        matrix_sequences_sham_nose = matrix_initiations_sham_nose + matrix_operation_sham_nose\n",
    "        # eliminate sequences (wind1<->event<->wind2) for which we don't have all the points\n",
    "        for k in range(5):\n",
    "            if matrix_sequences_sham_nose[0][0] < 0:\n",
    "                matrix_sequences_sham_nose = np.delete(\n",
    "                    matrix_sequences_sham_nose, 0, 0)\n",
    "            elif matrix_sequences_sham_nose[-1][-1] >= neuron_mat_info['C_raw'].shape[1]:\n",
    "                matrix_sequences_sham_nose = np.delete(\n",
    "                    matrix_sequences_sham_nose, -1, 0)\n",
    "        # use the indexes calculated in the previous step to obtain the z-score of the C_raw data\n",
    "        # add the mean of the events relative to the current shuffle to the structure for the final 'sham' peth\n",
    "        sham_nose_peth_neurons[j, :] = np.mean(np.array(df_C_raw_zscore[neuron])[\n",
    "            matrix_sequences_sham_nose.astype(int)], axis=0)\n",
    "\n",
    "    # compute the baseline of the current neuron as the average of all the averages of shuffled/sham initiations\n",
    "    baseline_C_raw_zscore_nose[i, :] = np.mean(\n",
    "        sham_nose_peth_neurons, axis=0)\n",
    "    # compute the classification cutOff of the currrent neuron as 2.576 times the standard deviation - confidence interval 99%\n",
    "    cutOff_modulation_nose[i, :] = z_alpha_over2 * \\\n",
    "        np.std(sham_nose_peth_neurons, axis=0)\n",
    "    # classify the current neuron as positively modulated\n",
    "    posmod = nose_peth_neurons[i][20:61] > baseline_C_raw_zscore_nose[i] + \\\n",
    "        cutOff_modulation_nose[i]\n",
    "    if np.sum(posmod) > 3:\n",
    "        for l, mod in enumerate(posmod):\n",
    "            if posmod[l] == 1 and posmod[l+1] == 1 and posmod[l+2] == 1:\n",
    "                posmod_nose[i] = 1\n",
    "                break\n",
    "    # classify the current neuron as negatively modulated\n",
    "    negmod = nose_peth_neurons[i][20:61] < baseline_C_raw_zscore_nose[i] - \\\n",
    "        cutOff_modulation_nose[i]\n",
    "    if np.sum(negmod) > 3:\n",
    "        for m, mod in enumerate(negmod):\n",
    "            if negmod[m] == 1 and negmod[m+1] == 1 and negmod[m+2] == 1:\n",
    "                negmod_nose[i] = 1\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbee967",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2)\n",
    "\n",
    "ax1.imshow(nose_peth_neurons[posmod_nose==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2.imshow(nose_peth_neurons[negmod_nose==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "\n",
    "ax3.imshow(nose_peth_neurons[posmod_nose==0], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax4.imshow(nose_peth_neurons[negmod_nose==0], cmap=custom_cmap, vmin=-0.8, vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ffbb7",
   "metadata": {},
   "source": [
    "## 2.6.1 Left hind paw (lhp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# define the window of the peth (x axis); e.g.: wind1<->event<->wind2\n",
    "time_sec = 1\n",
    "wind1 = -inscopix_aq_rate*time_sec\n",
    "wind2 = inscopix_aq_rate*time_sec+1\n",
    "\n",
    "# create a matrix (peth) to save the baseline activity of each neuron\n",
    "baseline_C_raw_zscore_lhp = np.empty(\n",
    "    [neuron_mat_info['C_raw'].shape[0], np.abs(wind1)*2+1])\n",
    "\n",
    "# define the confidence interval - in this case, 99%\n",
    "z_alpha_over2 = 2.576\n",
    "# create a matrix to save the classification cutOff of each neuron\n",
    "cutOff_modulation_lhp = np.empty(\n",
    "    [neuron_mat_info['C_raw'].shape[0], np.abs(wind1)*2+1])\n",
    "\n",
    "# create two arrays: one to save positively modulated neurons and another to save the negatively modulated neurons\n",
    "posmod_lhp = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "negmod_lhp = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "\n",
    "# for every neuron...\n",
    "for i, neuron in enumerate(df_C_raw_zscore.columns):\n",
    "    print(i, neuron)  # delete this\n",
    "    # create an array containing the temporal distance between consecutive events\n",
    "    diff_initiations_lhp = np.diff(indices_inscop_closest_ts_to_lhp_init)\n",
    "    # clone the above array, so that you have a copy that can be manipulated (the shuffle method is not reversible)\n",
    "    # inspite of the name, it is initialized with the original events\n",
    "    shuffled_diffs_lhp = np.diff(indices_inscop_closest_ts_to_lhp_init)\n",
    "\n",
    "    num_shuffles = 1000  # number of shuffles\n",
    "\n",
    "    # create an empty array in which the mean of the shuffled events will be stored\n",
    "    sham_lhp_peth_neurons = np.zeros(\n",
    "        [num_shuffles, np.abs(wind1)*2+1])\n",
    "\n",
    "    for j in range(num_shuffles):\n",
    "        # start by shuffling the distances between the events\n",
    "        random.shuffle(shuffled_diffs_lhp)\n",
    "        # create the array in which the shuffled events will be stored\n",
    "        sham_initiations_lhp = np.zeros(\n",
    "            len(indices_inscop_closest_ts_to_lhp_init))\n",
    "        # in this implementation, the first initiation is fixed (corresponds to the first initiation that was detected)...\n",
    "        sham_initiations_lhp[0] = indices_inscop_closest_ts_to_lhp_init[0]\n",
    "        # ...and the others are the cumsum of one shuffle of the diffs between the detected initiations.\n",
    "        # Note that the first initiation should be added to the diffs, so that the cumsum starts from there\n",
    "        sham_initiations_lhp[1:] = np.cumsum(\n",
    "            shuffled_diffs_lhp)+indices_inscop_closest_ts_to_lhp_init[0]\n",
    "        # so, now we have the sham initiations stored in memory and we can build the peth of the current shuffle\n",
    "        matrix_initiations_sham_lhp = np.tile(\n",
    "            np.vstack(sham_initiations_lhp), (1, len(range(wind1, wind2))))\n",
    "        matrix_operation_sham_lhp = np.tile(\n",
    "            range(wind1, wind2), (len(indices_inscop_closest_ts_to_lhp_init), 1))\n",
    "        matrix_sequences_sham_lhp = matrix_initiations_sham_lhp + matrix_operation_sham_lhp\n",
    "        # eliminate sequences (wind1<->event<->wind2) for which we don't have all the points\n",
    "        for k in range(5):\n",
    "            if matrix_sequences_sham_lhp[0][0] < 0:\n",
    "                matrix_sequences_sham_lhp = np.delete(\n",
    "                    matrix_sequences_sham_lhp, 0, 0)\n",
    "            elif matrix_sequences_sham_lhp[-1][-1] >= neuron_mat_info['C_raw'].shape[1]:\n",
    "                matrix_sequences_sham_lhp = np.delete(\n",
    "                    matrix_sequences_sham_lhp, -1, 0)\n",
    "        # use the indexes calculated in the previous step to obtain the z-score of the C_raw data\n",
    "        # add the mean of the events relative to the current shuffle to the structure for the final 'sham' peth\n",
    "        sham_lhp_peth_neurons[j, :] = np.mean(np.array(df_C_raw_zscore[neuron])[\n",
    "            matrix_sequences_sham_lhp.astype(int)], axis=0)\n",
    "\n",
    "    # compute the baseline of the current neuron as the average of all the averages of shuffled/sham initiations\n",
    "    baseline_C_raw_zscore_lhp[i, :] = np.mean(\n",
    "        sham_lhp_peth_neurons, axis=0)\n",
    "    # compute the classification cutOff of the currrent neuron as 2.576 times the standard deviation - confidence interval 99%\n",
    "    cutOff_modulation_lhp[i, :] = z_alpha_over2 * \\\n",
    "        np.std(sham_lhp_peth_neurons, axis=0)\n",
    "    # classify the current neuron as positively modulated\n",
    "    posmod = lhp_peth_neurons[i][20:61] > baseline_C_raw_zscore_lhp[i] + \\\n",
    "        cutOff_modulation_lhp[i]\n",
    "    if np.sum(posmod) > 3:\n",
    "        for l, mod in enumerate(posmod):\n",
    "            if l+2 >= np.abs(wind1)*2+1:\n",
    "                break\n",
    "            if posmod[l] == 1 and posmod[l+1] == 1 and posmod[l+2] == 1:\n",
    "                posmod_lhp[i] = 1\n",
    "                break\n",
    "    # classify the current neuron as negatively modulated\n",
    "    negmod = lhp_peth_neurons[i][20:61] < baseline_C_raw_zscore_lhp[i] - \\\n",
    "        cutOff_modulation_lhp[i]\n",
    "    if np.sum(negmod) > 3:\n",
    "        for m, mod in enumerate(negmod):\n",
    "            if m+2 >= np.abs(wind1)*2+1:\n",
    "                break\n",
    "            if negmod[m] == 1 and negmod[m+1] == 1 and negmod[m+2] == 1:\n",
    "                negmod_lhp[i] = 1\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e169a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(accel_peth_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ffd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhp_peth_neurons = np.array(lhp_peth_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f23059",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2)\n",
    "\n",
    "ax1.imshow(lhp_peth_neurons[posmod_lhp==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2.imshow(lhp_peth_neurons[negmod_lhp==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "\n",
    "ax3.imshow(lhp_peth_neurons[posmod_lhp==0], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax4.imshow(lhp_peth_neurons[negmod_lhp==0], cmap=custom_cmap, vmin=-0.8, vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb531c5",
   "metadata": {},
   "source": [
    "### Plot the positively modulated neurons for every event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aab96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2)\n",
    "\n",
    "fig.suptitle('Mice_'+path_data.split('\\\\')[4]+'\\nPositively modulated neurons', fontweight='bold')\n",
    "\n",
    "# row 1\n",
    "ax1.imshow(accel_peth_neurons[posmod_accel == 1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax1.set_title('Total body acceleration')\n",
    "ax2.imshow(nose_peth_neurons[posmod_nose == 1],\n",
    "           cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2.set_title('Nose')\n",
    "\n",
    "# row 2\n",
    "ax3.imshow(rhp_peth_neurons[posmod_rhp == 1],\n",
    "       cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax3.set_title('Right hind paw')\n",
    "ax4.imshow(lhp_peth_neurons[posmod_lhp == 1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax4.set_title('Left hind paw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862883b0",
   "metadata": {},
   "source": [
    "#### Plot everything representing only the positively modulated neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b098e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "from numpy.ma import masked_array\n",
    "\n",
    "# create the figure and define the display of the subplots\n",
    "fig, ((ax1, ax2, ax3, ax4), (ax9, ax10, ax11, ax12), (ax5, ax6, ax7, ax8), (ax13, ax14, ax15, ax16), (ax17, ax18, ax19, ax20)) = plt.subplots(5, 4, \n",
    "                       gridspec_kw={'width_ratios': [1, 1, 1, 1],'height_ratios': [4, 1, 1, 1, 1]}, constrained_layout=False)\n",
    "# need to adjust height ratios\n",
    "\n",
    "ratio = 0.7\n",
    "fig.suptitle('Mice_'+path_data.split('\\\\')[4], fontweight='bold')\n",
    "\n",
    "# set the spacing between subplots\n",
    "plt.subplots_adjust(left=0.1,bottom=0.1, right=0.5, top=0.9, wspace=0.8, hspace=0.2)\n",
    "\n",
    "### ROW_1 ### PETH ###\n",
    "\n",
    "# customize a colormap (goes from blue-negative to black-0 to yellow-positive)\n",
    "custom_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"custom\", [\"#29bbd9\",\"black\", \"#fbff00\"])\n",
    "\n",
    "# subplot 1 - PETH of the initiations detected using the accelerometer\n",
    "accel_peth_neurons_test = accel_peth_neurons\n",
    "accel_peth_neurons_test[posmod_accel == 0] = -1\n",
    "v1 = accel_peth_neurons_test\n",
    "v1a = masked_array(v1,v1 != -1)\n",
    "v1b = masked_array(v1,v1 == -1)\n",
    "pa = ax1.imshow(v1a,interpolation='nearest',cmap='Reds', vmin=-5, vmax=0)\n",
    "pb = ax1.imshow(v1b,interpolation='nearest',cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax1.set_xlabel('time (sec)')\n",
    "ax1.set_ylabel('# Neuron')\n",
    "ax1.set_title('Total body acceleration')\n",
    "ax1.set_xticks([0, 40, 80], labels = [-2,0,2])\n",
    "\n",
    "# subplot 2 - PETH of the initiations detected using the velocity computed from the DLC predictions of the right hindpaw coordinates\n",
    "rhp_peth_neurons_test = rhp_peth_neurons\n",
    "rhp_peth_neurons_test[posmod_rhp == 0] = -1\n",
    "v1 = rhp_peth_neurons_test\n",
    "v1a = masked_array(v1,v1 != -1)\n",
    "v1b = masked_array(v1,v1 == -1)\n",
    "pa = ax2.imshow(v1a,interpolation='nearest',cmap='Reds', vmin=-5, vmax=0)\n",
    "pb = ax2.imshow(v1b,interpolation='nearest',cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2.set_xlabel('time (sec)')\n",
    "ax2.set_title('Right hind paw')\n",
    "ax2.set_xticks([0, 40, 80], labels = [-2,0,2])\n",
    "\n",
    "# subplot 3 - PETH of the initiations detected using the velocity computed from the DLC predictions of the nose\n",
    "nose_peth_neurons_test = nose_peth_neurons\n",
    "nose_peth_neurons_test[posmod_nose == 0] = -1\n",
    "v1 = nose_peth_neurons_test\n",
    "v1a = masked_array(v1,v1 != -1)\n",
    "v1b = masked_array(v1,v1 == -1)\n",
    "pa = ax3.imshow(v1a,interpolation='nearest',cmap='Reds', vmin=-5, vmax=0)\n",
    "pb = ax3.imshow(v1b,interpolation='nearest',cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax3.set_xlabel('time (sec)')\n",
    "ax3.set_title('Nose')\n",
    "ax3.set_xticks([0, 40, 80], labels = [-2,0,2])\n",
    "\n",
    "# subplot 4 - PETH of the initiations detected using the velocity computed from the DLC predictions of the left hindpaw coordinates\n",
    "lhp_peth_neurons_test = lhp_peth_neurons\n",
    "lhp_peth_neurons_test[posmod_lhp == 0] = -1\n",
    "v1 = lhp_peth_neurons_test\n",
    "v1a = masked_array(v1,v1 != -1)\n",
    "v1b = masked_array(v1,v1 == -1)\n",
    "pa = ax4.imshow(v1a,interpolation='nearest',cmap='Reds', vmin=-5, vmax=0)\n",
    "pb = ax4.imshow(v1b,interpolation='nearest',cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax4.set_xlabel('time (sec)')\n",
    "ax4.set_title('Left hind paw')\n",
    "ax4.set_xticks([0, 40, 80], labels = [-2,0,2])\n",
    "\n",
    "### ROW_2 ### Probability density function of movement initiations\n",
    "# subplot 5 - total body acceleration\n",
    "ax5.set_ylabel('P (initiation)')\n",
    "time_sec=2\n",
    "wind2 = fs*time_sec+1\n",
    "ax5.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density)/matrix_pre_probability_density.shape[0], color = 'red')\n",
    "ax5.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax5.spines['top'].set_visible(False)\n",
    "ax5.spines['right'].set_visible(False)\n",
    "ax5.grid(False)\n",
    "x_left, x_right = ax5.get_xlim()\n",
    "y_low, y_high = ax5.get_ylim()\n",
    "ax5.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 6 - lesioned paw (DLC velocity)\n",
    "wind2 = camera_aq_rate*time_sec+1\n",
    "ax6.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density_rhp)/matrix_pre_probability_density_rhp.shape[0], color = 'red')\n",
    "ax6.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax6.spines['top'].set_visible(False)\n",
    "ax6.spines['right'].set_visible(False)\n",
    "ax6.grid(False)\n",
    "x_left, x_right = ax6.get_xlim()\n",
    "y_low, y_high = ax6.get_ylim()\n",
    "ax6.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "# subplot 7 - nose (DLC velocity)\n",
    "ax7.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density_nose)/matrix_pre_probability_density_nose.shape[0], color = 'red')\n",
    "ax7.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax7.spines['top'].set_visible(False)\n",
    "ax7.spines['right'].set_visible(False)\n",
    "ax7.grid(False)\n",
    "x_left, x_right = ax7.get_xlim()\n",
    "y_low, y_high = ax7.get_ylim()\n",
    "ax7.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "# subplot 8 - left hind paw (DLC velocity)\n",
    "ax8.plot(np.linspace(-2,2, (wind2-1)*2+1), sum(matrix_pre_probability_density_lhp)/matrix_pre_probability_density_lhp.shape[0], color = 'red')\n",
    "ax8.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax8.spines['top'].set_visible(False)\n",
    "ax8.spines['right'].set_visible(False)\n",
    "ax8.grid(False)\n",
    "x_left, x_right = ax8.get_xlim()\n",
    "y_low, y_high = ax8.get_ylim()\n",
    "ax8.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "\n",
    "### ROW_3 ### Average of the PETH\n",
    "# subplot 9 - Average of the PETH aligned to the initiations detected using the total body acceleration\n",
    "ax9.set_ylabel('C_raw (z-score)')\n",
    "ax9.set_ylim([-0.15,1.2])\n",
    "ax9.plot(np.linspace(-2, 2, 81),\n",
    "         np.mean(accel_peth_neurons[posmod_accel == 1], axis=0), label='Average of the PETH')\n",
    "ax9.fill_between(np.linspace(-2,2,81), \n",
    "                 np.mean(accel_peth_neurons[posmod_accel==1], axis = 0) - np.std(accel_peth_neurons[posmod_accel==1], axis = 0)/math.sqrt(np.sum(posmod_accel)),\n",
    "                 np.mean(accel_peth_neurons[posmod_accel==1], axis = 0) + np.std(accel_peth_neurons[posmod_accel==1], axis = 0)/math.sqrt(np.sum(posmod_accel)), alpha = 0.2)\n",
    "ax9.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax9.spines['top'].set_visible(False)\n",
    "ax9.spines['right'].set_visible(False)\n",
    "ax9.grid(False)\n",
    "x_left, x_right = ax9.get_xlim()\n",
    "y_low, y_high = ax9.get_ylim()\n",
    "ax9.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "ax9.legend(fontsize=6)\n",
    "\n",
    "# sublpot 10 - Average of the PETH aligned to the initiations detected using the velocity from the right hindpaw heel\n",
    "ax10.set_ylim([-0.15,1.2])\n",
    "ax10.plot(np.linspace(-2,2,81), np.mean(rhp_peth_neurons[posmod_rhp==1], axis = 0), label='Average of the PETH')\n",
    "ax10.fill_between(np.linspace(-2,2,81), \n",
    "                 np.mean(rhp_peth_neurons[posmod_rhp==1], axis = 0) - np.std(rhp_peth_neurons[posmod_rhp==1], axis = 0)/math.sqrt(np.sum(posmod_rhp)),\n",
    "                 np.mean(rhp_peth_neurons[posmod_rhp==1], axis = 0) + np.std(accel_peth_neurons[posmod_rhp==1], axis = 0)/math.sqrt(np.sum(posmod_rhp)), alpha = 0.2)\n",
    "ax10.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax10.spines['top'].set_visible(False)\n",
    "ax10.spines['right'].set_visible(False)\n",
    "ax10.grid(False)\n",
    "x_left, x_right = ax10.get_xlim()\n",
    "y_low, y_high = ax10.get_ylim()\n",
    "ax10.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "ax10.legend(fontsize=6)\n",
    "\n",
    "# subplot 11 - Average of the PETH aligned to the initiations detected using the velocity from the nose\n",
    "ax11.set_ylim([-0.15,1.2])\n",
    "ax11.plot(np.linspace(-2, 2, 81),\n",
    "          np.mean(nose_peth_neurons[posmod_nose == 1], axis=0), label='Average of the PETH')\n",
    "ax11.fill_between(np.linspace(-2,2,81), np.mean(nose_peth_neurons[posmod_nose==1], axis = 0) - np.std(nose_peth_neurons[posmod_nose==1], axis = 0)/math.sqrt(np.sum(posmod_nose)), \n",
    "                  np.mean(nose_peth_neurons[posmod_nose == 1], axis=0) + np.std(nose_peth_neurons[posmod_nose == 1], axis=0)/math.sqrt(np.sum(posmod_nose)), alpha=0.2)\n",
    "X_POSITION = 0\n",
    "ax11.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax11.spines['top'].set_visible(False)\n",
    "ax11.spines['right'].set_visible(False)\n",
    "ax11.grid(False)\n",
    "x_left, x_right = ax11.get_xlim()\n",
    "y_low, y_high = ax11.get_ylim()\n",
    "ax11.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "ax11.legend(fontsize=6)\n",
    "\n",
    "# subplot 12 - Average of the PETH aligned to the initiations detected using the velocity from the left hindpaw heel\n",
    "ax12.set_ylim([-0.15,1.2])\n",
    "ax12.plot(np.linspace(-2, 2, 81),\n",
    "          np.mean(lhp_peth_neurons[posmod_lhp == 1], axis=0), label='Average of the PETH')\n",
    "ax12.fill_between(np.linspace(-2, 2, 81), np.mean(lhp_peth_neurons[posmod_lhp == 1], axis=0) - np.std(\n",
    "    lhp_peth_neurons[posmod_lhp == 1], axis=0)/math.sqrt(np.sum(posmod_lhp)), \n",
    "    np.mean(lhp_peth_neurons[posmod_lhp == 1], axis=0) + np.std(lhp_peth_neurons[posmod_lhp == 1], axis=0)/math.sqrt(np.sum(posmod_lhp)), alpha=0.2)\n",
    "X_POSITION = 0\n",
    "ax12.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax12.spines['top'].set_visible(False)\n",
    "ax12.spines['right'].set_visible(False)\n",
    "ax12.grid(False)\n",
    "x_left, x_right = ax12.get_xlim()\n",
    "y_low, y_high = ax12.get_ylim()\n",
    "ax12.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "ax12.legend(fontsize=6)\n",
    "\n",
    "### ROW_4 ### Total body acceleration\n",
    "# subplot 13 - Movement initiations\n",
    "ax13.set_ylabel('Total body\\nacceleration (?)')\n",
    "time_sec=2\n",
    "beg_plot = -fs*time_sec\n",
    "end_plot = fs*time_sec+1\n",
    "ax13.set_ylim([0,3200])\n",
    "ax13.plot(np.linspace(-2,2,801), df_initiations_accel_sequence_interest.mean(axis=1), color='green')\n",
    "ax13.fill_between(np.linspace(-2,2,801), \n",
    "                 mean_accel - std_error_accel,\n",
    "                 mean_accel + std_error_accel, alpha = 0.2, color='green')\n",
    "\n",
    "ax13.spines['top'].set_visible(False)\n",
    "ax13.spines['right'].set_visible(False)\n",
    "ax13.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax13.grid(False)\n",
    "x_left, x_right = ax13.get_xlim()\n",
    "y_low, y_high = ax13.get_ylim()\n",
    "ax13.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 14 - TBA aligned to movement initiations of the right hind paw\n",
    "ax14.set_ylim([0,3200])\n",
    "ax14.plot(np.linspace(-2,2,801), df_accel_aligned_to_vel.mean(axis=1), color='green')\n",
    "ax14.fill_between(np.linspace(-2,2,801), \n",
    "                 mean_accel_ - std_error_accel_,\n",
    "                 mean_accel_ + std_error_accel_, alpha = 0.2, color='green')\n",
    "\n",
    "ax14.spines['top'].set_visible(False)\n",
    "ax14.spines['right'].set_visible(False)\n",
    "ax14.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax14.grid(False)\n",
    "x_left, x_right = ax14.get_xlim()\n",
    "y_low, y_high = ax14.get_ylim()\n",
    "ax14.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 15 - TBA aligned to movement initiations of the nose\n",
    "wind2 = fs*time_sec+1\n",
    "ax15.set_ylim([0,3200])\n",
    "mean_tba_aligned_2nose = sum(TBA_aligned_2nose_peth)/(len(indices_closest_ts_2nose_vel_init)-1)\n",
    "std_tba_aligned_2nose = TBA_aligned_2nose_peth.std(axis=0) \n",
    "std_error_tba_aligned_2nose = std_tba_aligned_2nose/math.sqrt(len(indices_closest_ts_2nose_vel_init)-1)\n",
    "ax15.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_tba_aligned_2nose, color = 'green')\n",
    "ax15.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_tba_aligned_2nose - std_error_tba_aligned_2nose,\n",
    "                 mean_tba_aligned_2nose + std_error_tba_aligned_2nose, alpha = 0.2, color = 'green')\n",
    "ax15.spines['top'].set_visible(False) \n",
    "ax15.spines['right'].set_visible(False)\n",
    "ax15.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax15.grid(False)\n",
    "x_left, x_right = ax15.get_xlim()\n",
    "y_low, y_high = ax15.get_ylim()\n",
    "ax15.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 16 - TBA aligned to movement initiations of the left hind paw\n",
    "ax16.set_ylim([0,3200])\n",
    "mean_tba_aligned_2lhp = sum(TBA_aligned_2lhp_peth)/(len(indices_closest_ts_2lhp_vel_init))\n",
    "std_tba_aligned_2lhp = TBA_aligned_2lhp_peth.std(axis=0) \n",
    "std_error_tba_aligned_2lhp = std_tba_aligned_2lhp/math.sqrt(len(indices_closest_ts_2lhp_vel_init))\n",
    "ax16.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_tba_aligned_2lhp, color = 'green')\n",
    "ax16.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_tba_aligned_2lhp - std_error_tba_aligned_2lhp,\n",
    "                 mean_tba_aligned_2lhp + std_error_tba_aligned_2lhp, alpha = 0.2, color = 'green')\n",
    "ax16.spines['top'].set_visible(False)\n",
    "ax16.spines['right'].set_visible(False)\n",
    "ax16.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax16.grid(False)\n",
    "x_left, x_right = ax16.get_xlim()\n",
    "y_low, y_high = ax16.get_ylim()\n",
    "ax16.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "### ROW_5 ### Velocity\n",
    "# subplot 17 - all velocities aligned to the movement initiations calculated form the total body acceleration\n",
    "wind2=camera_aq_rate*time_sec+1\n",
    "ax17.set_ylim([0,25])\n",
    "ax17.plot(np.linspace(-2,2,(wind2-1)*2+1), df_velocities_aligned_to_accel.mean(axis=1), label = 'right hind paw', color = 'purple')\n",
    "ax17.fill_between(np.linspace(-2,2,(wind2-1)*2+1), \n",
    "                 mean_velocity - std_error_velocity,\n",
    "                 mean_velocity + std_error_velocity, alpha = 0.2, color = 'purple')\n",
    "ax17.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_nose_aligned_2accel, color = 'yellow', label = 'nose')\n",
    "ax17.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_nose_aligned_2accel - std_error_nose_aligned_2accel,\n",
    "                 mean_nose_aligned_2accel + std_error_nose_aligned_2accel, alpha = 0.2, color = 'yellow')\n",
    "ax17.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_lhp_aligned_2accel, color = 'deeppink', label = 'left hind paw')\n",
    "ax17.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_lhp_aligned_2accel - std_error_lhp_aligned_2accel,\n",
    "                 mean_lhp_aligned_2accel + std_error_lhp_aligned_2accel, alpha = 0.2, color = 'deeppink')\n",
    "ax17.spines['top'].set_visible(False)\n",
    "ax17.spines['right'].set_visible(False)\n",
    "ax17.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax17.set_ylabel('Velocity\\n(px/frame)')\n",
    "ax17.set_xlabel('time (s)')\n",
    "ax17.grid(False)\n",
    "x_left, x_right = ax17.get_xlim()\n",
    "y_low, y_high = ax17.get_ylim()\n",
    "ax17.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "leg = ax17.legend(fontsize=6)\n",
    "\n",
    "# subplot 18 - movement initiations with the right hind paw\n",
    "ax18.set_ylim([0,25])\n",
    "ax18.plot(np.linspace(-2,2,121), df_initiations_sequence_interest.mean(axis=1), color='purple')\n",
    "mean_ = df_initiations_sequence_interest.mean(axis=1)\n",
    "std_error = (df_initiations_sequence_interest.std(axis=1)/math.sqrt(len(initiation_right_paw_corrected))) #standard error\n",
    "ax18.fill_between(np.linspace(-2,2,121), \n",
    "                 mean_ - std_error,\n",
    "                 mean_ + std_error, alpha = 0.2, color='purple')\n",
    "ax18.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax18.spines['top'].set_visible(False)\n",
    "ax18.spines['right'].set_visible(False)\n",
    "ax18.set_xlabel('time (s)')\n",
    "ax18.grid(False)\n",
    "x_left, x_right = ax18.get_xlim()\n",
    "y_low, y_high = ax18.get_ylim()\n",
    "ax18.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 19 - movement initiations with the nose\n",
    "wind2=camera_aq_rate*time_sec+1\n",
    "ax19.set_ylim([0,25])\n",
    "ax19.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_nose, color='yellow')\n",
    "ax19.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_nose - std_error_nose,\n",
    "                 mean_nose + std_error_nose, alpha = 0.2, color='yellow')\n",
    "ax19.spines['top'].set_visible(False)\n",
    "ax19.spines['right'].set_visible(False)\n",
    "ax19.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax19.set_ylabel('Velocity\\n(px/frame)')\n",
    "ax19.set_xlabel('time (s)')\n",
    "ax19.grid(False)\n",
    "x_left, x_right = ax19.get_xlim()\n",
    "y_low, y_high = ax19.get_ylim()\n",
    "ax19.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "# subplot 20 - movement initiations with the left hind paw\n",
    "ax20.set_ylim([0,25])\n",
    "plt.plot(np.linspace(-2, 2, (wind2-1)*2+1), mean_lhp, color='deeppink')\n",
    "plt.fill_between(np.linspace(-2, 2, (wind2-1)*2+1), \n",
    "                 mean_lhp - std_error_lhp,\n",
    "                 mean_lhp + std_error_lhp, alpha = 0.2, color='deeppink')\n",
    "ax20.spines['top'].set_visible(False)\n",
    "ax20.spines['right'].set_visible(False)\n",
    "ax20.axvline(X_POSITION, linestyle = '--', color = 'black')\n",
    "ax20.set_ylabel('Velocity\\n(px/frame)')\n",
    "ax20.set_xlabel('time (s)')\n",
    "ax20.grid(False)\n",
    "x_left, x_right = ax20.get_xlim()\n",
    "y_low, y_high = ax20.get_ylim()\n",
    "ax20.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc54d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a4117",
   "metadata": {},
   "source": [
    "#### Exploring the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7470da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Find neurons that are both positively modulated by the total body acceleration and by the velocity of the nose\n",
    "posmod_accel_nose = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "\n",
    "for i in range(neuron_mat_info['C_raw'].shape[0]):\n",
    "    if posmod_accel[i] == 1 and posmod_nose[i] == 1:\n",
    "        posmod_accel_nose[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib_venn as vplt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "%matplotlib inline \n",
    "fig = plt.figure()\n",
    "fig.suptitle('Mice_'+path_data.split('\\\\')[4], fontweight='bold')\n",
    "gs = GridSpec(2,2, figure = fig)\n",
    "\n",
    "#fig, ((ax1, ax2), (ax3)) = plt.subplots(2, [1,2])\n",
    "\n",
    "# row 1\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.imshow(accel_peth_neurons[posmod_accel_nose == 1],\n",
    "           cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "ax2.imshow(nose_peth_neurons[posmod_accel_nose == 1],\n",
    "           cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "\n",
    "# row 2\n",
    "ax3 = fig.add_subplot(gs[1,:])\n",
    "ax3 = vplt.venn2(subsets=(int(np.sum(posmod_accel))-int(np.sum(posmod_accel_nose)), int(np.sum(posmod_nose))-int(np.sum(posmod_accel_nose)), int(np.sum(posmod_accel_nose))),\n",
    "           set_labels=('Total body acceleration', 'Velocity of the nose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f94247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Find neurons that are both positively modulated by both hind paws\n",
    "posmod_rhp_lhp = np.zeros(neuron_mat_info['C_raw'].shape[0])\n",
    "\n",
    "for i in range(neuron_mat_info['C_raw'].shape[0]):\n",
    "    if posmod_rhp[i] == 1 and posmod_lhp[i] == 1:\n",
    "        posmod_rhp_lhp[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134caa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2)) = plt.subplots(1, 2)\n",
    "ax1.imshow(rhp_peth_neurons[posmod_rhp==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2.imshow(lhp_peth_neurons[posmod_lhp==1], cmap=custom_cmap, vmin=-0.8, vmax=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407656f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib_venn as vplt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "%matplotlib inline\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Mice_'+path_data.split('\\\\')[4], fontweight='bold')\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "#fig, ((ax1, ax2), (ax3)) = plt.subplots(2, [1,2])\n",
    "\n",
    "# row 1\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.imshow(rhp_peth_neurons[posmod_rhp_lhp == 1],\n",
    "           cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.imshow(lhp_peth_neurons[posmod_rhp_lhp == 1],\n",
    "           cmap=custom_cmap, vmin=-0.8, vmax=0.8)\n",
    "\n",
    "# row 2\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "ax3 = vplt.venn2(subsets=(int(np.sum(posmod_rhp))-int(np.sum(posmod_rhp_lhp)), int(np.sum(posmod_lhp))-int(np.sum(posmod_rhp_lhp)), int(np.sum(posmod_rhp_lhp))),\n",
    "                 set_labels=('Right hind paw', 'Left hind paw'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
